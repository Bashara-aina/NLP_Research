{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5bf24e9-d40b-45ad-9330-405d0097fe2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-20 12:41:00.769334: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-20 12:41:00.794139: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-20 12:41:01.232668: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm  # For displaying progress bars\n",
    "from datasets import load_dataset  # For loading datasets\n",
    "from sklearn.model_selection import train_test_split  # For splitting the dataset\n",
    "from transformers import BertTokenizer  # For tokenizing text\n",
    "from torch.utils.data import TensorDataset  # For creating Tensor datasets\n",
    "import time  # For measuring time\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score  # For evaluation metrics\n",
    "from sklearn.exceptions import UndefinedMetricWarning  # For handling metric warnings\n",
    "import matplotlib.pyplot as plt  # For plotting\n",
    "from tabulate import tabulate  # For tabular data formatting\n",
    "import random  # For randomization\n",
    "import numpy as np  # For numerical operations\n",
    "from transformers import (\n",
    "    BertTokenizer,  # Tokenizer for BERT models\n",
    "    AdamW,  # Optimizer for BERT models\n",
    "    get_linear_schedule_with_warmup,  # Learning rate scheduler for BERT models\n",
    "    BertConfig,  # Configuration for BERT models\n",
    "    BertForSequenceClassification  # BERT model for sequence classification tasks\n",
    ")\n",
    "from torch.utils.data import (\n",
    "    DataLoader,  # Data loader for creating batches\n",
    "    RandomSampler,  # Sampler for random sampling of data\n",
    "    SequentialSampler  # Sampler for sequential sampling of data\n",
    ")\n",
    "from sklearn.metrics import f1_score  # For computing the F1 score\n",
    "\n",
    "# 1. Torch: PyTorch library for deep learning\n",
    "# 2. Pandas: Library for data manipulation and analysis\n",
    "# 3. tqdm: Library for displaying progress bars\n",
    "# 4. datasets: Library for working with datasets\n",
    "# 5. train_test_split: Function for splitting the dataset into training and validation sets\n",
    "# 6. BertTokenizer: Tokenizer for BERT models\n",
    "# 7. TensorDataset: Dataset class for creating PyTorch Tensor datasets\n",
    "# 8. time: Module for measuring time\n",
    "# 9. accuracy_score, precision_score, f1_score: Evaluation metrics for classification tasks\n",
    "# 10. UndefinedMetricWarning: Warning for undefined metric values\n",
    "# 11. matplotlib.pyplot: Plotting library\n",
    "# 12. tabulate: Library for formatting tabular data\n",
    "# 13. random: Module for randomization\n",
    "# 14. numpy: Library for numerical operations\n",
    "# 15. AdamW: Optimizer for BERT models\n",
    "# 16. get_linear_schedule_with_warmup: Learning rate scheduler for BERT models\n",
    "# 17. BertConfig: Configuration for BERT models\n",
    "# 18. BertForSequenceClassification: BERT model for sequence classification tasks\n",
    "# 19. DataLoader: Data loader for creating batches\n",
    "# 20. RandomSampler: Sampler for random sampling of data\n",
    "# 21. SequentialSampler: Sampler for sequential sampling of data\n",
    "# 22. f1_score: Function for computing the F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "207f2073-3da6-4185-917f-e8b3694617ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_imdb():\n",
    "    dataset = load_dataset(\"imdb\")\n",
    "    train_data = dataset['train']\n",
    "    test_data = dataset['test']\n",
    "\n",
    "    df_train = train_data.to_pandas()  # Convert the training dataset to a Pandas DataFrame\n",
    "    df_test = test_data.to_pandas()  # Convert the validation dataset to a Pandas DataFrame\n",
    "\n",
    "    df_train['sentiment'] = df_train['label'].map({0: 'bad', 1: 'good'})\n",
    "    df_test['sentiment'] = df_test['label'].map({0: 'bad', 1: 'good'})\n",
    "\n",
    "    possible_labels = df_train.sentiment.unique()  # Get unique category labels from the training DataFrame column 'category'\n",
    "\n",
    "    label_dict = {}  # Create a dictionary to map each possible label to a unique index\n",
    "    for index, possible_label in enumerate(possible_labels):\n",
    "        label_dict[possible_label] = index\n",
    "\n",
    "    df_train['label'] = df_train.sentiment.replace(label_dict)\n",
    "    df_test['label'] = df_test.sentiment.replace(label_dict)\n",
    "\n",
    "    df_train['data_type'] = 'train'  # Set the 'data_type' column to 'train' for training data\n",
    "    df_test['data_type'] = 'test'  # Set the 'data_type' column to 'val' for validation data\n",
    "\n",
    "    df = pd.concat([df_train, df_test], ignore_index=True)  # Merge the training and validation dataframes\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten() #This line finds the index with the highest probability in each prediction, effectively giving the predicted class for each input.\n",
    "    labels_flat = labels.flatten()  #This line flattens the labels array into a 1D vector, as required by the f1_score function.\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted') #This line computes the F1 score using the true labels and the predicted labels, with the weighted averaging scheme. The result is returned.\n",
    "\n",
    "def accuracy_per_class(preds, labels, label_dict):\n",
    "    # Create a dictionary with keys and values reversed for easy lookup.\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    # Get the predicted labels and flatten them.\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    \n",
    "    # Get the actual labels and flatten them.\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    # Initialize the confusion matrix.\n",
    "    num_classes = len(label_dict)\n",
    "    confusion_mat = confusion_matrix(labels_flat, preds_flat, labels=list(range(num_classes)))\n",
    "    \n",
    "    # Calculate accuracy and F1 score per class\n",
    "    accuracies = {}\n",
    "    f1_scores = {}\n",
    "    for label in range(num_classes):\n",
    "        # Calculate accuracy for this class\n",
    "        num_correct = confusion_mat[label, label]\n",
    "        num_instances = np.sum(confusion_mat[label, :])\n",
    "        accuracy = num_correct / num_instances * 100\n",
    "        accuracies[label] = accuracy\n",
    "        \n",
    "        # Calculate F1 score for this class\n",
    "        f1 = f1_score(labels_flat, preds_flat, labels=[label], average='weighted')\n",
    "        f1_scores[label] = f1\n",
    "\n",
    "        # Print the class name, accuracy numerator, and denominator.\n",
    "        class_name = label_dict_inverse[label]\n",
    "        print(f'Class: {class_name}')\n",
    "        print(f'Accuracy: {num_correct}/{num_instances} ({accuracy:.2f}%)')\n",
    "        print(f'F1 Score: {f1:.2f}\\n')\n",
    "\n",
    "    # Calculate total accuracy and F1 score\n",
    "    total_accuracy = accuracy_score(labels_flat, preds_flat) * 100\n",
    "    total_f1_score = f1_score(labels_flat, preds_flat, average='weighted')\n",
    "\n",
    "    # Print the total accuracy and F1 score\n",
    "    print(f'Total Accuracy: {total_accuracy:.2f}%')\n",
    "    print(f'Total F1 Score: {total_f1_score:.2f}')\n",
    "\n",
    "\n",
    "#This code evaluates the performance of a trained model on a validation dataset by computing its loss and predictions for each batch in the dataset.\n",
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval() # setting the model to evaluation mode to disable dropout and other regularization techniques that are useful during training but not during evaluation.\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "    \n",
    "        batch = tuple(b.to(device) for b in batch) # moving the input batch to the GPU for faster computation.\n",
    "   \n",
    "        #  creating a dictionary of inputs that will be passed to the model. The input IDs and attention mask are for the BERT model, and the labels are the true labels for each input.\n",
    "        inputs = {'input_ids':  \tbatch[0],\n",
    "                'attention_mask': batch[1],\n",
    "                'labels':     \tbatch[2],\n",
    "                } \n",
    "\n",
    "        with torch.no_grad():   \n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val)\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "       \t \n",
    "    return loss_val_avg, predictions, true_vals\n",
    "\n",
    "def train_model(trainer, dataloader_train, dataloader_val, epochs, patience):\n",
    "    total_training_time = 0\n",
    "    \n",
    "    training_loss_list = []\n",
    "    validation_loss_list = []\n",
    "    accuracy_list = []\n",
    "    precision_list = []\n",
    "    f1_score_list = []\n",
    "    \n",
    "    previous_results = None  # Store previous epoch results\n",
    "    best_val_loss = float('inf')\n",
    "    counter = 0\n",
    "    \n",
    "    for epoch in tqdm(range(1, epochs + 1)):\n",
    "        start_time = time.time()\n",
    "    \n",
    "        model.train()\n",
    "        loss_train_total = 0\n",
    "    \n",
    "        progress_bar = tqdm(dataloader_train,\n",
    "                            desc='Epoch {:1d}'.format(epoch),\n",
    "                            leave=False,\n",
    "                            disable=False)\n",
    "        for batch in progress_bar:\n",
    "            model.zero_grad()\n",
    "            batch = tuple(b.to(device) for b in batch)\n",
    "            inputs = {\n",
    "                'input_ids': batch[0],\n",
    "                'attention_mask': batch[1],\n",
    "                'labels': batch[2],\n",
    "            }\n",
    "            output = model(**inputs)\n",
    "            loss = output[0]\n",
    "            loss_train_total += loss.item()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item() / len(batch))})\n",
    "    \n",
    "        end_time = time.time()\n",
    "        epoch_training_time = end_time - start_time\n",
    "        total_training_time += epoch_training_time\n",
    "    \n",
    "        torch.save(model.state_dict(), f'Models/finetuned_bert_imdb_ft_epoch{epoch}.model')\n",
    "    \n",
    "        tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "        loss_train_avg = loss_train_total / len(dataloader_train)\n",
    "        tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "        val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
    "    \n",
    "        # Convert predictions to discrete labels\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "        val_f1 = f1_score(true_vals, predictions, average='weighted')\n",
    "        tqdm.write(f'Validation loss: {val_loss}')\n",
    "        tqdm.write(f'F1 Score (weighted): {val_f1}')\n",
    "    \n",
    "        val_accuracy = accuracy_score(true_vals, predictions)\n",
    "        val_precision = precision_score(true_vals, predictions, average='weighted', zero_division=1)\n",
    "    \n",
    "        # Compute and store metrics\n",
    "        training_loss_list.append(loss_train_avg)\n",
    "        validation_loss_list.append(val_loss)\n",
    "        f1_score_list.append(val_f1)\n",
    "        accuracy_list.append(val_accuracy)\n",
    "        precision_list.append(val_precision)\n",
    "    \n",
    "        # Check if there are previous results to compare with\n",
    "        if previous_results is not None:\n",
    "            if loss_train_avg > previous_results['loss_train_avg']:\n",
    "                percentage_increase = ((loss_train_avg - previous_results['loss_train_avg']) / previous_results['loss_train_avg']) * 100\n",
    "                tqdm.write('\\033[91m' + f'{round(percentage_increase, 2)}% Training loss increased compared to the previous epoch' + '\\033[0m')\n",
    "            if loss_train_avg < previous_results['loss_train_avg']:\n",
    "                percentage_decrease = ((previous_results['loss_train_avg'] - loss_train_avg) / previous_results['loss_train_avg']) * 100\n",
    "                tqdm.write('\\033[92m' + f'{round(percentage_decrease, 2)}% Training loss decreased compared to the previous epoch' + '\\033[0m')\n",
    "            if val_loss > previous_results['val_loss']:\n",
    "                percentage_increase = ((val_loss - previous_results['val_loss']) / previous_results['val_loss']) * 100\n",
    "                tqdm.write('\\033[91m' + f'{round(percentage_increase, 2)}% Validation loss increased compared to the previous epoch' + '\\033[0m')\n",
    "            if val_loss < previous_results['val_loss']:\n",
    "                percentage_decrease = ((previous_results['val_loss'] - val_loss) / previous_results['val_loss']) * 100\n",
    "                tqdm.write('\\033[92m' + f'{round(percentage_decrease, 2)}% Validation loss decreased compared to the previous epoch' + '\\033[0m')\n",
    "            if val_f1 < previous_results['val_f1']:\n",
    "                percentage_decrease = ((previous_results['val_f1'] - val_f1) / previous_results['val_f1']) * 100\n",
    "                tqdm.write('\\033[91m' + f'{round(percentage_decrease, 2)}% F1 Score decreased compared to the previous epoch' + '\\033[0m')\n",
    "            if val_f1 > previous_results['val_f1']:\n",
    "                percentage_increase = ((val_f1 - previous_results['val_f1']) / previous_results['val_f1']) * 100\n",
    "                tqdm.write('\\033[92m' + f'{round(percentage_increase, 2)}% F1 Score increased compared to the previous epoch' + '\\033[0m')\n",
    "    \n",
    "        # Store current results as previous results for the next epoch\n",
    "        previous_results = {\n",
    "            'loss_train_avg': loss_train_avg,\n",
    "            'val_loss': val_loss,\n",
    "            'val_f1': val_f1\n",
    "        }\n",
    "        \n",
    "        # Check for early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                tqdm.write('\\nEarly stopping triggered. Training stopped.')\n",
    "                break\n",
    "    \n",
    "    total_time_minutes = total_training_time / 60\n",
    "    tqdm.write(f'\\nTotal training time: {total_time_minutes} minutes')\n",
    "    \n",
    "    final_accuracy = accuracy_list[-1]\n",
    "    final_precision = precision_list[-1]\n",
    "    tqdm.write(f'Final Accuracy: {final_accuracy}')\n",
    "    tqdm.write(f'Final Precision: {final_precision}')\n",
    "    \n",
    "    # Create the x-axis values based on the actual number of epochs completed\n",
    "    x_values = range(1, len(training_loss_list) + 1)\n",
    "    \n",
    "    # Create the metrics subplot\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    # Plot training loss\n",
    "    ax.plot(x_values, training_loss_list, label='Training Loss')\n",
    "    \n",
    "    # Plot validation loss\n",
    "    ax.plot(x_values, validation_loss_list, label='Validation Loss')\n",
    "    \n",
    "    # Plot F1-score\n",
    "    ax.plot(x_values, f1_score_list, label='F1 Score')\n",
    "\n",
    "    # Plot Accuracy\n",
    "    ax.plot(x_values, accuracy_list, label='Accuracy')\n",
    "    \n",
    "    # Set labels and title\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Metric Value')\n",
    "    ax.set_title('Training Loss, Validation Loss, and F1 Score')\n",
    "    \n",
    "    # Set legend\n",
    "    ax.legend()\n",
    "    \n",
    "    # Show the combined plot\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    # Create the metrics table\n",
    "    metrics_table = [\n",
    "        ['Epoch', 'Training Loss', 'Validation Loss', 'F1 Score', 'Accuracy', 'Precision'],\n",
    "    ]\n",
    "    previous_results = None\n",
    "    for epoch in range(1, len(training_loss_list) + 1):\n",
    "        row = [\n",
    "            epoch,\n",
    "            training_loss_list[epoch - 1],\n",
    "            validation_loss_list[epoch - 1],\n",
    "            f1_score_list[epoch - 1],\n",
    "            accuracy_list[epoch - 1],\n",
    "            precision_list[epoch - 1]\n",
    "        ]\n",
    "    \n",
    "        # Compare with previous epoch results\n",
    "        if previous_results is not None:\n",
    "            if training_loss_list[epoch - 1] < previous_results['loss_train_avg']:\n",
    "                row[1] = '\\033[92m' + str(row[1]) + '\\033[0m'  # Highlight in green\n",
    "            if training_loss_list[epoch - 1] > previous_results['loss_train_avg']:\n",
    "                row[1] = '\\033[91m' + str(row[1]) + '\\033[0m'  # Highlight in red\n",
    "            if validation_loss_list[epoch - 1] < previous_results['val_loss']:\n",
    "                row[2] = '\\033[92m' + str(row[2]) + '\\033[0m'  # Highlight in green\n",
    "            if validation_loss_list[epoch - 1] > previous_results['val_loss']:\n",
    "                row[2] = '\\033[91m' + str(row[2]) + '\\033[0m'  # Highlight in red\n",
    "            if f1_score_list[epoch - 1] > previous_results['val_f1']:\n",
    "                row[3] = '\\033[92m' + str(row[3]) + '\\033[0m'  # Highlight in green\n",
    "            if f1_score_list[epoch - 1] < previous_results['val_f1']:\n",
    "                row[3] = '\\033[91m' + str(row[3]) + '\\033[0m'  # Highlight in red\n",
    "            if accuracy_list[epoch - 1] > previous_results['val_f1']:\n",
    "                row[4] = '\\033[92m' + str(row[3]) + '\\033[0m'  # Highlight in green\n",
    "            if accuracy_list[epoch - 1] < previous_results['val_f1']:\n",
    "                row[4] = '\\033[91m' + str(row[3]) + '\\033[0m'  # Highlight in red\n",
    "            if precision_list[epoch - 1] > previous_results['val_f1']:\n",
    "                row[5] = '\\033[92m' + str(row[3]) + '\\033[0m'  # Highlight in green\n",
    "            if precision_list[epoch - 1] < previous_results['val_f1']:\n",
    "                row[5] = '\\033[91m' + str(row[3]) + '\\033[0m'  # Highlight in red\n",
    "    \n",
    "        metrics_table.append(row)\n",
    "        previous_results = {\n",
    "            'loss_train_avg': training_loss_list[epoch - 1],\n",
    "            'val_loss': validation_loss_list[epoch - 1],\n",
    "            'val_f1': f1_score_list[epoch - 1]\n",
    "        }\n",
    "    \n",
    "    # Calculate total training time in minutes\n",
    "    total_time_minutes = total_training_time / 60\n",
    "    \n",
    "    # Calculate total precision\n",
    "    total_precision = precision_list[-1]\n",
    "    \n",
    "    # Add total training time and total precision rows to the table\n",
    "    metrics_table.append(['Total Training Time', '', '', '', '', total_training_time])\n",
    "    metrics_table.append(['Final Precision', '', '', '', '', total_precision])\n",
    "    metrics_table.append(['Total Time (minutes)', '', '', '', '', total_time_minutes])\n",
    "    \n",
    "    # Print the table\n",
    "    print(tabulate(metrics_table, headers='firstrow'))\n",
    "\n",
    "    return training_loss_list, validation_loss_list, accuracy_list, precision_list, f1_score_list\n",
    "\n",
    "default_args = {\n",
    "    \"output_dir\": \"tmp\",\n",
    "    \"evaluation_strategy\": \"steps\",\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"log_level\": \"error\",\n",
    "    \"report_to\": \"none\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9785608-cd5e-4432-9d68-68d90c4a0a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/home/z123010/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6301297610349bf8e4feae0216de574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = data_imdb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8793b8bc-43bd-4d43-a17e-abf0174eb200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label_dict and assign the number of labels\n",
    "label_dict = {label: index for index, label in enumerate(df['label'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2707709e-9e1b-460f-9386-6d9e999f2d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33553</th>\n",
       "      <td>Forget what I said about Emeril. Rachael Ray i...</td>\n",
       "      <td>0</td>\n",
       "      <td>bad</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9427</th>\n",
       "      <td>Former private eye-turned-security guard ditch...</td>\n",
       "      <td>0</td>\n",
       "      <td>bad</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Mann photographs the Alberta Rocky Mountains i...</td>\n",
       "      <td>0</td>\n",
       "      <td>bad</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12447</th>\n",
       "      <td>Simply put: the movie is boring. Cliché upon c...</td>\n",
       "      <td>0</td>\n",
       "      <td>bad</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39489</th>\n",
       "      <td>Now being a fan of sci fi, the trailer for thi...</td>\n",
       "      <td>1</td>\n",
       "      <td>good</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42724</th>\n",
       "      <td>In 'Hoot' Logan Lerman plays Roy Eberhardt, th...</td>\n",
       "      <td>1</td>\n",
       "      <td>good</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10822</th>\n",
       "      <td>This is the worst film I have ever seen.I was ...</td>\n",
       "      <td>0</td>\n",
       "      <td>bad</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49498</th>\n",
       "      <td>I think that Toy Soldiers is an excellent movi...</td>\n",
       "      <td>1</td>\n",
       "      <td>good</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4144</th>\n",
       "      <td>I think Micheal Ironsides acting career must b...</td>\n",
       "      <td>0</td>\n",
       "      <td>bad</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36958</th>\n",
       "      <td>This was a disgrace to the game FarCry i had m...</td>\n",
       "      <td>0</td>\n",
       "      <td>bad</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label sentiment   \n",
       "33553  Forget what I said about Emeril. Rachael Ray i...      0       bad  \\\n",
       "9427   Former private eye-turned-security guard ditch...      0       bad   \n",
       "199    Mann photographs the Alberta Rocky Mountains i...      0       bad   \n",
       "12447  Simply put: the movie is boring. Cliché upon c...      0       bad   \n",
       "39489  Now being a fan of sci fi, the trailer for thi...      1      good   \n",
       "42724  In 'Hoot' Logan Lerman plays Roy Eberhardt, th...      1      good   \n",
       "10822  This is the worst film I have ever seen.I was ...      0       bad   \n",
       "49498  I think that Toy Soldiers is an excellent movi...      1      good   \n",
       "4144   I think Micheal Ironsides acting career must b...      0       bad   \n",
       "36958  This was a disgrace to the game FarCry i had m...      0       bad   \n",
       "\n",
       "      data_type  \n",
       "33553      test  \n",
       "9427      train  \n",
       "199       train  \n",
       "12447     train  \n",
       "39489      test  \n",
       "42724      test  \n",
       "10822     train  \n",
       "49498      test  \n",
       "4144      train  \n",
       "36958      test  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(n=10, random_state=42)  # Generate 10 random rows from df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc596d9c-5808-4f39-a59e-6ed36d8927dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            text  label  data_type\n",
       "sentiment                         \n",
       "bad        25000  25000      25000\n",
       "good       25000  25000      25000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['sentiment']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ab759d8-d194-4afb-8cd1-c4997224b920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            text  label  sentiment\n",
       "data_type                         \n",
       "test       25000  25000      25000\n",
       "train      25000  25000      25000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['data_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "731e5a17-8ab7-4d19-a012-05eeabab1d90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load BERT tokenizer\n",
    "pretrained_path = 'bert-base-uncased'  # Replace with the path to the pretrained BERT model\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    do_lower_case=True\n",
    ")\n",
    "\n",
    "encoded_data_train_text = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='train'].text.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding='longest',\n",
    "    max_length=512,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "input_ids_train = encoded_data_train_text['input_ids']\n",
    "attention_masks_train = encoded_data_train_text['attention_mask']\n",
    "\n",
    "labels_train = torch.tensor(df[df.data_type=='train'].label.values)\n",
    "\n",
    "encoded_data_test_text = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='test'].text.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding='longest',\n",
    "    max_length=512,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "input_ids_test = encoded_data_test_text['input_ids']\n",
    "attention_masks_test = encoded_data_test_text['attention_mask']\n",
    "\n",
    "labels_test = torch.tensor(df[df.data_type=='test'].label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42125069-fd5d-49c0-8032-2be61cb2a6d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_test = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n",
    "len(dataset_train), len(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a2f7e02-8423-4787-994e-d599ab86b123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Model, GPT2Config\n",
    "\n",
    "num_classes = 6\n",
    "\n",
    "class SentimentModel(nn.Module):\n",
    "    def __init__(self, pretrained_gpt_path):\n",
    "        super(SentimentModel, self).__init__()\n",
    "        \n",
    "        gpt_config = GPT2Config.from_pretrained(            \n",
    "            pretrained_gpt_path,\n",
    "            hidden_dropout_prob=0.3,\n",
    "            attention_probs_dropout_prob=0.1)\n",
    "        self.gpt = GPT2Model.from_pretrained(pretrained_gpt_path, config=gpt_config)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(gpt_config.hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        gpt_outputs = self.gpt(input_ids, attention_mask=attention_mask)[0]\n",
    "        gpt_last_hidden_state = self.dropout(gpt_outputs[:, -1, :])  # Use the last hidden state\n",
    "        \n",
    "        outputs = torch.cat((gpt_last_hidden_state,), dim=1)\n",
    "        \n",
    "        logits = self.fc(outputs)\n",
    "        outputs = nn.functional.softmax(logits, dim=1)\n",
    "        \n",
    "        if labels is not None:\n",
    "            loss = nn.CrossEntropyLoss()(logits.view(-1, num_classes), labels.view(-1))\n",
    "            return loss, outputs, labels\n",
    "        else:\n",
    "            return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d131f86-ee7e-49b3-a104-a61841bb78d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type bert to instantiate a model of type gpt2. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing GPT2Model: ['bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.pooler.dense.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.embeddings.word_embeddings.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'cls.predictions.bias', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.6.attention.self.key.bias', 'cls.predictions.transform.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'cls.predictions.transform.LayerNorm.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'cls.seq_relationship.bias', 'bert.pooler.dense.weight', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'cls.seq_relationship.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.5.output.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.embeddings.position_embeddings.weight', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'cls.predictions.transform.dense.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.4.output.dense.weight']\n",
      "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of GPT2Model were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['h.8.attn.c_attn.bias', 'h.9.attn.c_proj.weight', 'h.9.mlp.c_fc.weight', 'ln_f.bias', 'h.11.ln_2.bias', 'h.0.mlp.c_proj.bias', 'h.11.ln_2.weight', 'h.3.ln_1.bias', 'h.4.ln_1.weight', 'h.11.mlp.c_fc.weight', 'h.11.mlp.c_proj.weight', 'h.10.mlp.c_fc.bias', 'h.8.ln_1.weight', 'h.1.ln_1.weight', 'h.2.attn.c_proj.bias', 'h.3.ln_2.bias', 'h.0.mlp.c_fc.weight', 'h.5.attn.c_attn.bias', 'h.2.ln_2.bias', 'h.10.mlp.c_fc.weight', 'h.11.attn.c_attn.bias', 'h.2.mlp.c_fc.bias', 'h.4.mlp.c_fc.bias', 'h.6.attn.c_proj.weight', 'h.4.attn.c_proj.weight', 'h.7.ln_2.bias', 'h.4.ln_2.bias', 'h.6.ln_2.weight', 'h.7.ln_1.bias', 'h.9.ln_1.weight', 'h.3.mlp.c_fc.weight', 'h.8.attn.c_proj.weight', 'h.7.attn.c_proj.bias', 'h.1.ln_1.bias', 'h.6.mlp.c_fc.weight', 'h.1.mlp.c_fc.weight', 'h.0.mlp.c_proj.weight', 'h.6.ln_1.bias', 'h.11.attn.c_proj.weight', 'h.5.ln_2.bias', 'h.9.ln_2.bias', 'h.10.ln_2.bias', 'h.1.attn.c_attn.bias', 'h.11.ln_1.bias', 'h.8.ln_2.bias', 'h.1.ln_2.weight', 'h.7.attn.c_attn.bias', 'h.4.attn.c_attn.weight', 'wte.weight', 'h.11.attn.c_attn.weight', 'h.6.attn.c_attn.bias', 'h.0.attn.c_proj.weight', 'h.8.mlp.c_fc.weight', 'h.2.attn.c_attn.weight', 'h.7.ln_1.weight', 'h.7.mlp.c_fc.bias', 'ln_f.weight', 'h.7.mlp.c_proj.bias', 'h.2.attn.c_proj.weight', 'h.11.mlp.c_proj.bias', 'h.7.mlp.c_proj.weight', 'h.10.attn.c_attn.weight', 'h.10.attn.c_proj.bias', 'h.0.ln_1.weight', 'h.1.attn.c_proj.bias', 'h.4.mlp.c_fc.weight', 'h.10.mlp.c_proj.bias', 'h.8.attn.c_proj.bias', 'h.5.ln_1.weight', 'h.10.ln_1.bias', 'h.8.attn.c_attn.weight', 'h.0.ln_2.bias', 'h.11.mlp.c_fc.bias', 'h.9.mlp.c_fc.bias', 'h.2.mlp.c_fc.weight', 'h.9.attn.c_attn.weight', 'h.3.attn.c_proj.weight', 'h.3.attn.c_attn.bias', 'h.3.ln_2.weight', 'h.1.attn.c_proj.weight', 'h.6.ln_1.weight', 'h.8.ln_2.weight', 'h.2.mlp.c_proj.bias', 'h.0.ln_1.bias', 'h.8.ln_1.bias', 'h.1.attn.c_attn.weight', 'h.5.mlp.c_fc.bias', 'h.5.attn.c_attn.weight', 'h.0.ln_2.weight', 'h.5.mlp.c_fc.weight', 'h.1.ln_2.bias', 'h.4.mlp.c_proj.bias', 'h.6.mlp.c_fc.bias', 'h.7.ln_2.weight', 'h.2.ln_1.weight', 'h.6.mlp.c_proj.bias', 'h.7.attn.c_attn.weight', 'h.8.mlp.c_fc.bias', 'h.0.attn.c_proj.bias', 'h.0.attn.c_attn.bias', 'h.3.attn.c_attn.weight', 'h.9.mlp.c_proj.weight', 'h.4.attn.c_proj.bias', 'h.10.ln_1.weight', 'h.7.mlp.c_fc.weight', 'h.9.ln_2.weight', 'h.5.attn.c_proj.bias', 'h.10.attn.c_proj.weight', 'h.8.mlp.c_proj.bias', 'h.3.ln_1.weight', 'h.4.attn.c_attn.bias', 'h.2.ln_1.bias', 'h.11.attn.c_proj.bias', 'h.6.attn.c_proj.bias', 'h.9.attn.c_attn.bias', 'h.3.mlp.c_fc.bias', 'h.5.mlp.c_proj.bias', 'h.2.attn.c_attn.bias', 'h.10.ln_2.weight', 'wpe.weight', 'h.9.attn.c_proj.bias', 'h.1.mlp.c_proj.weight', 'h.4.ln_1.bias', 'h.5.ln_2.weight', 'h.4.ln_2.weight', 'h.0.mlp.c_fc.bias', 'h.9.ln_1.bias', 'h.11.ln_1.weight', 'h.2.mlp.c_proj.weight', 'h.6.mlp.c_proj.weight', 'h.5.ln_1.bias', 'h.0.attn.c_attn.weight', 'h.3.mlp.c_proj.bias', 'h.8.mlp.c_proj.weight', 'h.5.mlp.c_proj.weight', 'h.6.attn.c_attn.weight', 'h.7.attn.c_proj.weight', 'h.1.mlp.c_proj.bias', 'h.1.mlp.c_fc.bias', 'h.2.ln_2.weight', 'h.10.mlp.c_proj.weight', 'h.4.mlp.c_proj.weight', 'h.3.mlp.c_proj.weight', 'h.5.attn.c_proj.weight', 'h.3.attn.c_proj.bias', 'h.10.attn.c_attn.bias', 'h.6.ln_2.bias', 'h.9.mlp.c_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Create model instance\n",
    "model = SentimentModel('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "834c8c87-40a1-49c6-8e7b-307b931aec01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentModel(\n",
       "  (gpt): GPT2Model(\n",
       "    (wte): Embedding(30522, 768)\n",
       "    (wpe): Embedding(512, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c610d351-0be0-4899-bf58-2397193b5ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, logging\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    **default_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfb9e671-0f31-4a58-bf72-8c13ac04e6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "# Set the batch size and create data loaders for training and validation sets\n",
    "\n",
    "batch_size = 10 #32\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train,\n",
    "    sampler=RandomSampler(dataset_train),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "dataloader_test = DataLoader(\n",
    "    dataset_test,\n",
    "    sampler=RandomSampler(dataset_test),\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3bc14be-49bc-4b42-be70-17412957cdaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z123010/anaconda3/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=1e-7,\n",
    "    eps=1e-8,\n",
    "    weight_decay=0.01\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "epochs = 50\n",
    "patience = 10\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=len(dataloader_train) * epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27c174c9-8e92-42fa-9d81-54260c58251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val) #sets the seed value for the Python built-in pseudo-random generator.\n",
    "np.random.seed(seed_val) #sets the seed value for the NumPy pseudo-random number generator.\n",
    "torch.manual_seed(seed_val) #sets the seed value for the random number generator in PyTorch on the CPU.\n",
    "torch.cuda.manual_seed_all(seed_val) #sets the seed value for the random number generator in PyTorch on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3a28ec5-87fe-4bdf-b6a1-05bf8b6f6b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6959b8b0-8529-4b6f-9ca8-972f7003d475",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "model=model,\n",
    "args=training_args,\n",
    "train_dataset=dataset_train,\n",
    "eval_dataset=dataset_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd76f9c-2fac-4227-916b-83e6a350f732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c52b0ee00ec404093d70d35a3869ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 0.7286251679897309\n",
      "Validation loss: 0.6619056247591972\n",
      "F1 Score (weighted): 0.6028050741358807\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b03544cbc15490a815f63e182f6dbe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model(trainer, dataloader_train, dataloader_test, epochs, patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c363e7-c757-4bb6-bb2c-d19a126fd165",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "k = 10  # Number of folds\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Convert the multilabel indicator target to numpy array\n",
    "targets = dataset_train.tensors[1].numpy()\n",
    "\n",
    "# Initialize lists to store the evaluation metrics for each fold\n",
    "training_loss_lists = []\n",
    "validation_loss_lists = []\n",
    "accuracy_lists = []\n",
    "precision_lists = []\n",
    "f1_score_lists = []\n",
    "\n",
    "# Perform multilabel k-fold cross-validation\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(targets)):\n",
    "    print(f\"\\nFold {fold+1}\")\n",
    "    train_sampler = SubsetRandomSampler(train_index)\n",
    "    val_sampler = SubsetRandomSampler(val_index)\n",
    "\n",
    "    # Create data loaders for training and validation\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size=batch_size, sampler=train_sampler)\n",
    "    dataloader_vals = DataLoader(dataset_train, batch_size=batch_size, sampler=val_sampler)\n",
    "\n",
    "    # Initialize metrics lists for this fold\n",
    "    fold_training_loss_list = []\n",
    "    fold_validation_loss_list = []\n",
    "    fold_accuracy_list = []\n",
    "    fold_precision_list = []\n",
    "    fold_f1_score_list = []\n",
    "\n",
    "    try:\n",
    "        fold_training_loss_list, fold_validation_loss_list, fold_accuracy_list, fold_precision_list, fold_f1_score_list = \\\n",
    "        train_model(trainer, dataloader_train, dataloader_vals, epochs, patience)\n",
    "    except Exception as e:\n",
    "        print(f\"Continue to the next fold {fold+1}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "    # Append the metrics for this fold to the overall lists\n",
    "    training_loss_lists.append(fold_training_loss_list)\n",
    "    validation_loss_lists.append(fold_validation_loss_list)\n",
    "    accuracy_lists.append(fold_accuracy_list)\n",
    "    precision_lists.append(fold_precision_list)\n",
    "    f1_score_lists.append(fold_f1_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24429e4-743b-4a11-80d6-5e2fadaabc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"Models/finetuned_gpt_bert_imdb_ft_epoch24.model\", \n",
    "        map_location = torch.device('cuda')\n",
    "    )\n",
    ")\n",
    "_, predictions, true_vals = evaluate(dataloader_test)\n",
    "accuracy_per_class(predictions, true_vals, label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba4c1e0-c1c8-49c0-9e52-d9df797db69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(trainer, dataloader_train, dataloader_test, epochs, patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85b3abe-d7ee-46ec-ba19-fe472176c970",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "k = 10  # Number of folds\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Convert the multilabel indicator target to numpy array\n",
    "targets = dataset_train.tensors[1].numpy()\n",
    "\n",
    "# Initialize lists to store the evaluation metrics for each fold\n",
    "training_loss_lists = []\n",
    "validation_loss_lists = []\n",
    "accuracy_lists = []\n",
    "precision_lists = []\n",
    "f1_score_lists = []\n",
    "\n",
    "# Perform multilabel k-fold cross-validation\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(targets)):\n",
    "    print(f\"\\nFold {fold+1}\")\n",
    "    train_sampler = SubsetRandomSampler(train_index)\n",
    "    val_sampler = SubsetRandomSampler(val_index)\n",
    "\n",
    "    # Create data loaders for training and validation\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size=batch_size, sampler=train_sampler)\n",
    "    dataloader_vals = DataLoader(dataset_train, batch_size=batch_size, sampler=val_sampler)\n",
    "\n",
    "    # Initialize metrics lists for this fold\n",
    "    fold_training_loss_list = []\n",
    "    fold_validation_loss_list = []\n",
    "    fold_accuracy_list = []\n",
    "    fold_precision_list = []\n",
    "    fold_f1_score_list = []\n",
    "\n",
    "    try:\n",
    "        fold_training_loss_list, fold_validation_loss_list, fold_accuracy_list, fold_precision_list, fold_f1_score_list = \\\n",
    "        train_model(trainer, dataloader_train, dataloader_vals, epochs, patience)\n",
    "    except Exception as e:\n",
    "        print(f\"Continue to the next fold {fold+1}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "    # Append the metrics for this fold to the overall lists\n",
    "    training_loss_lists.append(fold_training_loss_list)\n",
    "    validation_loss_lists.append(fold_validation_loss_list)\n",
    "    accuracy_lists.append(fold_accuracy_list)\n",
    "    precision_lists.append(fold_precision_list)\n",
    "    f1_score_lists.append(fold_f1_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89692d11-fb56-4063-b9c0-e7971924366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(trainer, dataloader_train, dataloader_test, epochs, patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00950c82-5502-4c7b-9bd8-49b9588fd80e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
