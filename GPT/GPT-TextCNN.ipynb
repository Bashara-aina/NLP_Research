{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5bf24e9-d40b-45ad-9330-405d0097fe2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-27 18:22:49.852245: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-27 18:22:49.876695: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-27 18:22:50.307840: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm  # For displaying progress bars\n",
    "from datasets import load_dataset  # For loading datasets\n",
    "from sklearn.model_selection import train_test_split  # For splitting the dataset\n",
    "from transformers import BertTokenizer  # For tokenizing text\n",
    "from torch.utils.data import TensorDataset  # For creating Tensor datasets\n",
    "import time  # For measuring time\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score  # For evaluation metrics\n",
    "from sklearn.exceptions import UndefinedMetricWarning  # For handling metric warnings\n",
    "import matplotlib.pyplot as plt  # For plotting\n",
    "from tabulate import tabulate  # For tabular data formatting\n",
    "import random  # For randomization\n",
    "import numpy as np  # For numerical operations\n",
    "from transformers import (\n",
    "    BertTokenizer,  # Tokenizer for BERT models\n",
    "    AdamW,  # Optimizer for BERT models\n",
    "    get_linear_schedule_with_warmup,  # Learning rate scheduler for BERT models\n",
    "    BertConfig,  # Configuration for BERT models\n",
    "    BertForSequenceClassification  # BERT model for sequence classification tasks\n",
    ")\n",
    "from torch.utils.data import (\n",
    "    DataLoader,  # Data loader for creating batches\n",
    "    RandomSampler,  # Sampler for random sampling of data\n",
    "    SequentialSampler  # Sampler for sequential sampling of data\n",
    ")\n",
    "from sklearn.metrics import f1_score  # For computing the F1 score\n",
    "\n",
    "# 1. Torch: PyTorch library for deep learning\n",
    "# 2. Pandas: Library for data manipulation and analysis\n",
    "# 3. tqdm: Library for displaying progress bars\n",
    "# 4. datasets: Library for working with datasets\n",
    "# 5. train_test_split: Function for splitting the dataset into training and validation sets\n",
    "# 6. BertTokenizer: Tokenizer for BERT models\n",
    "# 7. TensorDataset: Dataset class for creating PyTorch Tensor datasets\n",
    "# 8. time: Module for measuring time\n",
    "# 9. accuracy_score, precision_score, f1_score: Evaluation metrics for classification tasks\n",
    "# 10. UndefinedMetricWarning: Warning for undefined metric values\n",
    "# 11. matplotlib.pyplot: Plotting library\n",
    "# 12. tabulate: Library for formatting tabular data\n",
    "# 13. random: Module for randomization\n",
    "# 14. numpy: Library for numerical operations\n",
    "# 15. AdamW: Optimizer for BERT models\n",
    "# 16. get_linear_schedule_with_warmup: Learning rate scheduler for BERT models\n",
    "# 17. BertConfig: Configuration for BERT models\n",
    "# 18. BertForSequenceClassification: BERT model for sequence classification tasks\n",
    "# 19. DataLoader: Data loader for creating batches\n",
    "# 20. RandomSampler: Sampler for random sampling of data\n",
    "# 21. SequentialSampler: Sampler for sequential sampling of data\n",
    "# 22. f1_score: Function for computing the F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "207f2073-3da6-4185-917f-e8b3694617ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datacleaning_amazon():\n",
    "    dataset = load_dataset(\"amazon_us_reviews\", \"Apparel_v1_00\")\n",
    "    train_data = dataset['train']\n",
    "\n",
    "    # Limit the dataset to the first 10,000 rows\n",
    "    train_data = train_data.select(range(10000))\n",
    "\n",
    "    df = train_data.to_pandas()  # Convert the dataset to a Pandas DataFrame\n",
    "    df = df[['customer_id', 'review_headline', 'review_body', 'star_rating']]  # Select specific columns\n",
    "    df.columns = ['customer_id', 'review_headline', 'review_body', 'star_rating']  # Rename the selected columns\n",
    "    df.set_index('customer_id', inplace=True)\n",
    "\n",
    "    df['sentiment'] = df['star_rating'].map({5: 'good', 4: 'good', 3: 'neutral', 2: 'bad', 1: 'bad'})\n",
    "\n",
    "    possible_labels = df.sentiment.unique()  # Get unique category labels from the DataFrame column 'category'\n",
    "\n",
    "    label_dict = {}  # Create a dictionary to map each possible label to a unique index\n",
    "    for index, possible_label in enumerate(possible_labels):\n",
    "        label_dict[possible_label] = index\n",
    "\n",
    "    df['label'] = df.sentiment.replace(label_dict)\n",
    "\n",
    "    # Split the dataset into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        df.index.values,\n",
    "        df.label.values,\n",
    "        test_size=0.15,\n",
    "        random_state=17,\n",
    "        stratify=df.label.values\n",
    "    )\n",
    "\n",
    "    df['data_type'] = ['not_set'] * df.shape[0]  # Set a new column 'data_type' for later data split\n",
    "\n",
    "    # Set the 'data_type' column of the dataframe for training and validation data\n",
    "    df.loc[X_train, 'data_type'] = 'train'\n",
    "    df.loc[X_val, 'data_type'] = 'val'\n",
    "\n",
    "    return df\n",
    "\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten() #This line finds the index with the highest probability in each prediction, effectively giving the predicted class for each input.\n",
    "    labels_flat = labels.flatten()  #This line flattens the labels array into a 1D vector, as required by the f1_score function.\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted') #This line computes the F1 score using the true labels and the predicted labels, with the weighted averaging scheme. The result is returned.\n",
    "\n",
    "def accuracy_per_class(preds, labels):\n",
    "    # Create a dictionary with keys and values reversed for easy lookup.\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    # Get the predicted labels and flatten them.\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    \n",
    "    # Get the actual labels and flatten them.\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    # Iterate over the unique labels in the actual labels.\n",
    "    for label in np.unique(labels_flat):\n",
    "        # Get the predicted labels for this class.\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        \n",
    "        # Get the actual labels for this class.\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        \n",
    "        # Print the class name, accuracy numerator and denominator.\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n",
    "\n",
    "#This code evaluates the performance of a trained model on a validation dataset by computing its loss and predictions for each batch in the dataset.\n",
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval() # setting the model to evaluation mode to disable dropout and other regularization techniques that are useful during training but not during evaluation.\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "    \n",
    "        batch = tuple(b.to(device) for b in batch) # moving the input batch to the GPU for faster computation.\n",
    "   \n",
    "        #  creating a dictionary of inputs that will be passed to the model. The input IDs and attention mask are for the BERT model, and the labels are the true labels for each input.\n",
    "        inputs = {'input_ids':  \tbatch[0],\n",
    "                'attention_mask': batch[1],\n",
    "                'labels':     \tbatch[2],\n",
    "                } \n",
    "\n",
    "        with torch.no_grad():   \n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val)\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "       \t \n",
    "    return loss_val_avg, predictions, true_vals\n",
    "\n",
    "def train_model(model, dataloader_train, dataloader_val, epochs):\n",
    "    total_training_time = 0\n",
    "    \n",
    "    training_loss_list = []\n",
    "    validation_loss_list = []\n",
    "    accuracy_list = []\n",
    "    precision_list = []\n",
    "    f1_score_list = []\n",
    "    \n",
    "    previous_results = None  # Store previous epoch results\n",
    "    \n",
    "    for epoch in tqdm(range(1, epochs + 1)):\n",
    "        start_time = time.time()\n",
    "    \n",
    "        model.train()\n",
    "        loss_train_total = 0\n",
    "    \n",
    "        progress_bar = tqdm(dataloader_train,\n",
    "                            desc='Epoch {:1d}'.format(epoch),\n",
    "                            leave=False,\n",
    "                            disable=False)\n",
    "        for batch in progress_bar:\n",
    "            model.zero_grad()\n",
    "            batch = tuple(b.to(device) for b in batch)\n",
    "            inputs = {\n",
    "                'input_ids': batch[0],\n",
    "                'attention_mask': batch[1],\n",
    "                'labels': batch[2],\n",
    "            }\n",
    "            output = model(**inputs)\n",
    "            loss = output[0]\n",
    "            loss_train_total += loss.item()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item() / len(batch))})\n",
    "    \n",
    "        end_time = time.time()\n",
    "        epoch_training_time = end_time - start_time\n",
    "        total_training_time += epoch_training_time\n",
    "    \n",
    "        torch.save(model.state_dict(), f'Models/finetuned_gpt_ft_epoch{epoch}.model')\n",
    "    \n",
    "        tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "        loss_train_avg = loss_train_total / len(dataloader_train)\n",
    "        tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "        val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
    "    \n",
    "        # Convert predictions to discrete labels\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "        val_f1 = f1_score(true_vals, predictions, average='weighted')\n",
    "        tqdm.write(f'Validation loss: {val_loss}')\n",
    "        tqdm.write(f'F1 Score (weighted): {val_f1}')\n",
    "    \n",
    "        val_accuracy = accuracy_score(true_vals, predictions)\n",
    "        val_precision = precision_score(true_vals, predictions, average='weighted', zero_division=1)\n",
    "    \n",
    "        # Compute and store metrics\n",
    "        training_loss_list.append(loss_train_avg)\n",
    "        validation_loss_list.append(val_loss)\n",
    "        f1_score_list.append(val_f1)\n",
    "        accuracy_list.append(val_accuracy)\n",
    "        precision_list.append(val_precision)\n",
    "    \n",
    "        # Check if there are previous results to compare with\n",
    "        if previous_results is not None:\n",
    "            if loss_train_avg > previous_results['loss_train_avg']:\n",
    "                percentage_increase = ((loss_train_avg - previous_results['loss_train_avg']) / previous_results['loss_train_avg']) * 100\n",
    "                tqdm.write('\\033[91m' + f'{round(percentage_increase, 2)}% Training loss increased compared to the previous epoch' + '\\033[0m')\n",
    "            if loss_train_avg < previous_results['loss_train_avg']:\n",
    "                percentage_decrease = ((previous_results['loss_train_avg'] - loss_train_avg) / previous_results['loss_train_avg']) * 100\n",
    "                tqdm.write('\\033[92m' + f'{round(percentage_decrease, 2)}% Training loss decreased compared to the previous epoch' + '\\033[0m')\n",
    "            if val_loss > previous_results['val_loss']:\n",
    "                percentage_increase = ((val_loss - previous_results['val_loss']) / previous_results['val_loss']) * 100\n",
    "                tqdm.write('\\033[91m' + f'{round(percentage_increase, 2)}% Validation loss increased compared to the previous epoch' + '\\033[0m')\n",
    "            if val_loss < previous_results['val_loss']:\n",
    "                percentage_decrease = ((previous_results['val_loss'] - val_loss) / previous_results['val_loss']) * 100\n",
    "                tqdm.write('\\033[92m' + f'{round(percentage_decrease, 2)}% Validation loss decreased compared to the previous epoch' + '\\033[0m')\n",
    "            if val_f1 < previous_results['val_f1']:\n",
    "                percentage_decrease = ((previous_results['val_f1'] - val_f1) / previous_results['val_f1']) * 100\n",
    "                tqdm.write('\\033[91m' + f'{round(percentage_decrease, 2)}% F1 Score decreased compared to the previous epoch' + '\\033[0m')\n",
    "            if val_f1 > previous_results['val_f1']:\n",
    "                percentage_increase = ((val_f1 - previous_results['val_f1']) / previous_results['val_f1']) * 100\n",
    "                tqdm.write('\\033[92m' + f'{round(percentage_increase, 2)}% F1 Score increased compared to the previous epoch' + '\\033[0m')\n",
    "    \n",
    "        # Store current results as previous results for the next epoch\n",
    "        previous_results = {\n",
    "            'loss_train_avg': loss_train_avg,\n",
    "            'val_loss': val_loss,\n",
    "            'val_f1': val_f1\n",
    "        }\n",
    "    \n",
    "    total_time_minutes = total_training_time / 60\n",
    "    tqdm.write(f'\\nTotal training time: {total_time_minutes} minutes')\n",
    "    \n",
    "    final_accuracy = accuracy_list[-1]\n",
    "    final_precision = precision_list[-1]\n",
    "    tqdm.write(f'Final Accuracy: {final_accuracy}')\n",
    "    tqdm.write(f'Final Precision: {final_precision}')\n",
    "    \n",
    "    # Create a single subplot\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    # Plot training loss\n",
    "    ax.plot(range(1, epochs + 1), training_loss_list, label='Training Loss')\n",
    "    \n",
    "    # Plot validation loss\n",
    "    ax.plot(range(1, epochs + 1), validation_loss_list, label='Validation Loss')\n",
    "    \n",
    "    # Plot F1-score\n",
    "    ax.plot(range(1, epochs + 1), f1_score_list, label='F1 Score')\n",
    "    \n",
    "    # Set labels and title\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Metric Value')\n",
    "    ax.set_title('Training Loss, Validation Loss, and F1 Score')\n",
    "    \n",
    "    # Set legend\n",
    "    ax.legend()\n",
    "    \n",
    "    # Show the combined plot\n",
    "    plt.show()\n",
    "\n",
    "        # Create the metrics table\n",
    "    metrics_table = [\n",
    "        ['Epoch', 'Training Loss', 'Validation Loss', 'F1 Score', 'Accuracy', 'Precision'],\n",
    "    ]\n",
    "    previous_results = None\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        row = [\n",
    "            epoch,\n",
    "            training_loss_list[epoch - 1],\n",
    "            validation_loss_list[epoch - 1],\n",
    "            f1_score_list[epoch - 1],\n",
    "            accuracy_list[epoch - 1],\n",
    "            precision_list[epoch - 1]\n",
    "        ]\n",
    "    \n",
    "        # Compare with previous epoch results\n",
    "        if previous_results is not None:\n",
    "            if training_loss_list[epoch - 1] < previous_results['loss_train_avg']:\n",
    "                row[1] = '\\033[92m' + str(row[1]) + '\\033[0m'  # Highlight in green\n",
    "            if training_loss_list[epoch - 1] > previous_results['loss_train_avg']:\n",
    "                row[1] = '\\033[91m' + str(row[1]) + '\\033[0m'  # Highlight in red\n",
    "            if validation_loss_list[epoch - 1] < previous_results['val_loss']:\n",
    "                row[2] = '\\033[92m' + str(row[2]) + '\\033[0m'  # Highlight in green\n",
    "            if validation_loss_list[epoch - 1] > previous_results['val_loss']:\n",
    "                row[2] = '\\033[91m' + str(row[2]) + '\\033[0m'  # Highlight in red\n",
    "            if f1_score_list[epoch - 1] > previous_results['val_f1']:\n",
    "                row[3] = '\\033[92m' + str(row[3]) + '\\033[0m'  # Highlight in green\n",
    "            if f1_score_list[epoch - 1] < previous_results['val_f1']:\n",
    "                row[3] = '\\033[91m' + str(row[3]) + '\\033[0m'  # Highlight in red\n",
    "    \n",
    "        metrics_table.append(row)\n",
    "        previous_results = {\n",
    "            'loss_train_avg': training_loss_list[epoch - 1],\n",
    "            'val_loss': validation_loss_list[epoch - 1],\n",
    "            'val_f1': f1_score_list[epoch - 1]\n",
    "        }\n",
    "    \n",
    "    # Calculate total training time in minutes\n",
    "    total_time_minutes = total_training_time / 60\n",
    "    \n",
    "    # Calculate total precision\n",
    "    total_precision = precision_list[-1]\n",
    "    \n",
    "    # Add total training time and total precision rows to the table\n",
    "    metrics_table.append(['Total Training Time', '', '', '', '', total_training_time])\n",
    "    metrics_table.append(['Final Precision', '', '', '', '', total_precision])\n",
    "    metrics_table.append(['Total Time (minutes)', '', '', '', '', total_time_minutes])\n",
    "    \n",
    "    # Print the table\n",
    "    print(tabulate(metrics_table, headers='firstrow'))\n",
    "\n",
    "default_args = {\n",
    "    \"output_dir\": \"tmp\",\n",
    "    \"evaluation_strategy\": \"steps\",\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"log_level\": \"error\",\n",
    "    \"report_to\": \"none\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9785608-cd5e-4432-9d68-68d90c4a0a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/z123010/.cache/huggingface/modules/datasets_modules/datasets/amazon_us_reviews/17b2481be59723469538adeb8fd0a68b0ba363bbbdd71090e72c325ee6c7e563 (last modified on Tue May 23 19:43:32 2023) since it couldn't be found locally at amazon_us_reviews., or remotely on the Hugging Face Hub.\n",
      "Found cached dataset amazon_us_reviews (/home/z123010/.cache/huggingface/datasets/amazon_us_reviews/Apparel_v1_00/0.1.0/17b2481be59723469538adeb8fd0a68b0ba363bbbdd71090e72c325ee6c7e563)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a315535ebd594327a889474a6c392a59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = datacleaning_amazon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8793b8bc-43bd-4d43-a17e-abf0174eb200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label_dict and assign the number of labels\n",
    "label_dict = {label: index for index, label in enumerate(df['label'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2707709e-9e1b-460f-9386-6d9e999f2d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39856338</th>\n",
       "      <td>Best No slip socks I've ever owned</td>\n",
       "      <td>Four out of five pairs are perfect. One pair d...</td>\n",
       "      <td>4</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25914116</th>\n",
       "      <td>Four Stars</td>\n",
       "      <td>ok</td>\n",
       "      <td>4</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439146</th>\n",
       "      <td>Three Stars</td>\n",
       "      <td>Expected for the logo to be more original</td>\n",
       "      <td>3</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37398528</th>\n",
       "      <td>Just what I wanted</td>\n",
       "      <td>Just what I wanted - a nice, thin credit card ...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44593047</th>\n",
       "      <td>Three Stars</td>\n",
       "      <td>returned</td>\n",
       "      <td>3</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26403334</th>\n",
       "      <td>I love them.</td>\n",
       "      <td>For the price, these are soft and fit well and...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7158905</th>\n",
       "      <td>absolutely LOVE to cute</td>\n",
       "      <td>Super cute! If you're an alternative chick thi...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47427058</th>\n",
       "      <td>Better than I could have imagined</td>\n",
       "      <td>This wallet is everything they say it is. Afte...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20692814</th>\n",
       "      <td>Very nice !!</td>\n",
       "      <td>A very nice dress, I bought this dress for my ...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17035996</th>\n",
       "      <td>One Star</td>\n",
       "      <td>absolutely not like the picture... dont buy! C...</td>\n",
       "      <td>1</td>\n",
       "      <td>bad</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                review_headline   \n",
       "customer_id                                       \n",
       "39856338     Best No slip socks I've ever owned  \\\n",
       "25914116                             Four Stars   \n",
       "439146                              Three Stars   \n",
       "37398528                     Just what I wanted   \n",
       "44593047                            Three Stars   \n",
       "26403334                           I love them.   \n",
       "7158905                 absolutely LOVE to cute   \n",
       "47427058      Better than I could have imagined   \n",
       "20692814                           Very nice !!   \n",
       "17035996                               One Star   \n",
       "\n",
       "                                                   review_body  star_rating   \n",
       "customer_id                                                                   \n",
       "39856338     Four out of five pairs are perfect. One pair d...            4  \\\n",
       "25914116                                                    ok            4   \n",
       "439146               Expected for the logo to be more original            3   \n",
       "37398528     Just what I wanted - a nice, thin credit card ...            5   \n",
       "44593047                                              returned            3   \n",
       "26403334     For the price, these are soft and fit well and...            5   \n",
       "7158905      Super cute! If you're an alternative chick thi...            5   \n",
       "47427058     This wallet is everything they say it is. Afte...            5   \n",
       "20692814     A very nice dress, I bought this dress for my ...            5   \n",
       "17035996     absolutely not like the picture... dont buy! C...            1   \n",
       "\n",
       "            sentiment  label data_type  \n",
       "customer_id                             \n",
       "39856338         good      0       val  \n",
       "25914116         good      0     train  \n",
       "439146        neutral      1     train  \n",
       "37398528         good      0     train  \n",
       "44593047      neutral      1       val  \n",
       "26403334         good      0     train  \n",
       "7158905          good      0     train  \n",
       "47427058         good      0     train  \n",
       "20692814         good      0     train  \n",
       "17035996          bad      2     train  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(n=10, random_state=42)  # Generate 10 random rows from df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc596d9c-5808-4f39-a59e-6ed36d8927dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star_rating</th>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>train</th>\n",
       "      <td>932</td>\n",
       "      <td>932</td>\n",
       "      <td>932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>163</td>\n",
       "      <td>163</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>train</th>\n",
       "      <td>459</td>\n",
       "      <td>459</td>\n",
       "      <td>459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>train</th>\n",
       "      <td>682</td>\n",
       "      <td>682</td>\n",
       "      <td>682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>137</td>\n",
       "      <td>137</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>train</th>\n",
       "      <td>1307</td>\n",
       "      <td>1307</td>\n",
       "      <td>1307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>278</td>\n",
       "      <td>278</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>train</th>\n",
       "      <td>4620</td>\n",
       "      <td>4620</td>\n",
       "      <td>4620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>1321</td>\n",
       "      <td>1321</td>\n",
       "      <td>1321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             review_headline  review_body  sentiment\n",
       "star_rating label data_type                                         \n",
       "1           2     train                  932          932        932\n",
       "                  val                    163          163        163\n",
       "2           2     train                  459          459        459\n",
       "                  val                    101          101        101\n",
       "3           1     train                  682          682        682\n",
       "                  val                    137          137        137\n",
       "4           0     train                 1307         1307       1307\n",
       "                  val                    278          278        278\n",
       "5           0     train                 4620         4620       4620\n",
       "                  val                   1321         1321       1321"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['star_rating', 'label', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "731e5a17-8ab7-4d19-a012-05eeabab1d90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load BERT tokenizer\n",
    "pretrained_path = 'gpt2'  # Replace with the path to the pretrained BERT model\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    do_lower_case=True\n",
    ")\n",
    "\n",
    "encoded_data_train_headline = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='train'].review_headline.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding='longest',\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_train_body = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='train'].review_body.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding='longest',\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "input_ids_train_headline = encoded_data_train_headline['input_ids']\n",
    "attention_masks_train_headline = encoded_data_train_headline['attention_mask']\n",
    "\n",
    "input_ids_train_body = encoded_data_train_body['input_ids']\n",
    "attention_masks_train_body = encoded_data_train_body['attention_mask']\n",
    "\n",
    "input_ids_train = torch.cat((input_ids_train_headline, input_ids_train_body), dim=1)\n",
    "attention_masks_train = torch.cat((attention_masks_train_headline, attention_masks_train_body), dim=1)\n",
    "\n",
    "labels_train = torch.tensor(df[df.data_type=='train'].label.values)\n",
    "\n",
    "\n",
    "encoded_data_val_headline = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='val'].review_headline.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding='longest',\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_val_body = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='val'].review_body.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding='longest',\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "input_ids_val_headline = encoded_data_val_headline['input_ids']\n",
    "attention_masks_val_headline = encoded_data_val_headline['attention_mask']\n",
    "\n",
    "input_ids_val_body = encoded_data_val_body['input_ids']\n",
    "attention_masks_val_body = encoded_data_val_body['attention_mask']\n",
    "\n",
    "input_ids_val = torch.cat((input_ids_val_headline, input_ids_val_body), dim=1)\n",
    "attention_masks_val = torch.cat((attention_masks_val_headline, attention_masks_val_body), dim=1)\n",
    "\n",
    "labels_val = torch.tensor(df[df.data_type=='val'].label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42125069-fd5d-49c0-8032-2be61cb2a6d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 2000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
    "len(dataset_train), len(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a2f7e02-8423-4787-994e-d599ab86b123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Model, GPT2Config\n",
    "\n",
    "num_classes = 6\n",
    "\n",
    "class SentimentModel(nn.Module):\n",
    "    def __init__(self, pretrained_path, num_classes, cnn_out_channels, cnn_kernel_sizes):\n",
    "        super(SentimentModel, self).__init__()\n",
    "\n",
    "        gpt_config = GPT2Config.from_pretrained(            \n",
    "            pretrained_path,\n",
    "            hidden_dropout_prob=0.3,\n",
    "            attention_probs_dropout_prob=0.1)\n",
    "        self.gpt = GPT2Model.from_pretrained(pretrained_path, config=gpt_config)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(1, cnn_out_channels, kernel_size) for kernel_size in cnn_kernel_sizes\n",
    "        ])\n",
    "        self.fc = nn.Linear(cnn_out_channels * len(cnn_kernel_sizes), num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        gpt_outputs = self.gpt(input_ids, attention_mask=attention_mask)[0]\n",
    "        gpt_last_hidden_state = self.dropout(gpt_outputs[:, -1, :])  # Use the last hidden state\n",
    "        \n",
    "        output = torch.cat((gpt_last_hidden_state,), dim=1)\n",
    "    \n",
    "        # Add an extra dimension to pooled_output\n",
    "        output = output.unsqueeze(2)\n",
    "    \n",
    "        # Permute the dimensions of pooled_output\n",
    "        output = output.permute(0, 2, 1)\n",
    "    \n",
    "        # Remove the extra dimension from pooled_output\n",
    "        output = output.squeeze(2)\n",
    "    \n",
    "        # Apply convolution operation for each kernel size\n",
    "        conv_outputs = [conv(output) for conv in self.convs]\n",
    "    \n",
    "        # Apply max pooling over each convolution output\n",
    "        max_pooled = [torch.max(conv_output, dim=2)[0] for conv_output in conv_outputs]\n",
    "    \n",
    "        # Concatenate max pooled features from different kernel sizes\n",
    "        concatenated = torch.cat(max_pooled, dim=1)\n",
    "    \n",
    "        logits = self.fc(concatenated)\n",
    "        outputs = nn.functional.softmax(logits, dim=1)\n",
    "    \n",
    "        if labels is not None:\n",
    "            loss = nn.CrossEntropyLoss()(logits.view(-1, num_classes), labels.view(-1))\n",
    "            return loss, outputs, labels\n",
    "        else:\n",
    "            return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d131f86-ee7e-49b3-a104-a61841bb78d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_path = \"gpt2\"\n",
    "gpt_config = GPT2Config.from_pretrained(pretrained_path)\n",
    "cnn_out_channels = 256\n",
    "cnn_kernel_sizes = [2, 3, 4, 5]\n",
    "\n",
    "model = SentimentModel(pretrained_path, num_classes, cnn_out_channels, cnn_kernel_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "834c8c87-40a1-49c6-8e7b-307b931aec01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentModel(\n",
       "  (gpt): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv1d(1, 256, kernel_size=(2,), stride=(1,))\n",
       "    (1): Conv1d(1, 256, kernel_size=(3,), stride=(1,))\n",
       "    (2): Conv1d(1, 256, kernel_size=(4,), stride=(1,))\n",
       "    (3): Conv1d(1, 256, kernel_size=(5,), stride=(1,))\n",
       "  )\n",
       "  (fc): Linear(in_features=1024, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c610d351-0be0-4899-bf58-2397193b5ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, logging\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    **default_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7feb2f9d-26d7-41ed-b138-f2a59173c99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_train,\n",
    "    eval_dataset=dataset_val,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfb9e671-0f31-4a58-bf72-8c13ac04e6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "# Set the batch size and create data loaders for training and validation sets\n",
    "\n",
    "batch_size = 8 #32\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train,\n",
    "    sampler=RandomSampler(dataset_train),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "dataloader_val = DataLoader(\n",
    "    dataset_val,\n",
    "    sampler=RandomSampler(dataset_val),\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3bc14be-49bc-4b42-be70-17412957cdaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z123010/anaconda3/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=1e-5,\n",
    "    eps=1e-8\n",
    ")\n",
    "\n",
    "epochs = 10\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=len(dataloader_train) * epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27c174c9-8e92-42fa-9d81-54260c58251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val) #sets the seed value for the Python built-in pseudo-random generator.\n",
    "np.random.seed(seed_val) #sets the seed value for the NumPy pseudo-random number generator.\n",
    "torch.manual_seed(seed_val) #sets the seed value for the random number generator in PyTorch on the CPU.\n",
    "torch.cuda.manual_seed_all(seed_val) #sets the seed value for the random number generator in PyTorch on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3a28ec5-87fe-4bdf-b6a1-05bf8b6f6b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "110a870e-a6d8-46a5-a668-88049126c9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(trainer, dataloader_train, dataloader_val, epochs):\n",
    "    total_training_time = 0\n",
    "    \n",
    "    training_loss_list = []\n",
    "    validation_loss_list = []\n",
    "    accuracy_list = []\n",
    "    precision_list = []\n",
    "    f1_score_list = []\n",
    "    \n",
    "    previous_results = None  # Store previous epoch results\n",
    "    \n",
    "    for epoch in tqdm(range(1, epochs + 1)):\n",
    "        start_time = time.time()\n",
    "    \n",
    "        model.train()\n",
    "        loss_train_total = 0\n",
    "    \n",
    "        progress_bar = tqdm(dataloader_train,\n",
    "                            desc='Epoch {:1d}'.format(epoch),\n",
    "                            leave=False,\n",
    "                            disable=False)\n",
    "        for batch in progress_bar:\n",
    "            model.zero_grad()\n",
    "            batch = tuple(b.to(device) for b in batch)\n",
    "            inputs = {\n",
    "                'input_ids': batch[0],\n",
    "                'attention_mask': batch[1],\n",
    "                'labels': batch[2],\n",
    "            }\n",
    "            output = model(**inputs)\n",
    "            loss = output[0]\n",
    "            loss_train_total += loss.item()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item() / len(batch))})\n",
    "    \n",
    "        end_time = time.time()\n",
    "        epoch_training_time = end_time - start_time\n",
    "        total_training_time += epoch_training_time\n",
    "    \n",
    "        torch.save(model.state_dict(), f'Models/finetuned_gpt_textcnn_ft_epoch{epoch}.model')\n",
    "    \n",
    "        tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "        loss_train_avg = loss_train_total / len(dataloader_train)\n",
    "        tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "        val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
    "    \n",
    "        # Convert predictions to discrete labels\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "        val_f1 = f1_score(true_vals, predictions, average='weighted')\n",
    "        tqdm.write(f'Validation loss: {val_loss}')\n",
    "        tqdm.write(f'F1 Score (weighted): {val_f1}')\n",
    "    \n",
    "        val_accuracy = accuracy_score(true_vals, predictions)\n",
    "        val_precision = precision_score(true_vals, predictions, average='weighted', zero_division=1)\n",
    "    \n",
    "        # Compute and store metrics\n",
    "        training_loss_list.append(loss_train_avg)\n",
    "        validation_loss_list.append(val_loss)\n",
    "        f1_score_list.append(val_f1)\n",
    "        accuracy_list.append(val_accuracy)\n",
    "        precision_list.append(val_precision)\n",
    "    \n",
    "        # Check if there are previous results to compare with\n",
    "        if previous_results is not None:\n",
    "            if loss_train_avg > previous_results['loss_train_avg']:\n",
    "                percentage_increase = ((loss_train_avg - previous_results['loss_train_avg']) / previous_results['loss_train_avg']) * 100\n",
    "                tqdm.write('\\033[91m' + f'{round(percentage_increase, 2)}% Training loss increased compared to the previous epoch' + '\\033[0m')\n",
    "            if loss_train_avg < previous_results['loss_train_avg']:\n",
    "                percentage_decrease = ((previous_results['loss_train_avg'] - loss_train_avg) / previous_results['loss_train_avg']) * 100\n",
    "                tqdm.write('\\033[92m' + f'{round(percentage_decrease, 2)}% Training loss decreased compared to the previous epoch' + '\\033[0m')\n",
    "            if val_loss > previous_results['val_loss']:\n",
    "                percentage_increase = ((val_loss - previous_results['val_loss']) / previous_results['val_loss']) * 100\n",
    "                tqdm.write('\\033[91m' + f'{round(percentage_increase, 2)}% Validation loss increased compared to the previous epoch' + '\\033[0m')\n",
    "            if val_loss < previous_results['val_loss']:\n",
    "                percentage_decrease = ((previous_results['val_loss'] - val_loss) / previous_results['val_loss']) * 100\n",
    "                tqdm.write('\\033[92m' + f'{round(percentage_decrease, 2)}% Validation loss decreased compared to the previous epoch' + '\\033[0m')\n",
    "            if val_f1 < previous_results['val_f1']:\n",
    "                percentage_decrease = ((previous_results['val_f1'] - val_f1) / previous_results['val_f1']) * 100\n",
    "                tqdm.write('\\033[91m' + f'{round(percentage_decrease, 2)}% F1 Score decreased compared to the previous epoch' + '\\033[0m')\n",
    "            if val_f1 > previous_results['val_f1']:\n",
    "                percentage_increase = ((val_f1 - previous_results['val_f1']) / previous_results['val_f1']) * 100\n",
    "                tqdm.write('\\033[92m' + f'{round(percentage_increase, 2)}% F1 Score increased compared to the previous epoch' + '\\033[0m')\n",
    "    \n",
    "        # Store current results as previous results for the next epoch\n",
    "        previous_results = {\n",
    "            'loss_train_avg': loss_train_avg,\n",
    "            'val_loss': val_loss,\n",
    "            'val_f1': val_f1\n",
    "        }\n",
    "    \n",
    "    total_time_minutes = total_training_time / 60\n",
    "    tqdm.write(f'\\nTotal training time: {total_time_minutes} minutes')\n",
    "    \n",
    "    final_accuracy = accuracy_list[-1]\n",
    "    final_precision = precision_list[-1]\n",
    "    tqdm.write(f'Final Accuracy: {final_accuracy}')\n",
    "    tqdm.write(f'Final Precision: {final_precision}')\n",
    "    \n",
    "    # Create a single subplot\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    # Plot training loss\n",
    "    ax.plot(range(1, epochs + 1), training_loss_list, label='Training Loss')\n",
    "    \n",
    "    # Plot validation loss\n",
    "    ax.plot(range(1, epochs + 1), validation_loss_list, label='Validation Loss')\n",
    "    \n",
    "    # Plot F1-score\n",
    "    ax.plot(range(1, epochs + 1), f1_score_list, label='F1 Score')\n",
    "    \n",
    "    # Set labels and title\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Metric Value')\n",
    "    ax.set_title('Training Loss, Validation Loss, and F1 Score')\n",
    "    \n",
    "    # Set legend\n",
    "    ax.legend()\n",
    "    \n",
    "    # Show the combined plot\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    # Create the metrics table\n",
    "    metrics_table = [\n",
    "        ['Epoch', 'Training Loss', 'Validation Loss', 'F1 Score', 'Accuracy', 'Precision'],\n",
    "    ]\n",
    "    previous_results = None\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        row = [\n",
    "            epoch,\n",
    "            training_loss_list[epoch - 1],\n",
    "            validation_loss_list[epoch - 1],\n",
    "            f1_score_list[epoch - 1],\n",
    "            accuracy_list[epoch - 1],\n",
    "            precision_list[epoch - 1]\n",
    "        ]\n",
    "    \n",
    "        # Compare with previous epoch results\n",
    "        if previous_results is not None:\n",
    "            if training_loss_list[epoch - 1] < previous_results['loss_train_avg']:\n",
    "                row[1] = '\\033[92m' + str(row[1]) + '\\033[0m'  # Highlight in green\n",
    "            if training_loss_list[epoch - 1] > previous_results['loss_train_avg']:\n",
    "                row[1] = '\\033[91m' + str(row[1]) + '\\033[0m'  # Highlight in red\n",
    "            if validation_loss_list[epoch - 1] < previous_results['val_loss']:\n",
    "                row[2] = '\\033[92m' + str(row[2]) + '\\033[0m'  # Highlight in green\n",
    "            if validation_loss_list[epoch - 1] > previous_results['val_loss']:\n",
    "                row[2] = '\\033[91m' + str(row[2]) + '\\033[0m'  # Highlight in red\n",
    "            if f1_score_list[epoch - 1] > previous_results['val_f1']:\n",
    "                row[3] = '\\033[92m' + str(row[3]) + '\\033[0m'  # Highlight in green\n",
    "            if f1_score_list[epoch - 1] < previous_results['val_f1']:\n",
    "                row[3] = '\\033[91m' + str(row[3]) + '\\033[0m'  # Highlight in red\n",
    "    \n",
    "        metrics_table.append(row)\n",
    "        previous_results = {\n",
    "            'loss_train_avg': training_loss_list[epoch - 1],\n",
    "            'val_loss': validation_loss_list[epoch - 1],\n",
    "            'val_f1': f1_score_list[epoch - 1]\n",
    "        }\n",
    "    \n",
    "    # Calculate total training time in minutes\n",
    "    total_time_minutes = total_training_time / 60\n",
    "    \n",
    "    # Calculate total precision\n",
    "    total_precision = precision_list[-1]\n",
    "    \n",
    "    # Add total training time and total precision rows to the table\n",
    "    metrics_table.append(['Total Training Time', '', '', '', '', total_training_time])\n",
    "    metrics_table.append(['Final Precision', '', '', '', '', total_precision])\n",
    "    metrics_table.append(['Total Time (minutes)', '', '', '', '', total_time_minutes])\n",
    "    \n",
    "    # Print the table\n",
    "    print(tabulate(metrics_table, headers='firstrow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "092f1c4d-d96b-4ab6-8c15-fdc3caf7a7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20524f3a94604375b78abc32298f3ee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 1.6043423211942427\n",
      "Validation loss: 0.41174523505568505\n",
      "F1 Score (weighted): 0.8204106210621063\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2\n",
      "Training loss: 0.5054994777219836\n",
      "Validation loss: 0.4049614305444993\n",
      "F1 Score (weighted): 0.8399134164364198\n",
      "\u001b[92m68.49% Training loss decreased compared to the previous epoch\u001b[0m\n",
      "\u001b[92m1.65% Validation loss decreased compared to the previous epoch\u001b[0m\n",
      "\u001b[92m2.38% F1 Score increased compared to the previous epoch\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3\n",
      "Training loss: 0.45806812550107134\n",
      "Validation loss: 0.31810731188382485\n",
      "F1 Score (weighted): 0.8769392082712616\n",
      "\u001b[92m9.38% Training loss decreased compared to the previous epoch\u001b[0m\n",
      "\u001b[92m21.45% Validation loss decreased compared to the previous epoch\u001b[0m\n",
      "\u001b[92m4.41% F1 Score increased compared to the previous epoch\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4\n",
      "Training loss: 0.4134708538886771\n",
      "Validation loss: 0.3286711525036517\n",
      "F1 Score (weighted): 0.8842726647342686\n",
      "\u001b[92m9.74% Training loss decreased compared to the previous epoch\u001b[0m\n",
      "\u001b[91m3.32% Validation loss increased compared to the previous epoch\u001b[0m\n",
      "\u001b[92m0.84% F1 Score increased compared to the previous epoch\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5\n",
      "Training loss: 0.4102325768745213\n",
      "Validation loss: 0.30022202698281036\n",
      "F1 Score (weighted): 0.8920669628537258\n",
      "\u001b[92m0.78% Training loss decreased compared to the previous epoch\u001b[0m\n",
      "\u001b[92m8.66% Validation loss decreased compared to the previous epoch\u001b[0m\n",
      "\u001b[92m0.88% F1 Score increased compared to the previous epoch\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6\n",
      "Training loss: 0.3757554317411275\n",
      "Validation loss: 0.34380354802380314\n",
      "F1 Score (weighted): 0.8845889871440086\n",
      "\u001b[92m8.4% Training loss decreased compared to the previous epoch\u001b[0m\n",
      "\u001b[91m14.52% Validation loss increased compared to the previous epoch\u001b[0m\n",
      "\u001b[91m0.84% F1 Score decreased compared to the previous epoch\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7\n",
      "Training loss: 0.3777133868402633\n",
      "Validation loss: 0.33230200227303247\n",
      "F1 Score (weighted): 0.9002053713131329\n",
      "\u001b[91m0.52% Training loss increased compared to the previous epoch\u001b[0m\n",
      "\u001b[92m3.35% Validation loss decreased compared to the previous epoch\u001b[0m\n",
      "\u001b[92m1.77% F1 Score increased compared to the previous epoch\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8\n",
      "Training loss: 0.355892270846281\n",
      "Validation loss: 0.33709681780909156\n",
      "F1 Score (weighted): 0.8918728834453404\n",
      "\u001b[92m5.78% Training loss decreased compared to the previous epoch\u001b[0m\n",
      "\u001b[91m1.44% Validation loss increased compared to the previous epoch\u001b[0m\n",
      "\u001b[91m0.93% F1 Score decreased compared to the previous epoch\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9\n",
      "Training loss: 0.34378480695645247\n",
      "Validation loss: 0.3541843294912405\n",
      "F1 Score (weighted): 0.8927264279502752\n",
      "\u001b[92m3.4% Training loss decreased compared to the previous epoch\u001b[0m\n",
      "\u001b[91m5.07% Validation loss increased compared to the previous epoch\u001b[0m\n",
      "\u001b[92m0.1% F1 Score increased compared to the previous epoch\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10\n",
      "Training loss: 0.34336152575212986\n",
      "Validation loss: 0.35531266367595526\n",
      "F1 Score (weighted): 0.8898131681756826\n",
      "\u001b[92m0.12% Training loss decreased compared to the previous epoch\u001b[0m\n",
      "\u001b[91m0.32% Validation loss increased compared to the previous epoch\u001b[0m\n",
      "\u001b[91m0.33% F1 Score decreased compared to the previous epoch\u001b[0m\n",
      "\n",
      "Total training time: 51.50265078941981 minutes\n",
      "Final Accuracy: 0.8955\n",
      "Final Precision: 0.8929174611304769\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch                 Training Loss        Validation Loss      F1 Score            Accuracy      Precision\n",
      "--------------------  -------------------  -------------------  ------------------  ----------  -----------\n",
      "1                     1.6043423211942427   0.41174523505568505  0.8204106210621063  0.852          0.85976\n",
      "2                     \u001b[92m0.5054994777219836\u001b[0m   \u001b[92m0.4049614305444993\u001b[0m   \u001b[92m0.8399134164364198\u001b[0m  0.86           0.901291\n",
      "3                     \u001b[92m0.45806812550107134\u001b[0m  \u001b[92m0.31810731188382485\u001b[0m  \u001b[92m0.8769392082712616\u001b[0m  0.8915         0.878456\n",
      "4                     \u001b[92m0.4134708538886771\u001b[0m   \u001b[91m0.3286711525036517\u001b[0m   \u001b[92m0.8842726647342686\u001b[0m  0.886          0.886485\n",
      "5                     \u001b[92m0.4102325768745213\u001b[0m   \u001b[92m0.30022202698281036\u001b[0m  \u001b[92m0.8920669628537258\u001b[0m  0.8995         0.894936\n",
      "6                     \u001b[92m0.3757554317411275\u001b[0m   \u001b[91m0.34380354802380314\u001b[0m  \u001b[91m0.8845889871440086\u001b[0m  0.891          0.893892\n",
      "7                     \u001b[91m0.3777133868402633\u001b[0m   \u001b[92m0.33230200227303247\u001b[0m  \u001b[92m0.9002053713131329\u001b[0m  0.909          0.898964\n",
      "8                     \u001b[92m0.355892270846281\u001b[0m    \u001b[91m0.33709681780909156\u001b[0m  \u001b[91m0.8918728834453404\u001b[0m  0.899          0.893773\n",
      "9                     \u001b[92m0.34378480695645247\u001b[0m  \u001b[91m0.3541843294912405\u001b[0m   \u001b[92m0.8927264279502752\u001b[0m  0.8985         0.89604\n",
      "10                    \u001b[92m0.34336152575212986\u001b[0m  \u001b[91m0.35531266367595526\u001b[0m  \u001b[91m0.8898131681756826\u001b[0m  0.8955         0.892917\n",
      "Total Training Time                                                                             3090.16\n",
      "Final Precision                                                                                    0.892917\n",
      "Total Time (minutes)                                                                              51.5027\n"
     ]
    }
   ],
   "source": [
    "train_model(trainer, dataloader_train, dataloader_val, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bcc719-bffb-4972-b301-81eb6d861cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
