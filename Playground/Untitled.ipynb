{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4a8bd14-8616-4fbf-96fc-5d44e05d8e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf9888a4-70c6-49dd-aa8f-5ea20229862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    'Data/smile-annotations-final.csv',\n",
    "    names=['id', 'text', 'category'])\n",
    "df.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2fd376f-b6cc-4f47-af0f-1f09f71924bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>611857364396965889</th>\n",
       "      <td>@aandraous @britishmuseum @AndrewsAntonio Merc...</td>\n",
       "      <td>nocode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614484565059596288</th>\n",
       "      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614746522043973632</th>\n",
       "      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614877582664835073</th>\n",
       "      <td>@Sofabsports thank you for following me back. ...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611932373039644672</th>\n",
       "      <td>@britishmuseum @TudorHistory What a beautiful ...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 text category\n",
       "id                                                                            \n",
       "611857364396965889  @aandraous @britishmuseum @AndrewsAntonio Merc...   nocode\n",
       "614484565059596288  Dorian Gray with Rainbow Scarf #LoveWins (from...    happy\n",
       "614746522043973632  @SelectShowcase @Tate_StIves ... Replace with ...    happy\n",
       "614877582664835073  @Sofabsports thank you for following me back. ...    happy\n",
       "611932373039644672  @britishmuseum @TudorHistory What a beautiful ...    happy"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d61d75f-b449-4c1a-abf1-eebeb87c77b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "nocode               1572\n",
       "happy                1137\n",
       "not-relevant          214\n",
       "angry                  57\n",
       "surprise               35\n",
       "sad                    32\n",
       "happy|surprise         11\n",
       "happy|sad               9\n",
       "disgust|angry           7\n",
       "disgust                 6\n",
       "sad|disgust             2\n",
       "sad|angry               2\n",
       "sad|disgust|angry       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f3a9fae-9bf9-438c-bdf1-5a871978f96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.category.str.contains('\\|')] #Remove rows in 'category' column that contain the '|' symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d445567a-689d-4f78-ba5d-9b7b0cc1224a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.category != 'nocode'] #Remove rows in 'category' column that contain the 'nocode'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18732872-479c-4536-8ca0-e698600b1591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "happy           1137\n",
       "not-relevant     214\n",
       "angry             57\n",
       "surprise          35\n",
       "sad               32\n",
       "disgust            6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f7915e5-df4c-4cf5-ad9d-c5f4ee12abb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_labels = df.category.unique() #Get unique category labels from the DataFrame column 'category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37127423-10c3-41f5-a9bb-c75308ad2033",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {} #Create a dictionary to map each possible label to a unique index\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3a5190f-e680-4d7e-9be2-0fdf60417eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'happy': 0,\n",
       " 'not-relevant': 1,\n",
       " 'angry': 2,\n",
       " 'disgust': 3,\n",
       " 'sad': 4,\n",
       " 'surprise': 5}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f032eef8-bd72-4f58-912e-9e0e138a3556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>614484565059596288</th>\n",
       "      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614746522043973632</th>\n",
       "      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614877582664835073</th>\n",
       "      <td>@Sofabsports thank you for following me back. ...</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611932373039644672</th>\n",
       "      <td>@britishmuseum @TudorHistory What a beautiful ...</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611570404268883969</th>\n",
       "      <td>@NationalGallery @ThePoldarkian I have always ...</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614499696015503361</th>\n",
       "      <td>Lucky @FitzMuseum_UK! Good luck @MirandaStearn...</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613601881441570816</th>\n",
       "      <td>Yr 9 art students are off to the @britishmuseu...</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613696526297210880</th>\n",
       "      <td>@RAMMuseum Please vote for us as @sainsbury #s...</td>\n",
       "      <td>not-relevant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610746718641102848</th>\n",
       "      <td>#AskTheGallery Have you got plans to privatise...</td>\n",
       "      <td>not-relevant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612648200588038144</th>\n",
       "      <td>@BarbyWT @britishmuseum so beautiful</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 text   \n",
       "id                                                                      \n",
       "614484565059596288  Dorian Gray with Rainbow Scarf #LoveWins (from...  \\\n",
       "614746522043973632  @SelectShowcase @Tate_StIves ... Replace with ...   \n",
       "614877582664835073  @Sofabsports thank you for following me back. ...   \n",
       "611932373039644672  @britishmuseum @TudorHistory What a beautiful ...   \n",
       "611570404268883969  @NationalGallery @ThePoldarkian I have always ...   \n",
       "614499696015503361  Lucky @FitzMuseum_UK! Good luck @MirandaStearn...   \n",
       "613601881441570816  Yr 9 art students are off to the @britishmuseu...   \n",
       "613696526297210880  @RAMMuseum Please vote for us as @sainsbury #s...   \n",
       "610746718641102848  #AskTheGallery Have you got plans to privatise...   \n",
       "612648200588038144               @BarbyWT @britishmuseum so beautiful   \n",
       "\n",
       "                        category  label  \n",
       "id                                       \n",
       "614484565059596288         happy      0  \n",
       "614746522043973632         happy      0  \n",
       "614877582664835073         happy      0  \n",
       "611932373039644672         happy      0  \n",
       "611570404268883969         happy      0  \n",
       "614499696015503361         happy      0  \n",
       "613601881441570816         happy      0  \n",
       "613696526297210880  not-relevant      1  \n",
       "610746718641102848  not-relevant      1  \n",
       "612648200588038144         happy      0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df.category.replace(label_dict)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b644d99-7e99-451a-94b7-218aab812be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53086bf7-43ca-49d9-b215-4004539398e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    df.index.values,\n",
    "    df.label.values,\n",
    "    test_size=0.15,\n",
    "    random_state=17,\n",
    "    stratify=df.label.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d32204e-594a-4c09-9945-34875347e726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "from keras_radam import RAdam\n",
    "from keras import backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "98366c46-394a-4e48-a35a-97f2bb272d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  multi_cased_L-12_H-768_A-12.zip\n",
      "   creating: multi_cased_L-12_H-768_A-12/\n",
      "  inflating: multi_cased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
      "  inflating: multi_cased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
      "  inflating: multi_cased_L-12_H-768_A-12/vocab.txt  \n",
      "  inflating: multi_cased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
      "  inflating: multi_cased_L-12_H-768_A-12/bert_config.json  \n"
     ]
    }
   ],
   "source": [
    "!wget -q https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip\n",
    "!unzip -o multi_cased_L-12_H-768_A-12.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc1dc4e8-d601-460b-8f29-60e7559fa729",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_path = 'multi_cased_L-12_H-768_A-12'\n",
    "config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
    "checkpoint_path = os.path.join(pretrained_path, 'bert_model.ckpt')\n",
    "vocab_path = os.path.join(pretrained_path, 'vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d48078b2-09b5-428b-a79b-51232545b8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0fedd192-3861-48ee-955d-04cc32740a61",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'math_ops' from 'tensorflow.python' (/home/z123010/.local/lib/python3.10/site-packages/tensorflow/python/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_bert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_trained_model_from_checkpoint\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras_bert/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tokenizer\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras_bert/bert.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_inputs, get_embedding, TokenEmbedding, EmbeddingSimilarity, Masked, Extract, TaskEmbedding\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AdamWarmup\n\u001b[1;32m     11\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTOKEN_PAD\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTOKEN_UNK\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTOKEN_CLS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTOKEN_SEP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTOKEN_MASK\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgelu\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget_model\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompile_model\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget_base_dict\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgen_batch_inputs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget_token_embedding\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget_custom_objects\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mset_custom_objects\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     15\u001b[0m ]\n\u001b[1;32m     18\u001b[0m TOKEN_PAD \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Token for padding\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras_bert/optimizers/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras_bert/optimizers/util.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwarmup_v2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AdamWarmup\n\u001b[1;32m      3\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdamWarmup\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcalc_train_steps\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalc_train_steps\u001b[39m(num_example, batch_size, epochs, warmup_proportion\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras_bert/optimizers/warmup_v2.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizer_v2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizer_v2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OptimizerV2\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops, math_ops, state_ops, control_flow_ops\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend_config\n\u001b[1;32m      7\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdamWarmup\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'math_ops' from 'tensorflow.python' (/home/z123010/.local/lib/python3.10/site-packages/tensorflow/python/__init__.py)"
     ]
    }
   ],
   "source": [
    "from keras_bert import load_trained_model_from_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f92748a7-cd99-4d28-b875-e12262b63bf6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_trained_model_from_checkpoint' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_trained_model_from_checkpoint\u001b[49m(\n\u001b[1;32m      2\u001b[0m     config_path,\n\u001b[1;32m      3\u001b[0m     checkpoint_path,\n\u001b[1;32m      4\u001b[0m     seq_len\u001b[38;5;241m=\u001b[39mSEQ_LEN,\n\u001b[1;32m      5\u001b[0m     output_layer_num\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m      6\u001b[0m     trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_trained_model_from_checkpoint' is not defined"
     ]
    }
   ],
   "source": [
    "model = load_trained_model_from_checkpoint(\n",
    "    config_path,\n",
    "    checkpoint_path,\n",
    "    seq_len=SEQ_LEN,\n",
    "    output_layer_num=4,\n",
    "    trainable=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745c4a2c-395e-44ae-ac33-f9abdbe6806f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
