{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5bf24e9-d40b-45ad-9330-405d0097fe2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-14 17:44:22.277655: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-14 17:44:22.302136: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-14 17:44:22.661893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf90b811-cb1b-46a7-bc34-754fd93bc00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_args = {\n",
    "    \"output_dir\": \"tmp\",\n",
    "    \"evaluation_strategy\": \"steps\",\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"log_level\": \"error\",\n",
    "    \"report_to\": \"none\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a95a7954-1961-44b6-acce-b47069daf7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset amazon_us_reviews (/home/z123010/.cache/huggingface/datasets/amazon_us_reviews/Apparel_v1_00/0.1.0/17b2481be59723469538adeb8fd0a68b0ba363bbbdd71090e72c325ee6c7e563)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f0ba580015944f3839ca3dab318d075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32158956</th>\n",
       "      <td>★ THESE REALLY DO WORK GREAT WITH SOME TWEAKING ★</td>\n",
       "      <td>These Really Do Work Great, But You Do Need To...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714559</th>\n",
       "      <td>Favorite for winter. Very warm!</td>\n",
       "      <td>I love this dress. Absolute favorite for winte...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12608825</th>\n",
       "      <td>Great Socks for the money.</td>\n",
       "      <td>Nice socks, great colors, just enough support ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25482800</th>\n",
       "      <td>Slick hat!</td>\n",
       "      <td>I bought this for my husband and WOW, this is ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9310286</th>\n",
       "      <td>I would do it again!</td>\n",
       "      <td>Perfect dress and the customer service was awe...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review_headline   \n",
       "customer_id                                                      \n",
       "32158956     ★ THESE REALLY DO WORK GREAT WITH SOME TWEAKING ★  \\\n",
       "2714559                        Favorite for winter. Very warm!   \n",
       "12608825                            Great Socks for the money.   \n",
       "25482800                                            Slick hat!   \n",
       "9310286                                   I would do it again!   \n",
       "\n",
       "                                                   review_body  star_rating  \n",
       "customer_id                                                                  \n",
       "32158956     These Really Do Work Great, But You Do Need To...            4  \n",
       "2714559      I love this dress. Absolute favorite for winte...            5  \n",
       "12608825     Nice socks, great colors, just enough support ...            5  \n",
       "25482800     I bought this for my husband and WOW, this is ...            5  \n",
       "9310286      Perfect dress and the customer service was awe...            5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"amazon_us_reviews\", \"Apparel_v1_00\")\n",
    "train_data = dataset['train']\n",
    "\n",
    "# Limit the dataset to the first 100,000 rows\n",
    "train_data = train_data.select(range(100000))\n",
    "\n",
    "df = train_data.to_pandas()  # Convert the dataset to a Pandas DataFrame\n",
    "df = df[['customer_id', 'review_headline', 'review_body', 'star_rating']]  # Select specific columns\n",
    "df.columns = ['customer_id', 'review_headline', 'review_body', 'star_rating']  # Rename the selected columns\n",
    "df.set_index('customer_id', inplace=True)\n",
    "df.head()  # Display the first few rows of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6011a43-7e34-4346-b7e1-39bed6f5a9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "star_rating\n",
       "5    53374\n",
       "4    17763\n",
       "1    11741\n",
       "3    10431\n",
       "2     6691\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.star_rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76f31ee9-e50a-48e5-ab20-6b5121170111",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['star_rating'].map({5: 'good', 4: 'good', 3: 'neutral', 2: 'bad', 1: 'bad'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98b49bb4-ba9e-4288-acd3-0faf8d1f1e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "good       71137\n",
       "bad        18432\n",
       "neutral    10431\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "571b1f52-61cd-4a43-8834-1677a53710cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_labels = df.sentiment.unique() #Get unique category labels from the DataFrame column 'category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "011dcf57-fcae-45a6-a4b0-e418d8be03b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {} #Create a dictionary to map each possible label to a unique index\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba3099c7-f149-47ea-9209-8e9259d5037d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'good': 0, 'neutral': 1, 'bad': 2}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b5c9e29-57cc-4236-8b60-7b0d9b03fa45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32158956</th>\n",
       "      <td>★ THESE REALLY DO WORK GREAT WITH SOME TWEAKING ★</td>\n",
       "      <td>These Really Do Work Great, But You Do Need To...</td>\n",
       "      <td>4</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714559</th>\n",
       "      <td>Favorite for winter. Very warm!</td>\n",
       "      <td>I love this dress. Absolute favorite for winte...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12608825</th>\n",
       "      <td>Great Socks for the money.</td>\n",
       "      <td>Nice socks, great colors, just enough support ...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25482800</th>\n",
       "      <td>Slick hat!</td>\n",
       "      <td>I bought this for my husband and WOW, this is ...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9310286</th>\n",
       "      <td>I would do it again!</td>\n",
       "      <td>Perfect dress and the customer service was awe...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26631939</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Excellent for my 6 feet skinny 15 years old boy.</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48785098</th>\n",
       "      <td>Love it!</td>\n",
       "      <td>Raw is the only way to go! Absolutely love thi...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39548589</th>\n",
       "      <td>Three Stars</td>\n",
       "      <td>A bit large.</td>\n",
       "      <td>4</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29355866</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Great fit!</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477484</th>\n",
       "      <td>Not my favorite.</td>\n",
       "      <td>Shirt a bit too long, with heavy hem, which in...</td>\n",
       "      <td>3</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review_headline   \n",
       "customer_id                                                      \n",
       "32158956     ★ THESE REALLY DO WORK GREAT WITH SOME TWEAKING ★  \\\n",
       "2714559                        Favorite for winter. Very warm!   \n",
       "12608825                            Great Socks for the money.   \n",
       "25482800                                            Slick hat!   \n",
       "9310286                                   I would do it again!   \n",
       "26631939                                            Five Stars   \n",
       "48785098                                              Love it!   \n",
       "39548589                                           Three Stars   \n",
       "29355866                                            Five Stars   \n",
       "27477484                                      Not my favorite.   \n",
       "\n",
       "                                                   review_body  star_rating   \n",
       "customer_id                                                                   \n",
       "32158956     These Really Do Work Great, But You Do Need To...            4  \\\n",
       "2714559      I love this dress. Absolute favorite for winte...            5   \n",
       "12608825     Nice socks, great colors, just enough support ...            5   \n",
       "25482800     I bought this for my husband and WOW, this is ...            5   \n",
       "9310286      Perfect dress and the customer service was awe...            5   \n",
       "26631939      Excellent for my 6 feet skinny 15 years old boy.            5   \n",
       "48785098     Raw is the only way to go! Absolutely love thi...            5   \n",
       "39548589                                          A bit large.            4   \n",
       "29355866                                            Great fit!            5   \n",
       "27477484     Shirt a bit too long, with heavy hem, which in...            3   \n",
       "\n",
       "            sentiment  label  \n",
       "customer_id                   \n",
       "32158956         good      0  \n",
       "2714559          good      0  \n",
       "12608825         good      0  \n",
       "25482800         good      0  \n",
       "9310286          good      0  \n",
       "26631939         good      0  \n",
       "48785098         good      0  \n",
       "39548589         good      0  \n",
       "29355866         good      0  \n",
       "27477484      neutral      1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df.sentiment.replace(label_dict)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "091a8040-1ecd-4617-b0e2-f24236c1e0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32158956</th>\n",
       "      <td>★ THESE REALLY DO WORK GREAT WITH SOME TWEAKING ★</td>\n",
       "      <td>These Really Do Work Great, But You Do Need To...</td>\n",
       "      <td>4</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714559</th>\n",
       "      <td>Favorite for winter. Very warm!</td>\n",
       "      <td>I love this dress. Absolute favorite for winte...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12608825</th>\n",
       "      <td>Great Socks for the money.</td>\n",
       "      <td>Nice socks, great colors, just enough support ...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25482800</th>\n",
       "      <td>Slick hat!</td>\n",
       "      <td>I bought this for my husband and WOW, this is ...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9310286</th>\n",
       "      <td>I would do it again!</td>\n",
       "      <td>Perfect dress and the customer service was awe...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26631939</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Excellent for my 6 feet skinny 15 years old boy.</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48785098</th>\n",
       "      <td>Love it!</td>\n",
       "      <td>Raw is the only way to go! Absolutely love thi...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39548589</th>\n",
       "      <td>Three Stars</td>\n",
       "      <td>A bit large.</td>\n",
       "      <td>4</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29355866</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Great fit!</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477484</th>\n",
       "      <td>Not my favorite.</td>\n",
       "      <td>Shirt a bit too long, with heavy hem, which in...</td>\n",
       "      <td>3</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review_headline   \n",
       "customer_id                                                      \n",
       "32158956     ★ THESE REALLY DO WORK GREAT WITH SOME TWEAKING ★  \\\n",
       "2714559                        Favorite for winter. Very warm!   \n",
       "12608825                            Great Socks for the money.   \n",
       "25482800                                            Slick hat!   \n",
       "9310286                                   I would do it again!   \n",
       "26631939                                            Five Stars   \n",
       "48785098                                              Love it!   \n",
       "39548589                                           Three Stars   \n",
       "29355866                                            Five Stars   \n",
       "27477484                                      Not my favorite.   \n",
       "\n",
       "                                                   review_body  star_rating   \n",
       "customer_id                                                                   \n",
       "32158956     These Really Do Work Great, But You Do Need To...            4  \\\n",
       "2714559      I love this dress. Absolute favorite for winte...            5   \n",
       "12608825     Nice socks, great colors, just enough support ...            5   \n",
       "25482800     I bought this for my husband and WOW, this is ...            5   \n",
       "9310286      Perfect dress and the customer service was awe...            5   \n",
       "26631939      Excellent for my 6 feet skinny 15 years old boy.            5   \n",
       "48785098     Raw is the only way to go! Absolutely love thi...            5   \n",
       "39548589                                          A bit large.            4   \n",
       "29355866                                            Great fit!            5   \n",
       "27477484     Shirt a bit too long, with heavy hem, which in...            3   \n",
       "\n",
       "            sentiment  label  \n",
       "customer_id                   \n",
       "32158956         good      0  \n",
       "2714559          good      0  \n",
       "12608825         good      0  \n",
       "25482800         good      0  \n",
       "9310286          good      0  \n",
       "26631939         good      0  \n",
       "48785098         good      0  \n",
       "39548589         good      0  \n",
       "29355866         good      0  \n",
       "27477484      neutral      1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df.sentiment.replace(label_dict)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94ecbd52-6087-42b9-a35d-b8fb585d90ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad6acd5b-9b47-4eba-834c-b76acd53e9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    df.index.values,\n",
    "    df.label.values,\n",
    "    test_size=0.15,\n",
    "    random_state=17,\n",
    "    stratify=df.label.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "193eff85-82e0-4a8b-9907-918728f9ae05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['data_type'] = ['not_set']*df.shape[0] #Set a new column 'data_type' for later data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99a24a99-34b3-4dfb-91b5-f2318654c72c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32158956</th>\n",
       "      <td>★ THESE REALLY DO WORK GREAT WITH SOME TWEAKING ★</td>\n",
       "      <td>These Really Do Work Great, But You Do Need To...</td>\n",
       "      <td>4</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714559</th>\n",
       "      <td>Favorite for winter. Very warm!</td>\n",
       "      <td>I love this dress. Absolute favorite for winte...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12608825</th>\n",
       "      <td>Great Socks for the money.</td>\n",
       "      <td>Nice socks, great colors, just enough support ...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25482800</th>\n",
       "      <td>Slick hat!</td>\n",
       "      <td>I bought this for my husband and WOW, this is ...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9310286</th>\n",
       "      <td>I would do it again!</td>\n",
       "      <td>Perfect dress and the customer service was awe...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review_headline   \n",
       "customer_id                                                      \n",
       "32158956     ★ THESE REALLY DO WORK GREAT WITH SOME TWEAKING ★  \\\n",
       "2714559                        Favorite for winter. Very warm!   \n",
       "12608825                            Great Socks for the money.   \n",
       "25482800                                            Slick hat!   \n",
       "9310286                                   I would do it again!   \n",
       "\n",
       "                                                   review_body  star_rating   \n",
       "customer_id                                                                   \n",
       "32158956     These Really Do Work Great, But You Do Need To...            4  \\\n",
       "2714559      I love this dress. Absolute favorite for winte...            5   \n",
       "12608825     Nice socks, great colors, just enough support ...            5   \n",
       "25482800     I bought this for my husband and WOW, this is ...            5   \n",
       "9310286      Perfect dress and the customer service was awe...            5   \n",
       "\n",
       "            sentiment  label data_type  \n",
       "customer_id                             \n",
       "32158956         good      0   not_set  \n",
       "2714559          good      0   not_set  \n",
       "12608825         good      0   not_set  \n",
       "25482800         good      0   not_set  \n",
       "9310286          good      0   not_set  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "212019be-eff8-4c8c-8662-2fbdf93c9ee9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4997ac9d-5f65-445a-adc6-87bc8ce9ebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the 'data_type' column of the dataframe for training and validation data\n",
    "df.loc[X_train, 'data_type'] = 'train'\n",
    "df.loc[X_val, 'data_type'] = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fd8b4e3-1abd-462c-8d7c-28babcc8c3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star_rating</th>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>train</th>\n",
       "      <td>9581</td>\n",
       "      <td>9581</td>\n",
       "      <td>9581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>2160</td>\n",
       "      <td>2160</td>\n",
       "      <td>2160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>train</th>\n",
       "      <td>5463</td>\n",
       "      <td>5463</td>\n",
       "      <td>5463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>1228</td>\n",
       "      <td>1228</td>\n",
       "      <td>1228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>train</th>\n",
       "      <td>8439</td>\n",
       "      <td>8439</td>\n",
       "      <td>8439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>train</th>\n",
       "      <td>14202</td>\n",
       "      <td>14202</td>\n",
       "      <td>14202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>3561</td>\n",
       "      <td>3561</td>\n",
       "      <td>3561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>train</th>\n",
       "      <td>41279</td>\n",
       "      <td>41279</td>\n",
       "      <td>41279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>12095</td>\n",
       "      <td>12095</td>\n",
       "      <td>12095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             review_headline  review_body  sentiment\n",
       "star_rating label data_type                                         \n",
       "1           2     train                 9581         9581       9581\n",
       "                  val                   2160         2160       2160\n",
       "2           2     train                 5463         5463       5463\n",
       "                  val                   1228         1228       1228\n",
       "3           1     train                 8439         8439       8439\n",
       "                  val                   1992         1992       1992\n",
       "4           0     train                14202        14202      14202\n",
       "                  val                   3561         3561       3561\n",
       "5           0     train                41279        41279      41279\n",
       "                  val                  12095        12095      12095"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['star_rating', 'label', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4063ccde-23ff-431b-8091-4ba4c07dcaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERT tokenizer\n",
    "pretrained_path = 'bert-base-uncased'  # Replace with the path to the pretrained BERT model\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    do_lower_case=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "731e5a17-8ab7-4d19-a012-05eeabab1d90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoded_data_train_headline = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='train'].review_headline.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding='longest',\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_train_body = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='train'].review_body.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding='longest',\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "input_ids_train_headline = encoded_data_train_headline['input_ids']\n",
    "attention_masks_train_headline = encoded_data_train_headline['attention_mask']\n",
    "\n",
    "input_ids_train_body = encoded_data_train_body['input_ids']\n",
    "attention_masks_train_body = encoded_data_train_body['attention_mask']\n",
    "\n",
    "input_ids_train = torch.cat((input_ids_train_headline, input_ids_train_body), dim=1)\n",
    "attention_masks_train = torch.cat((attention_masks_train_headline, attention_masks_train_body), dim=1)\n",
    "\n",
    "labels_train = torch.tensor(df[df.data_type=='train'].label.values)\n",
    "\n",
    "\n",
    "encoded_data_val_headline = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='val'].review_headline.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding='longest',\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_val_body = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='val'].review_body.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding='longest',\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "input_ids_val_headline = encoded_data_val_headline['input_ids']\n",
    "attention_masks_val_headline = encoded_data_val_headline['attention_mask']\n",
    "\n",
    "input_ids_val_body = encoded_data_val_body['input_ids']\n",
    "attention_masks_val_body = encoded_data_val_body['attention_mask']\n",
    "\n",
    "input_ids_val = torch.cat((input_ids_val_headline, input_ids_val_body), dim=1)\n",
    "attention_masks_val = torch.cat((attention_masks_val_headline, attention_masks_val_body), dim=1)\n",
    "\n",
    "labels_val = torch.tensor(df[df.data_type=='val'].label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42125069-fd5d-49c0-8032-2be61cb2a6d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8df41f6-f750-48fd-a867-cd8211b4eea6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78964"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06087a20-bb64-451f-930d-e4020b74cd1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21036"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa9e4857-e3c7-4660-87a2-d88b3380da90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "SEQ_LEN = 256\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "LR = 2e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "530ad32e-d143-410e-b9fb-7baa1b6951b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertConfig, GPT2Model, GPT2Config\n",
    "\n",
    "num_classes = 6\n",
    "\n",
    "class SentimentModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SentimentModel, self).__init__()\n",
    "        \n",
    "        bert_config = BertConfig.from_pretrained(pretrained_path)\n",
    "        self.bert = BertModel.from_pretrained(pretrained_path, config=bert_config)\n",
    "        \n",
    "        gpt_config = GPT2Config.from_pretrained(pretrained_path)\n",
    "        self.gpt = GPT2Model.from_pretrained(pretrained_path, config=gpt_config)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(bert_config.hidden_size + gpt_config.hidden_size, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        bert_outputs = self.bert(input_ids, attention_mask=attention_mask)[0]\n",
    "        gpt_outputs = self.gpt(input_ids, attention_mask=attention_mask)[0]\n",
    "        \n",
    "        bert_outputs = self.dropout(bert_outputs[:, -1, :])  # Use the last hidden state\n",
    "        gpt_outputs = self.dropout(gpt_outputs[:, -1, :])  # Use the last hidden state\n",
    "        \n",
    "        combined_outputs = torch.cat((bert_outputs, gpt_outputs), dim=1)\n",
    "        \n",
    "        outputs = self.fc(combined_outputs)\n",
    "        outputs = self.softmax(outputs)\n",
    "        \n",
    "        if labels is not None:\n",
    "            loss = nn.CrossEntropyLoss()(outputs.view(-1, num_classes), labels.view(-1))\n",
    "            return loss, outputs, labels\n",
    "        else:\n",
    "            return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d26716a-419e-457b-9f45-89263db5cc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "You are using a model of type bert to instantiate a model of type gpt2. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing GPT2Model: ['bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.embeddings.position_embeddings.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.pooler.dense.bias', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.embeddings.token_type_embeddings.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.5.output.dense.bias', 'cls.predictions.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.output.dense.bias', 'cls.predictions.transform.dense.weight', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.embeddings.word_embeddings.weight', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.pooler.dense.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.11.output.dense.bias', 'cls.seq_relationship.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.self.key.bias', 'cls.seq_relationship.bias', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.value.weight']\n",
      "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of GPT2Model were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['h.9.ln_2.weight', 'h.3.ln_1.weight', 'h.8.attn.c_attn.weight', 'h.5.mlp.c_proj.weight', 'h.11.ln_2.bias', 'h.4.mlp.c_fc.weight', 'h.2.mlp.c_fc.bias', 'h.7.attn.c_proj.bias', 'h.4.ln_2.weight', 'h.7.ln_1.bias', 'h.2.mlp.c_fc.weight', 'h.6.ln_1.bias', 'h.10.ln_1.bias', 'h.4.ln_1.weight', 'h.2.attn.c_proj.bias', 'h.0.mlp.c_fc.weight', 'h.0.mlp.c_fc.bias', 'h.4.mlp.c_fc.bias', 'h.8.mlp.c_proj.bias', 'h.0.ln_1.bias', 'h.10.attn.c_attn.weight', 'h.0.attn.c_attn.bias', 'h.1.ln_1.bias', 'h.1.ln_2.weight', 'h.8.attn.c_proj.bias', 'h.10.mlp.c_proj.bias', 'h.1.mlp.c_proj.weight', 'h.11.attn.c_attn.weight', 'h.10.ln_1.weight', 'h.8.mlp.c_proj.weight', 'h.10.attn.c_proj.weight', 'h.2.ln_1.bias', 'h.6.mlp.c_fc.bias', 'h.2.mlp.c_proj.bias', 'h.6.attn.c_proj.bias', 'h.6.mlp.c_proj.weight', 'h.4.mlp.c_proj.bias', 'h.3.ln_2.weight', 'h.3.mlp.c_fc.weight', 'h.3.attn.c_proj.bias', 'h.5.ln_1.weight', 'h.6.ln_2.bias', 'h.1.ln_1.weight', 'h.7.mlp.c_proj.weight', 'h.9.attn.c_proj.bias', 'h.11.attn.c_proj.bias', 'h.6.ln_2.weight', 'h.8.ln_1.bias', 'h.3.ln_1.bias', 'h.0.ln_2.bias', 'h.6.attn.c_attn.weight', 'h.4.ln_2.bias', 'h.8.ln_2.weight', 'h.5.ln_2.bias', 'h.11.mlp.c_fc.bias', 'h.5.attn.c_proj.bias', 'wpe.weight', 'h.7.mlp.c_fc.weight', 'h.9.attn.c_attn.bias', 'h.0.mlp.c_proj.bias', 'h.5.attn.c_proj.weight', 'h.8.attn.c_proj.weight', 'ln_f.bias', 'h.1.attn.c_proj.bias', 'h.7.attn.c_attn.bias', 'h.2.mlp.c_proj.weight', 'h.10.mlp.c_fc.weight', 'h.5.mlp.c_proj.bias', 'h.10.attn.c_proj.bias', 'h.2.attn.c_proj.weight', 'h.4.ln_1.bias', 'h.5.mlp.c_fc.bias', 'h.10.ln_2.bias', 'h.7.ln_2.bias', 'h.5.ln_1.bias', 'h.1.attn.c_proj.weight', 'h.3.attn.c_attn.bias', 'h.8.mlp.c_fc.bias', 'h.9.attn.c_attn.weight', 'h.7.attn.c_proj.weight', 'h.10.ln_2.weight', 'h.0.mlp.c_proj.weight', 'h.5.attn.c_attn.bias', 'h.3.mlp.c_fc.bias', 'h.1.attn.c_attn.bias', 'h.10.mlp.c_fc.bias', 'h.0.attn.c_proj.weight', 'h.2.ln_1.weight', 'h.2.attn.c_attn.weight', 'h.11.mlp.c_fc.weight', 'h.8.attn.c_attn.bias', 'h.10.attn.c_attn.bias', 'h.4.attn.c_proj.weight', 'h.2.ln_2.weight', 'h.8.mlp.c_fc.weight', 'h.4.mlp.c_proj.weight', 'h.10.mlp.c_proj.weight', 'h.11.attn.c_proj.weight', 'h.5.ln_2.weight', 'h.9.mlp.c_proj.weight', 'h.3.mlp.c_proj.bias', 'h.9.mlp.c_proj.bias', 'h.5.mlp.c_fc.weight', 'h.9.ln_1.bias', 'h.4.attn.c_attn.bias', 'ln_f.weight', 'h.7.mlp.c_proj.bias', 'h.11.attn.c_attn.bias', 'wte.weight', 'h.11.ln_1.bias', 'h.1.ln_2.bias', 'h.7.mlp.c_fc.bias', 'h.11.mlp.c_proj.weight', 'h.1.attn.c_attn.weight', 'h.0.attn.c_proj.bias', 'h.1.mlp.c_proj.bias', 'h.11.ln_1.weight', 'h.9.ln_1.weight', 'h.6.attn.c_attn.bias', 'h.4.attn.c_attn.weight', 'h.11.mlp.c_proj.bias', 'h.3.mlp.c_proj.weight', 'h.4.attn.c_proj.bias', 'h.9.ln_2.bias', 'h.6.mlp.c_proj.bias', 'h.7.ln_1.weight', 'h.1.mlp.c_fc.weight', 'h.0.ln_1.weight', 'h.2.ln_2.bias', 'h.3.ln_2.bias', 'h.6.mlp.c_fc.weight', 'h.8.ln_2.bias', 'h.7.attn.c_attn.weight', 'h.5.attn.c_attn.weight', 'h.9.mlp.c_fc.bias', 'h.3.attn.c_attn.weight', 'h.3.attn.c_proj.weight', 'h.8.ln_1.weight', 'h.9.mlp.c_fc.weight', 'h.11.ln_2.weight', 'h.0.ln_2.weight', 'h.9.attn.c_proj.weight', 'h.7.ln_2.weight', 'h.2.attn.c_attn.bias', 'h.6.attn.c_proj.weight', 'h.6.ln_1.weight', 'h.1.mlp.c_fc.bias', 'h.0.attn.c_attn.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Create model instance\n",
    "model = SentimentModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "883547f2-7393-4d9b-964a-14385afbcd8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentModel(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (gpt): GPT2Model(\n",
       "    (wte): Embedding(30522, 768)\n",
       "    (wpe): Embedding(512, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=1536, out_features=6, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "353a7033-bb18-4751-90b4-f1877eb47703",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, logging\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    **default_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2855d37-a20d-4404-8fce-581fc9d2f2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_train,\n",
    "    eval_dataset=dataset_val,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e745c86-5db1-4cb7-9a47-4410f18e62c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "# Set the batch size and create data loaders for training and validation sets\n",
    "\n",
    "batch_size = 8 #32\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train,\n",
    "    sampler=RandomSampler(dataset_train),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "dataloader_val = DataLoader(\n",
    "    dataset_val,\n",
    "    sampler=RandomSampler(dataset_val),\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e80355ae-0454-468f-8bdd-25a59191e39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z123010/anaconda3/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=1e-5,\n",
    "    eps=1e-8\n",
    ")\n",
    "\n",
    "epochs = 10\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=len(dataloader_train) * epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe17bbb8-191e-48be-b5f9-b1aa2f39a041",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30b611a8-c688-4fec-b2e7-eb16390cd8df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score #F1 score is a measure of a model's accuracy, combining both precision and recall, used to evaluate binary classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "97209521-74d4-4d9a-afa7-e67084dea77e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten() #This line finds the index with the highest probability in each prediction, effectively giving the predicted class for each input.\n",
    "    labels_flat = labels.flatten()  #This line flattens the labels array into a 1D vector, as required by the f1_score function.\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted') #This line computes the F1 score using the true labels and the predicted labels, with the weighted averaging scheme. The result is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32fea2e3-d16c-4978-8843-bd5d2ccb152a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def accuracy_per_class(preds, labels):\n",
    "    # Create a dictionary with keys and values reversed for easy lookup.\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    # Get the predicted labels and flatten them.\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    \n",
    "    # Get the actual labels and flatten them.\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    # Iterate over the unique labels in the actual labels.\n",
    "    for label in np.unique(labels_flat):\n",
    "        # Get the predicted labels for this class.\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        \n",
    "        # Get the actual labels for this class.\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        \n",
    "        # Print the class name, accuracy numerator and denominator.\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9dd050b1-a41d-4a72-a0fd-9a56091e052b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val) #sets the seed value for the Python built-in pseudo-random generator.\n",
    "np.random.seed(seed_val) #sets the seed value for the NumPy pseudo-random number generator.\n",
    "torch.manual_seed(seed_val) #sets the seed value for the random number generator in PyTorch on the CPU.\n",
    "torch.cuda.manual_seed_all(seed_val) #sets the seed value for the random number generator in PyTorch on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f803e9ea-087b-47df-b978-a418a8414aa3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9bb07e43-e584-4f7a-9e29-8f0bcde6254c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This code evaluates the performance of a trained model on a validation dataset by computing its loss and predictions for each batch in the dataset.\n",
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval() # setting the model to evaluation mode to disable dropout and other regularization techniques that are useful during training but not during evaluation.\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "    \n",
    "        batch = tuple(b.to(device) for b in batch) # moving the input batch to the GPU for faster computation.\n",
    "   \n",
    "        #  creating a dictionary of inputs that will be passed to the model. The input IDs and attention mask are for the BERT model, and the labels are the true labels for each input.\n",
    "        inputs = {'input_ids':  \tbatch[0],\n",
    "                'attention_mask': batch[1],\n",
    "                'labels':     \tbatch[2],\n",
    "                } \n",
    "\n",
    "        with torch.no_grad():   \n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val)\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "       \t \n",
    "    return loss_val_avg, predictions, true_vals\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe4a5f53-ced2-47ec-8e71-f7a7e27b177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a8d126b-ef43-4103-9a1b-d1b736ebc518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "def train_model(trainer, dataloader_train, dataloader_val, epochs):\n",
    "    total_training_time = 0\n",
    "    \n",
    "    training_loss_list = []\n",
    "    validation_loss_list = []\n",
    "    accuracy_list = []\n",
    "    precision_list = []\n",
    "    f1_score_list = []\n",
    "    \n",
    "    previous_results = None  # Store previous epoch results\n",
    "    \n",
    "    for epoch in tqdm(range(1, epochs + 1)):\n",
    "        start_time = time.time()\n",
    "    \n",
    "        model.train()\n",
    "        loss_train_total = 0\n",
    "    \n",
    "        progress_bar = tqdm(dataloader_train,\n",
    "                            desc='Epoch {:1d}'.format(epoch),\n",
    "                            leave=False,\n",
    "                            disable=False)\n",
    "        for batch in progress_bar:\n",
    "            model.zero_grad()\n",
    "            batch = tuple(b.to(device) for b in batch)\n",
    "            inputs = {\n",
    "                'input_ids': batch[0],\n",
    "                'attention_mask': batch[1],\n",
    "                'labels': batch[2],\n",
    "            }\n",
    "            output, predictions, true_vals = model(**inputs)\n",
    "            loss = output\n",
    "            loss_train_total += loss.item()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item() / len(batch))})\n",
    "    \n",
    "        end_time = time.time()\n",
    "        epoch_training_time = end_time - start_time\n",
    "        total_training_time += epoch_training_time\n",
    "    \n",
    "        torch.save(model.state_dict(), f'Models/finetuned_bert_gpt_ft_epoch{epoch}.model')\n",
    "    \n",
    "        tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "        loss_train_avg = loss_train_total / len(dataloader_train)\n",
    "        tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "        val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
    "    \n",
    "        # Convert predictions to discrete labels\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "        val_f1 = f1_score(true_vals, predictions, average='weighted')\n",
    "        tqdm.write(f'Validation loss: {val_loss}')\n",
    "        tqdm.write(f'F1 Score (weighted): {val_f1}')\n",
    "    \n",
    "        val_accuracy = accuracy_score(true_vals, predictions)\n",
    "        val_precision = precision_score(true_vals, predictions, average='weighted', zero_division=1)\n",
    "    \n",
    "        # Compute and store metrics\n",
    "        training_loss_list.append(loss_train_avg)\n",
    "        validation_loss_list.append(val_loss)\n",
    "        f1_score_list.append(val_f1)\n",
    "        accuracy_list.append(val_accuracy)\n",
    "        precision_list.append(val_precision)\n",
    "    \n",
    "        # Check if there are previous results to compare with\n",
    "        if previous_results is not None:\n",
    "            if loss_train_avg > previous_results['loss_train_avg']:\n",
    "                percentage_increase = ((loss_train_avg - previous_results['loss_train_avg']) / previous_results['loss_train_avg']) * 100\n",
    "                tqdm.write('\\033[91m' + f'{round(percentage_increase, 2)}% Training loss increased compared to the previous epoch' + '\\033[0m')\n",
    "            if loss_train_avg < previous_results['loss_train_avg']:\n",
    "                percentage_decrease = ((previous_results['loss_train_avg'] - loss_train_avg) / previous_results['loss_train_avg']) * 100\n",
    "                tqdm.write('\\033[92m' + f'{round(percentage_decrease, 2)}% Training loss decreased compared to the previous epoch' + '\\033[0m')\n",
    "            if val_loss > previous_results['val_loss']:\n",
    "                percentage_increase = ((val_loss - previous_results['val_loss']) / previous_results['val_loss']) * 100\n",
    "                tqdm.write('\\033[91m' + f'{round(percentage_increase, 2)}% Validation loss increased compared to the previous epoch' + '\\033[0m')\n",
    "            if val_loss < previous_results['val_loss']:\n",
    "                percentage_decrease = ((previous_results['val_loss'] - val_loss) / previous_results['val_loss']) * 100\n",
    "                tqdm.write('\\033[92m' + f'{round(percentage_decrease, 2)}% Validation loss decreased compared to the previous epoch' + '\\033[0m')\n",
    "            if val_f1 < previous_results['val_f1']:\n",
    "                percentage_decrease = ((previous_results['val_f1'] - val_f1) / previous_results['val_f1']) * 100\n",
    "                tqdm.write('\\033[91m' + f'{round(percentage_decrease, 2)}% F1 Score decreased compared to the previous epoch' + '\\033[0m')\n",
    "            if val_f1 > previous_results['val_f1']:\n",
    "                percentage_increase = ((val_f1 - previous_results['val_f1']) / previous_results['val_f1']) * 100\n",
    "                tqdm.write('\\033[92m' + f'{round(percentage_increase, 2)}% F1 Score increased compared to the previous epoch' + '\\033[0m')\n",
    "    \n",
    "        # Store current results as previous results for the next epoch\n",
    "        previous_results = {\n",
    "            'loss_train_avg': loss_train_avg,\n",
    "            'val_loss': val_loss,\n",
    "            'val_f1': val_f1\n",
    "        }\n",
    "    \n",
    "    total_time_minutes = total_training_time / 60\n",
    "    tqdm.write(f'\\nTotal training time: {total_time_minutes} minutes')\n",
    "    \n",
    "    final_accuracy = accuracy_list[-1]\n",
    "    final_precision = precision_list[-1]\n",
    "    tqdm.write(f'Final Accuracy: {final_accuracy}')\n",
    "    tqdm.write(f'Final Precision: {final_precision}')\n",
    "    \n",
    "    # Create a single subplot\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    # Plot training loss\n",
    "    ax.plot(range(1, epochs + 1), training_loss_list, label='Training Loss')\n",
    "    \n",
    "    # Plot validation loss\n",
    "    ax.plot(range(1, epochs + 1), validation_loss_list, label='Validation Loss')\n",
    "    \n",
    "    # Plot F1-score\n",
    "    ax.plot(range(1, epochs + 1), f1_score_list, label='F1 Score')\n",
    "    \n",
    "    # Set labels and title\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Metric Value')\n",
    "    ax.set_title('Training Loss, Validation Loss, and F1 Score')\n",
    "    \n",
    "    # Set legend\n",
    "    ax.legend()\n",
    "    \n",
    "    # Show the combined plot\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    # Create the metrics table\n",
    "    metrics_table = [\n",
    "        ['Epoch', 'Training Loss', 'Validation Loss', 'F1 Score', 'Accuracy', 'Precision'],\n",
    "    ]\n",
    "    previous_results = None\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        row = [\n",
    "            epoch,\n",
    "            training_loss_list[epoch - 1],\n",
    "            validation_loss_list[epoch - 1],\n",
    "            f1_score_list[epoch - 1],\n",
    "            accuracy_list[epoch - 1],\n",
    "            precision_list[epoch - 1]\n",
    "        ]\n",
    "    \n",
    "        # Compare with previous epoch results\n",
    "        if previous_results is not None:\n",
    "            if training_loss_list[epoch - 1] < previous_results['loss_train_avg']:\n",
    "                row[1] = '\\033[92m' + str(row[1]) + '\\033[0m'  # Highlight in green\n",
    "            if training_loss_list[epoch - 1] > previous_results['loss_train_avg']:\n",
    "                row[1] = '\\033[91m' + str(row[1]) + '\\033[0m'  # Highlight in red\n",
    "            if validation_loss_list[epoch - 1] < previous_results['val_loss']:\n",
    "                row[2] = '\\033[92m' + str(row[2]) + '\\033[0m'  # Highlight in green\n",
    "            if validation_loss_list[epoch - 1] > previous_results['val_loss']:\n",
    "                row[2] = '\\033[91m' + str(row[2]) + '\\033[0m'  # Highlight in red\n",
    "            if f1_score_list[epoch - 1] > previous_results['val_f1']:\n",
    "                row[3] = '\\033[92m' + str(row[3]) + '\\033[0m'  # Highlight in green\n",
    "            if f1_score_list[epoch - 1] < previous_results['val_f1']:\n",
    "                row[3] = '\\033[91m' + str(row[3]) + '\\033[0m'  # Highlight in red\n",
    "    \n",
    "        metrics_table.append(row)\n",
    "        previous_results = {\n",
    "            'loss_train_avg': training_loss_list[epoch - 1],\n",
    "            'val_loss': validation_loss_list[epoch - 1],\n",
    "            'val_f1': f1_score_list[epoch - 1]\n",
    "        }\n",
    "    \n",
    "    # Calculate total training time in minutes\n",
    "    total_time_minutes = total_training_time / 60\n",
    "    \n",
    "    # Calculate total precision\n",
    "    total_precision = precision_list[-1]\n",
    "    \n",
    "    # Add total training time and total precision rows to the table\n",
    "    metrics_table.append(['Total Training Time', '', '', '', '', total_training_time])\n",
    "    metrics_table.append(['Final Precision', '', '', '', '', total_precision])\n",
    "    metrics_table.append(['Total Time (minutes)', '', '', '', '', total_time_minutes])\n",
    "    \n",
    "    # Print the table\n",
    "    print(tabulate(metrics_table, headers='firstrow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aea362aa-ae91-4ba7-9bd4-922230191694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f75df1992d6d46e882c17193e71db043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/9871 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 1.2388049686900655\n",
      "Validation loss: 1.1277008882493573\n",
      "F1 Score (weighted): 0.9078910583948105\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/9871 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2\n",
      "Training loss: 1.134976623763841\n",
      "Validation loss: 1.1264592863307705\n",
      "F1 Score (weighted): 0.9106449734573415\n",
      "\u001b[92m8.38% Training loss decreased compared to the previous epoch\u001b[0m\n",
      "\u001b[92m0.11% Validation loss decreased compared to the previous epoch\u001b[0m\n",
      "\u001b[92m0.3% F1 Score increased compared to the previous epoch\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/9871 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3\n",
      "Training loss: 1.1253183757192444\n",
      "Validation loss: 1.1284113304696608\n",
      "F1 Score (weighted): 0.9164137911514051\n",
      "\u001b[92m0.85% Training loss decreased compared to the previous epoch\u001b[0m\n",
      "\u001b[91m0.17% Validation loss increased compared to the previous epoch\u001b[0m\n",
      "\u001b[92m0.63% F1 Score increased compared to the previous epoch\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/9871 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4\n",
      "Training loss: 1.1189118437993588\n",
      "Validation loss: 1.1227114081382752\n",
      "F1 Score (weighted): 0.9153232527933933\n",
      "\u001b[92m0.57% Training loss decreased compared to the previous epoch\u001b[0m\n",
      "\u001b[92m0.51% Validation loss decreased compared to the previous epoch\u001b[0m\n",
      "\u001b[91m0.12% F1 Score decreased compared to the previous epoch\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/9871 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5\n",
      "Training loss: 1.1130916370155721\n",
      "Validation loss: 1.1230739582174178\n",
      "F1 Score (weighted): 0.9173015601480139\n",
      "\u001b[92m0.52% Training loss decreased compared to the previous epoch\u001b[0m\n",
      "\u001b[91m0.03% Validation loss increased compared to the previous epoch\u001b[0m\n",
      "\u001b[92m0.22% F1 Score increased compared to the previous epoch\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/9871 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6\n",
      "Training loss: 1.1085530417195666\n",
      "Validation loss: 1.1255174807722577\n",
      "F1 Score (weighted): 0.9170627554637402\n",
      "\u001b[92m0.41% Training loss decreased compared to the previous epoch\u001b[0m\n",
      "\u001b[91m0.22% Validation loss increased compared to the previous epoch\u001b[0m\n",
      "\u001b[91m0.03% F1 Score decreased compared to the previous epoch\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7:   0%|          | 0/9871 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7\n",
      "Training loss: 1.1033951007007115\n",
      "Validation loss: 1.1214608181112167\n",
      "F1 Score (weighted): 0.9193050158698544\n",
      "\u001b[92m0.47% Training loss decreased compared to the previous epoch\u001b[0m\n",
      "\u001b[92m0.36% Validation loss decreased compared to the previous epoch\u001b[0m\n",
      "\u001b[92m0.24% F1 Score increased compared to the previous epoch\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8:   0%|          | 0/9871 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8\n",
      "Training loss: 1.098675573044859\n",
      "Validation loss: 1.1228356476972312\n",
      "F1 Score (weighted): 0.9179639984891182\n",
      "\u001b[92m0.43% Training loss decreased compared to the previous epoch\u001b[0m\n",
      "\u001b[91m0.12% Validation loss increased compared to the previous epoch\u001b[0m\n",
      "\u001b[91m0.15% F1 Score decreased compared to the previous epoch\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9:   0%|          | 0/9871 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9\n",
      "Training loss: 1.095351897284997\n",
      "Validation loss: 1.1215972571318593\n",
      "F1 Score (weighted): 0.9197776270479971\n",
      "\u001b[92m0.3% Training loss decreased compared to the previous epoch\u001b[0m\n",
      "\u001b[92m0.11% Validation loss decreased compared to the previous epoch\u001b[0m\n",
      "\u001b[92m0.2% F1 Score increased compared to the previous epoch\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10:   0%|          | 0/9871 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10\n",
      "Training loss: 1.0925025085513564\n",
      "Validation loss: 1.1219029031325656\n",
      "F1 Score (weighted): 0.919943668132325\n",
      "\u001b[92m0.26% Training loss decreased compared to the previous epoch\u001b[0m\n",
      "\u001b[91m0.03% Validation loss increased compared to the previous epoch\u001b[0m\n",
      "\u001b[92m0.02% F1 Score increased compared to the previous epoch\u001b[0m\n",
      "\n",
      "Total training time: 974.9588504473369 minutes\n",
      "Final Accuracy: 0.921325347024149\n",
      "Final Precision: 0.9188526625640768\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch                 Training Loss       Validation Loss     F1 Score            Accuracy               Precision\n",
      "--------------------  ------------------  ------------------  ------------------  ------------------  ------------\n",
      "1                     1.2388049686900655  1.1277008882493573  0.9078910583948105  0.9157634531279711      0.909983\n",
      "2                     \u001b[92m1.134976623763841\u001b[0m   \u001b[92m1.1264592863307705\u001b[0m  \u001b[92m0.9106449734573415\u001b[0m  0.9164765164479939      0.913176\n",
      "3                     \u001b[92m1.1253183757192444\u001b[0m  \u001b[91m1.1284113304696608\u001b[0m  \u001b[92m0.9164137911514051\u001b[0m  0.9143848640425937      0.919075\n",
      "4                     \u001b[92m1.1189118437993588\u001b[0m  \u001b[92m1.1227114081382752\u001b[0m  \u001b[91m0.9153232527933933\u001b[0m  0.9203270583761172      0.915262\n",
      "5                     \u001b[92m1.1130916370155721\u001b[0m  \u001b[91m1.1230739582174178\u001b[0m  \u001b[92m0.9173015601480139\u001b[0m  0.9201369081574444      0.915979\n",
      "6                     \u001b[92m1.1085530417195666\u001b[0m  \u001b[91m1.1255174807722577\u001b[0m  \u001b[91m0.9170627554637402\u001b[0m  0.9175698802053622      0.916626\n",
      "7                     \u001b[92m1.1033951007007115\u001b[0m  \u001b[92m1.1214608181112167\u001b[0m  \u001b[92m0.9193050158698544\u001b[0m  0.9217056474614945      0.917814\n",
      "8                     \u001b[92m1.098675573044859\u001b[0m   \u001b[91m1.1228356476972312\u001b[0m  \u001b[91m0.9179639984891182\u001b[0m  0.9204696710401217      0.916548\n",
      "9                     \u001b[92m1.095351897284997\u001b[0m   \u001b[92m1.1215972571318593\u001b[0m  \u001b[92m0.9197776270479971\u001b[0m  0.9217531850161628      0.918447\n",
      "10                    \u001b[92m1.0925025085513564\u001b[0m  \u001b[91m1.1219029031325656\u001b[0m  \u001b[92m0.919943668132325\u001b[0m   0.921325347024149       0.918853\n",
      "Total Training Time                                                                                   58497.5\n",
      "Final Precision                                                                                           0.918853\n",
      "Total Time (minutes)                                                                                    974.959\n"
     ]
    }
   ],
   "source": [
    "train_model(trainer, dataloader_train, dataloader_val, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "82b25d26-6a38-434f-bf44-2ec31d099396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10b24c6b75a8420ab3b12024fefb0a93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/9871 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 1.0911161917802497\n",
      "Validation loss: 1.1219029038577932\n",
      "F1 Score (weighted): 0.919943668132325\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f911a711f584557a91876cd0f6fcb41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/9871 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m output, predictions, true_vals \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[1;32m     30\u001b[0m loss \u001b[38;5;241m=\u001b[39m output\n\u001b[0;32m---> 31\u001b[0m loss_train_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     33\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "    total_training_time = 0\n",
    "    \n",
    "    training_loss_list = []\n",
    "    validation_loss_list = []\n",
    "    accuracy_list = []\n",
    "    precision_list = []\n",
    "    f1_score_list = []\n",
    "    \n",
    "    previous_results = None  # Store previous epoch results\n",
    "    \n",
    "    for epoch in tqdm(range(1, epochs + 1)):\n",
    "        start_time = time.time()\n",
    "    \n",
    "        model.train()\n",
    "        loss_train_total = 0\n",
    "    \n",
    "        progress_bar = tqdm(dataloader_train,\n",
    "                            desc='Epoch {:1d}'.format(epoch),\n",
    "                            leave=False,\n",
    "                            disable=False)\n",
    "        for batch in progress_bar:\n",
    "            model.zero_grad()\n",
    "            batch = tuple(b.to(device) for b in batch)\n",
    "            inputs = {\n",
    "                'input_ids': batch[0],\n",
    "                'attention_mask': batch[1],\n",
    "                'labels': batch[2],\n",
    "            }\n",
    "            output, predictions, true_vals = model(**inputs)\n",
    "            loss = output\n",
    "            loss_train_total += loss.item()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item() / len(batch))})\n",
    "    \n",
    "        end_time = time.time()\n",
    "        epoch_training_time = end_time - start_time\n",
    "        total_training_time += epoch_training_time\n",
    "    \n",
    "        torch.save(model.state_dict(), f'Models/finetuned_bert_lstm_ft_epoch{epoch}.model')\n",
    "    \n",
    "        tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "        loss_train_avg = loss_train_total / len(dataloader_train)\n",
    "        tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "        val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
    "    \n",
    "        # Convert predictions to discrete labels\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "        val_f1 = f1_score(true_vals, predictions, average='weighted')\n",
    "        tqdm.write(f'Validation loss: {val_loss}')\n",
    "        tqdm.write(f'F1 Score (weighted): {val_f1}')\n",
    "    \n",
    "        val_accuracy = accuracy_score(true_vals, predictions)\n",
    "        val_precision = precision_score(true_vals, predictions, average='weighted', zero_division=1)\n",
    "    \n",
    "        # Compute and store metrics\n",
    "        training_loss_list.append(loss_train_avg)\n",
    "        validation_loss_list.append(val_loss)\n",
    "        f1_score_list.append(val_f1)\n",
    "        accuracy_list.append(val_accuracy)\n",
    "        precision_list.append(val_precision)\n",
    "    \n",
    "        # Check if there are previous results to compare with\n",
    "        if previous_results is not None:\n",
    "            if loss_train_avg > previous_results['loss_train_avg']:\n",
    "                percentage_increase = ((loss_train_avg - previous_results['loss_train_avg']) / previous_results['loss_train_avg']) * 100\n",
    "                tqdm.write('\\033[91m' + f'{round(percentage_increase, 2)}% Training loss increased compared to the previous epoch' + '\\033[0m')\n",
    "            if loss_train_avg < previous_results['loss_train_avg']:\n",
    "                percentage_decrease = ((previous_results['loss_train_avg'] - loss_train_avg) / previous_results['loss_train_avg']) * 100\n",
    "                tqdm.write('\\033[92m' + f'{round(percentage_decrease, 2)}% Training loss decreased compared to the previous epoch' + '\\033[0m')\n",
    "            if val_loss > previous_results['val_loss']:\n",
    "                percentage_increase = ((val_loss - previous_results['val_loss']) / previous_results['val_loss']) * 100\n",
    "                tqdm.write('\\033[91m' + f'{round(percentage_increase, 2)}% Validation loss increased compared to the previous epoch' + '\\033[0m')\n",
    "            if val_loss < previous_results['val_loss']:\n",
    "                percentage_decrease = ((previous_results['val_loss'] - val_loss) / previous_results['val_loss']) * 100\n",
    "                tqdm.write('\\033[92m' + f'{round(percentage_decrease, 2)}% Validation loss decreased compared to the previous epoch' + '\\033[0m')\n",
    "            if val_f1 < previous_results['val_f1']:\n",
    "                percentage_decrease = ((previous_results['val_f1'] - val_f1) / previous_results['val_f1']) * 100\n",
    "                tqdm.write('\\033[91m' + f'{round(percentage_decrease, 2)}% F1 Score decreased compared to the previous epoch' + '\\033[0m')\n",
    "            if val_f1 > previous_results['val_f1']:\n",
    "                percentage_increase = ((val_f1 - previous_results['val_f1']) / previous_results['val_f1']) * 100\n",
    "                tqdm.write('\\033[92m' + f'{round(percentage_increase, 2)}% F1 Score increased compared to the previous epoch' + '\\033[0m')\n",
    "    \n",
    "        # Store current results as previous results for the next epoch\n",
    "        previous_results = {\n",
    "            'loss_train_avg': loss_train_avg,\n",
    "            'val_loss': val_loss,\n",
    "            'val_f1': val_f1\n",
    "        }\n",
    "    \n",
    "    total_time_minutes = total_training_time / 60\n",
    "    tqdm.write(f'\\nTotal training time: {total_time_minutes} minutes')\n",
    "    \n",
    "    final_accuracy = accuracy_list[-1]\n",
    "    final_precision = precision_list[-1]\n",
    "    tqdm.write(f'Final Accuracy: {final_accuracy}')\n",
    "    tqdm.write(f'Final Precision: {final_precision}')\n",
    "    \n",
    "    # Create a single subplot\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    # Plot training loss\n",
    "    ax.plot(range(1, epochs + 1), training_loss_list, label='Training Loss')\n",
    "    \n",
    "    # Plot validation loss\n",
    "    ax.plot(range(1, epochs + 1), validation_loss_list, label='Validation Loss')\n",
    "    \n",
    "    # Plot F1-score\n",
    "    ax.plot(range(1, epochs + 1), f1_score_list, label='F1 Score')\n",
    "    \n",
    "    # Set labels and title\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Metric Value')\n",
    "    ax.set_title('Training Loss, Validation Loss, and F1 Score')\n",
    "    \n",
    "    # Set legend\n",
    "    ax.legend()\n",
    "    \n",
    "    # Show the combined plot\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    # Create the metrics table\n",
    "    metrics_table = [\n",
    "        ['Epoch', 'Training Loss', 'Validation Loss', 'F1 Score', 'Accuracy', 'Precision'],\n",
    "    ]\n",
    "    previous_results = None\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        row = [\n",
    "            epoch,\n",
    "            training_loss_list[epoch - 1],\n",
    "            validation_loss_list[epoch - 1],\n",
    "            f1_score_list[epoch - 1],\n",
    "            accuracy_list[epoch - 1],\n",
    "            precision_list[epoch - 1]\n",
    "        ]\n",
    "    \n",
    "        # Compare with previous epoch results\n",
    "        if previous_results is not None:\n",
    "            if training_loss_list[epoch - 1] < previous_results['loss_train_avg']:\n",
    "                row[1] = '\\033[92m' + str(row[1]) + '\\033[0m'  # Highlight in green\n",
    "            if training_loss_list[epoch - 1] > previous_results['loss_train_avg']:\n",
    "                row[1] = '\\033[91m' + str(row[1]) + '\\033[0m'  # Highlight in red\n",
    "            if validation_loss_list[epoch - 1] < previous_results['val_loss']:\n",
    "                row[2] = '\\033[92m' + str(row[2]) + '\\033[0m'  # Highlight in green\n",
    "            if validation_loss_list[epoch - 1] > previous_results['val_loss']:\n",
    "                row[2] = '\\033[91m' + str(row[2]) + '\\033[0m'  # Highlight in red\n",
    "            if f1_score_list[epoch - 1] > previous_results['val_f1']:\n",
    "                row[3] = '\\033[92m' + str(row[3]) + '\\033[0m'  # Highlight in green\n",
    "            if f1_score_list[epoch - 1] < previous_results['val_f1']:\n",
    "                row[3] = '\\033[91m' + str(row[3]) + '\\033[0m'  # Highlight in red\n",
    "    \n",
    "        metrics_table.append(row)\n",
    "        previous_results = {\n",
    "            'loss_train_avg': training_loss_list[epoch - 1],\n",
    "            'val_loss': validation_loss_list[epoch - 1],\n",
    "            'val_f1': f1_score_list[epoch - 1]\n",
    "        }\n",
    "    \n",
    "    # Calculate total training time in minutes\n",
    "    total_time_minutes = total_training_time / 60\n",
    "    \n",
    "    # Calculate total precision\n",
    "    total_precision = precision_list[-1]\n",
    "    \n",
    "    # Add total training time and total precision rows to the table\n",
    "    metrics_table.append(['Total Training Time', '', '', '', '', total_training_time])\n",
    "    metrics_table.append(['Final Precision', '', '', '', '', total_precision])\n",
    "    metrics_table.append(['Total Time (minutes)', '', '', '', '', total_time_minutes])\n",
    "    \n",
    "    # Print the table\n",
    "    print(tabulate(metrics_table, headers='firstrow'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
