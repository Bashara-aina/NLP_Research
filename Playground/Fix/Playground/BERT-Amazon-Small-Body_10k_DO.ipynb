{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5bf24e9-d40b-45ad-9330-405d0097fe2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a95a7954-1961-44b6-acce-b47069daf7d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset amazon_us_reviews (/home/z123010/.cache/huggingface/datasets/amazon_us_reviews/Apparel_v1_00/0.1.0/17b2481be59723469538adeb8fd0a68b0ba363bbbdd71090e72c325ee6c7e563)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc464807909c433189278e28aa131a7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32158956</th>\n",
       "      <td>★ THESE REALLY DO WORK GREAT WITH SOME TWEAKING ★</td>\n",
       "      <td>These Really Do Work Great, But You Do Need To...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714559</th>\n",
       "      <td>Favorite for winter. Very warm!</td>\n",
       "      <td>I love this dress. Absolute favorite for winte...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12608825</th>\n",
       "      <td>Great Socks for the money.</td>\n",
       "      <td>Nice socks, great colors, just enough support ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25482800</th>\n",
       "      <td>Slick hat!</td>\n",
       "      <td>I bought this for my husband and WOW, this is ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9310286</th>\n",
       "      <td>I would do it again!</td>\n",
       "      <td>Perfect dress and the customer service was awe...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review_headline   \n",
       "customer_id                                                      \n",
       "32158956     ★ THESE REALLY DO WORK GREAT WITH SOME TWEAKING ★  \\\n",
       "2714559                        Favorite for winter. Very warm!   \n",
       "12608825                            Great Socks for the money.   \n",
       "25482800                                            Slick hat!   \n",
       "9310286                                   I would do it again!   \n",
       "\n",
       "                                                   review_body  star_rating  \n",
       "customer_id                                                                  \n",
       "32158956     These Really Do Work Great, But You Do Need To...            4  \n",
       "2714559      I love this dress. Absolute favorite for winte...            5  \n",
       "12608825     Nice socks, great colors, just enough support ...            5  \n",
       "25482800     I bought this for my husband and WOW, this is ...            5  \n",
       "9310286      Perfect dress and the customer service was awe...            5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"amazon_us_reviews\", \"Apparel_v1_00\")\n",
    "train_data = dataset['train']\n",
    "\n",
    "# Limit the dataset to the first 10,000 rows\n",
    "train_data = train_data.select(range(10000))\n",
    "\n",
    "df = train_data.to_pandas()  # Convert the dataset to a Pandas DataFrame\n",
    "df = df[['customer_id', 'review_headline', 'review_body', 'star_rating']]  # Select specific columns\n",
    "df.columns = ['customer_id', 'review_headline', 'review_body', 'star_rating']  # Rename the selected columns\n",
    "df.set_index('customer_id', inplace=True)\n",
    "df.head()  # Display the first few rows of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7034b23d-56ed-490e-8125-cb0d2ba6eb69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "star_rating\n",
       "5    5941\n",
       "4    1585\n",
       "1    1095\n",
       "3     819\n",
       "2     560\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.star_rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4325d8a-a436-4a86-9995-a7e0cd00f43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['star_rating'].map({5: 'good', 4: 'good', 3: 'neutral', 2: 'bad', 1: 'bad'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0320fe9a-383c-4aa0-9894-8efad043769d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "good       7526\n",
       "bad        1655\n",
       "neutral     819\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3347837a-4483-4d9b-8557-1962090af758",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "possible_labels = df.sentiment.unique() #Get unique category labels from the DataFrame column 'category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f79a32b-1bda-48eb-a85f-a00dcf87866d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_dict = {} #Create a dictionary to map each possible label to a unique index\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c080c74-e058-4f12-bdcc-d3856baaacc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'good': 0, 'neutral': 1, 'bad': 2}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c496a65-b68a-432d-9054-d3403152ed28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32158956</th>\n",
       "      <td>★ THESE REALLY DO WORK GREAT WITH SOME TWEAKING ★</td>\n",
       "      <td>These Really Do Work Great, But You Do Need To...</td>\n",
       "      <td>4</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714559</th>\n",
       "      <td>Favorite for winter. Very warm!</td>\n",
       "      <td>I love this dress. Absolute favorite for winte...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12608825</th>\n",
       "      <td>Great Socks for the money.</td>\n",
       "      <td>Nice socks, great colors, just enough support ...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25482800</th>\n",
       "      <td>Slick hat!</td>\n",
       "      <td>I bought this for my husband and WOW, this is ...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9310286</th>\n",
       "      <td>I would do it again!</td>\n",
       "      <td>Perfect dress and the customer service was awe...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26631939</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Excellent for my 6 feet skinny 15 years old boy.</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48785098</th>\n",
       "      <td>Love it!</td>\n",
       "      <td>Raw is the only way to go! Absolutely love thi...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39548589</th>\n",
       "      <td>Three Stars</td>\n",
       "      <td>A bit large.</td>\n",
       "      <td>4</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29355866</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Great fit!</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477484</th>\n",
       "      <td>Not my favorite.</td>\n",
       "      <td>Shirt a bit too long, with heavy hem, which in...</td>\n",
       "      <td>3</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review_headline   \n",
       "customer_id                                                      \n",
       "32158956     ★ THESE REALLY DO WORK GREAT WITH SOME TWEAKING ★  \\\n",
       "2714559                        Favorite for winter. Very warm!   \n",
       "12608825                            Great Socks for the money.   \n",
       "25482800                                            Slick hat!   \n",
       "9310286                                   I would do it again!   \n",
       "26631939                                            Five Stars   \n",
       "48785098                                              Love it!   \n",
       "39548589                                           Three Stars   \n",
       "29355866                                            Five Stars   \n",
       "27477484                                      Not my favorite.   \n",
       "\n",
       "                                                   review_body  star_rating   \n",
       "customer_id                                                                   \n",
       "32158956     These Really Do Work Great, But You Do Need To...            4  \\\n",
       "2714559      I love this dress. Absolute favorite for winte...            5   \n",
       "12608825     Nice socks, great colors, just enough support ...            5   \n",
       "25482800     I bought this for my husband and WOW, this is ...            5   \n",
       "9310286      Perfect dress and the customer service was awe...            5   \n",
       "26631939      Excellent for my 6 feet skinny 15 years old boy.            5   \n",
       "48785098     Raw is the only way to go! Absolutely love thi...            5   \n",
       "39548589                                          A bit large.            4   \n",
       "29355866                                            Great fit!            5   \n",
       "27477484     Shirt a bit too long, with heavy hem, which in...            3   \n",
       "\n",
       "            sentiment  label  \n",
       "customer_id                   \n",
       "32158956         good      0  \n",
       "2714559          good      0  \n",
       "12608825         good      0  \n",
       "25482800         good      0  \n",
       "9310286          good      0  \n",
       "26631939         good      0  \n",
       "48785098         good      0  \n",
       "39548589         good      0  \n",
       "29355866         good      0  \n",
       "27477484      neutral      1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df.sentiment.replace(label_dict)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6129a4a-5efc-42e8-831f-4b939a133fe2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fc0132b-933e-42c4-87e4-9d3089f8e76a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Split the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    df.index.values,\n",
    "    df.label.values,\n",
    "    test_size=0.15,\n",
    "    random_state=17,\n",
    "    stratify=df.label.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "496c9a74-cf4f-4c0f-aa10-20ae4199f5d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['data_type'] = ['not_set']*df.shape[0] #Set a new column 'data_type' for later data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfb25a43-cd81-4897-b8a9-c92cbb9cd219",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32158956</th>\n",
       "      <td>★ THESE REALLY DO WORK GREAT WITH SOME TWEAKING ★</td>\n",
       "      <td>These Really Do Work Great, But You Do Need To...</td>\n",
       "      <td>4</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714559</th>\n",
       "      <td>Favorite for winter. Very warm!</td>\n",
       "      <td>I love this dress. Absolute favorite for winte...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12608825</th>\n",
       "      <td>Great Socks for the money.</td>\n",
       "      <td>Nice socks, great colors, just enough support ...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25482800</th>\n",
       "      <td>Slick hat!</td>\n",
       "      <td>I bought this for my husband and WOW, this is ...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9310286</th>\n",
       "      <td>I would do it again!</td>\n",
       "      <td>Perfect dress and the customer service was awe...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review_headline   \n",
       "customer_id                                                      \n",
       "32158956     ★ THESE REALLY DO WORK GREAT WITH SOME TWEAKING ★  \\\n",
       "2714559                        Favorite for winter. Very warm!   \n",
       "12608825                            Great Socks for the money.   \n",
       "25482800                                            Slick hat!   \n",
       "9310286                                   I would do it again!   \n",
       "\n",
       "                                                   review_body  star_rating   \n",
       "customer_id                                                                   \n",
       "32158956     These Really Do Work Great, But You Do Need To...            4  \\\n",
       "2714559      I love this dress. Absolute favorite for winte...            5   \n",
       "12608825     Nice socks, great colors, just enough support ...            5   \n",
       "25482800     I bought this for my husband and WOW, this is ...            5   \n",
       "9310286      Perfect dress and the customer service was awe...            5   \n",
       "\n",
       "            sentiment  label data_type  \n",
       "customer_id                             \n",
       "32158956         good      0   not_set  \n",
       "2714559          good      0   not_set  \n",
       "12608825         good      0   not_set  \n",
       "25482800         good      0   not_set  \n",
       "9310286          good      0   not_set  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a8b1568-baf2-441b-910b-7d5e77119e2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Set the 'data_type' column of the dataframe for training and validation data\n",
    "df.loc[X_train, 'data_type'] = 'train'\n",
    "df.loc[X_val, 'data_type'] = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "886206e4-6450-46d5-b88d-b14120707852",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star_rating</th>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>train</th>\n",
       "      <td>932</td>\n",
       "      <td>932</td>\n",
       "      <td>932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>163</td>\n",
       "      <td>163</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>train</th>\n",
       "      <td>459</td>\n",
       "      <td>459</td>\n",
       "      <td>459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>train</th>\n",
       "      <td>682</td>\n",
       "      <td>682</td>\n",
       "      <td>682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>137</td>\n",
       "      <td>137</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>train</th>\n",
       "      <td>1307</td>\n",
       "      <td>1307</td>\n",
       "      <td>1307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>278</td>\n",
       "      <td>278</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>train</th>\n",
       "      <td>4620</td>\n",
       "      <td>4620</td>\n",
       "      <td>4620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>1321</td>\n",
       "      <td>1321</td>\n",
       "      <td>1321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             review_headline  review_body  sentiment\n",
       "star_rating label data_type                                         \n",
       "1           2     train                  932          932        932\n",
       "                  val                    163          163        163\n",
       "2           2     train                  459          459        459\n",
       "                  val                    101          101        101\n",
       "3           1     train                  682          682        682\n",
       "                  val                    137          137        137\n",
       "4           0     train                 1307         1307       1307\n",
       "                  val                    278          278        278\n",
       "5           0     train                 4620         4620       4620\n",
       "                  val                   1321         1321       1321"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['star_rating', 'label', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "212019be-eff8-4c8c-8662-2fbdf93c9ee9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fa1ca9b-f491-4889-927f-f8731694bd47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    do_lower_case=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "731e5a17-8ab7-4d19-a012-05eeabab1d90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoded_data_train_headline = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='train'].review_headline.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding='longest',\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_train_body = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='train'].review_body.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding='longest',\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "input_ids_train_headline = encoded_data_train_headline['input_ids']\n",
    "attention_masks_train_headline = encoded_data_train_headline['attention_mask']\n",
    "\n",
    "input_ids_train_body = encoded_data_train_body['input_ids']\n",
    "attention_masks_train_body = encoded_data_train_body['attention_mask']\n",
    "\n",
    "input_ids_train = torch.cat((input_ids_train_headline, input_ids_train_body), dim=1)\n",
    "attention_masks_train = torch.cat((attention_masks_train_headline, attention_masks_train_body), dim=1)\n",
    "\n",
    "labels_train = torch.tensor(df[df.data_type=='train'].label.values)\n",
    "\n",
    "\n",
    "encoded_data_val_headline = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='val'].review_headline.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding='longest',\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_val_body = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='val'].review_body.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding='longest',\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "input_ids_val_headline = encoded_data_val_headline['input_ids']\n",
    "attention_masks_val_headline = encoded_data_val_headline['attention_mask']\n",
    "\n",
    "input_ids_val_body = encoded_data_val_body['input_ids']\n",
    "attention_masks_val_body = encoded_data_val_body['attention_mask']\n",
    "\n",
    "input_ids_val = torch.cat((input_ids_val_headline, input_ids_val_body), dim=1)\n",
    "attention_masks_val = torch.cat((attention_masks_val_headline, attention_masks_val_body), dim=1)\n",
    "\n",
    "labels_val = torch.tensor(df[df.data_type=='val'].label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42125069-fd5d-49c0-8032-2be61cb2a6d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8df41f6-f750-48fd-a867-cd8211b4eea6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06087a20-bb64-451f-930d-e4020b74cd1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f1be16f-2e08-451f-ad43-76262311d89f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 15:14:53.177315: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-26 15:14:53.201628: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-26 15:14:53.673234: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertConfig, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57dc7b55-a622-43f7-9127-ab13bdd6b839",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nHere, I use the BERTForSequenceClassification model, which is a BERT model for sequence classification\\ntask such as sentiment analysis. The pre-trained BERT model is loaded from 'bert-base-uncased', and we set the number of labels to be the length of unique labels in the dataset.\\n\\nI also set output_attentions and output_hidden_states to False, which means I only get the output\\nfrom the last layer of BERT.\\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define a BERT model for sequence classification task\n",
    "model_config = BertConfig.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=len(label_dict),\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    "    hidden_dropout_prob=0.3,  # Set the dropout rate (0.1 means 10% dropout)\n",
    "    attention_probs_dropout_prob=0.1  # Set the attention dropout rate\n",
    ")\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    config=model_config\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "Here, I use the BERTForSequenceClassification model, which is a BERT model for sequence classification\n",
    "task such as sentiment analysis. The pre-trained BERT model is loaded from 'bert-base-uncased', and we set the number of labels to be the length of unique labels in the dataset.\n",
    "\n",
    "I also set output_attentions and output_hidden_states to False, which means I only get the output\n",
    "from the last layer of BERT.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97b9c932-47f8-4683-8a5c-45ac3feec88c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02ff5662-1ec8-43b0-98b1-4d299d584843",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the batch size and create data loaders for training and validation sets\n",
    "\n",
    "batch_size = 1 #32\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train,\n",
    "    sampler=RandomSampler(dataset_train),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "dataloader_val = DataLoader(\n",
    "    dataset_val,\n",
    "    sampler=RandomSampler(dataset_val),\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b361e31-7b47-4264-9b3e-bd27a35b3d5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b74eccba-b3d4-46e6-902d-f794dbdf0d0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z123010/anaconda3/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(\n",
    "    model.parameters(),  # Passes the model parameters to the optimizer\n",
    "    lr=1e-5,             # Sets the learning rate for the optimizer to 1e-5\n",
    "    eps=1e-8             # Sets the epsilon value for numerical stability to 1e-8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c115596-a088-4b99-ba48-95c378dd9694",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs= 10 #This sets the number of epochs or the number of times the model will iterate over the entire dataset during training to 10.\n",
    "\n",
    "#This creates a linear learning rate scheduler that increases the learning rate linearly over the course of training and uses the specified number of warm-up steps and total training steps.\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0, #This sets the number of warm-up steps during training to 0. Warm-up steps gradually increase the learning rate from an initial low value to the target learning rate.\n",
    "    num_training_steps=len(dataloader_train)*epochs #This sets the number of total training steps to the number of batches per epoch times the number of epochs.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe17bbb8-191e-48be-b5f9-b1aa2f39a041",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30b611a8-c688-4fec-b2e7-eb16390cd8df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score #F1 score is a measure of a model's accuracy, combining both precision and recall, used to evaluate binary classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97209521-74d4-4d9a-afa7-e67084dea77e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten() #This line finds the index with the highest probability in each prediction, effectively giving the predicted class for each input.\n",
    "    labels_flat = labels.flatten()  #This line flattens the labels array into a 1D vector, as required by the f1_score function.\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted') #This line computes the F1 score using the true labels and the predicted labels, with the weighted averaging scheme. The result is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32fea2e3-d16c-4978-8843-bd5d2ccb152a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def accuracy_per_class(preds, labels):\n",
    "    # Create a dictionary with keys and values reversed for easy lookup.\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    # Get the predicted labels and flatten them.\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    \n",
    "    # Get the actual labels and flatten them.\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    # Iterate over the unique labels in the actual labels.\n",
    "    for label in np.unique(labels_flat):\n",
    "        # Get the predicted labels for this class.\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        \n",
    "        # Get the actual labels for this class.\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        \n",
    "        # Print the class name, accuracy numerator and denominator.\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9dd050b1-a41d-4a72-a0fd-9a56091e052b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val) #sets the seed value for the Python built-in pseudo-random generator.\n",
    "np.random.seed(seed_val) #sets the seed value for the NumPy pseudo-random number generator.\n",
    "torch.manual_seed(seed_val) #sets the seed value for the random number generator in PyTorch on the CPU.\n",
    "torch.cuda.manual_seed_all(seed_val) #sets the seed value for the random number generator in PyTorch on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f803e9ea-087b-47df-b978-a418a8414aa3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9bb07e43-e584-4f7a-9e29-8f0bcde6254c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This code evaluates the performance of a trained model on a validation dataset by computing its loss and predictions for each batch in the dataset.\n",
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval() # setting the model to evaluation mode to disable dropout and other regularization techniques that are useful during training but not during evaluation.\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "    \n",
    "        batch = tuple(b.to(device) for b in batch) # moving the input batch to the GPU for faster computation.\n",
    "   \n",
    "        #  creating a dictionary of inputs that will be passed to the model. The input IDs and attention mask are for the BERT model, and the labels are the true labels for each input.\n",
    "        inputs = {'input_ids':  \tbatch[0],\n",
    "                'attention_mask': batch[1],\n",
    "                'labels':     \tbatch[2],\n",
    "                } \n",
    "\n",
    "        with torch.no_grad():   \n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val)\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "       \t \n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a8d126b-ef43-4103-9a1b-d1b736ebc518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce81b8e638f45ed97529a4ecfd6c227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ae70a8ad864b44b28563af98a7eb8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/8000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "total_training_time = 0\n",
    "\n",
    "training_loss_list = []\n",
    "validation_loss_list = []\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "f1_score_list = []\n",
    "\n",
    "previous_results = None  # Store previous epoch results\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    start_time = time.time()\n",
    "\n",
    "    model.train()\n",
    "    loss_train_total = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader_train,\n",
    "                        desc='Epoch {:1d}'.format(epoch),\n",
    "                        leave=False,\n",
    "                        disable=False)\n",
    "    for batch in progress_bar:\n",
    "        model.zero_grad()\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        inputs = {\n",
    "            'input_ids': batch[0],\n",
    "            'attention_mask': batch[1],\n",
    "            'labels': batch[2],\n",
    "        }\n",
    "        output = model(**inputs)\n",
    "        loss = output[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item() / len(batch))})\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_training_time = end_time - start_time\n",
    "    total_training_time += epoch_training_time\n",
    "\n",
    "    torch.save(model.state_dict(), f'Models/finetuned_gpt_ft_epoch{epoch}.model')\n",
    "\n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "\n",
    "    loss_train_avg = loss_train_total / len(dataloader_train)\n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "\n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
    "\n",
    "    # Convert predictions to discrete labels\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    val_f1 = f1_score(true_vals, predictions, average='weighted')\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (weighted): {val_f1}')\n",
    "\n",
    "    val_accuracy = accuracy_score(true_vals, predictions)\n",
    "    val_precision = precision_score(true_vals, predictions, average='weighted', zero_division=1)\n",
    "\n",
    "    # Compute and store metrics\n",
    "    training_loss_list.append(loss_train_avg)\n",
    "    validation_loss_list.append(val_loss)\n",
    "    f1_score_list.append(val_f1)\n",
    "    accuracy_list.append(val_accuracy)\n",
    "    precision_list.append(val_precision)\n",
    "\n",
    "    # Check if there are previous results to compare with\n",
    "    if previous_results is not None:\n",
    "        if loss_train_avg > previous_results['loss_train_avg']:\n",
    "            percentage_increase = ((loss_train_avg - previous_results['loss_train_avg']) / previous_results['loss_train_avg']) * 100\n",
    "            tqdm.write('\\033[91m' + f'{round(percentage_increase, 2)}% Training loss increased compared to the previous epoch' + '\\033[0m')\n",
    "        if loss_train_avg < previous_results['loss_train_avg']:\n",
    "            percentage_decrease = ((previous_results['loss_train_avg'] - loss_train_avg) / previous_results['loss_train_avg']) * 100\n",
    "            tqdm.write('\\033[92m' + f'{round(percentage_decrease, 2)}% Training loss decreased compared to the previous epoch' + '\\033[0m')\n",
    "        if val_loss > previous_results['val_loss']:\n",
    "            percentage_increase = ((val_loss - previous_results['val_loss']) / previous_results['val_loss']) * 100\n",
    "            tqdm.write('\\033[91m' + f'{round(percentage_increase, 2)}% Validation loss increased compared to the previous epoch' + '\\033[0m')\n",
    "        if val_loss < previous_results['val_loss']:\n",
    "            percentage_decrease = ((previous_results['val_loss'] - val_loss) / previous_results['val_loss']) * 100\n",
    "            tqdm.write('\\033[92m' + f'{round(percentage_decrease, 2)}% Validation loss decreased compared to the previous epoch' + '\\033[0m')\n",
    "        if val_f1 < previous_results['val_f1']:\n",
    "            percentage_decrease = ((previous_results['val_f1'] - val_f1) / previous_results['val_f1']) * 100\n",
    "            tqdm.write('\\033[91m' + f'{round(percentage_decrease, 2)}% F1 Score decreased compared to the previous epoch' + '\\033[0m')\n",
    "        if val_f1 > previous_results['val_f1']:\n",
    "            percentage_increase = ((val_f1 - previous_results['val_f1']) / previous_results['val_f1']) * 100\n",
    "            tqdm.write('\\033[92m' + f'{round(percentage_increase, 2)}% F1 Score increased compared to the previous epoch' + '\\033[0m')\n",
    "\n",
    "    # Store current results as previous results for the next epoch\n",
    "    previous_results = {\n",
    "        'loss_train_avg': loss_train_avg,\n",
    "        'val_loss': val_loss,\n",
    "        'val_f1': val_f1\n",
    "    }\n",
    "\n",
    "total_time_minutes = total_training_time / 60\n",
    "tqdm.write(f'\\nTotal training time: {total_time_minutes} minutes')\n",
    "\n",
    "final_accuracy = accuracy_list[-1]\n",
    "final_precision = precision_list[-1]\n",
    "tqdm.write(f'Final Accuracy: {final_accuracy}')\n",
    "tqdm.write(f'Final Precision: {final_precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec92d8d-7962-4f8e-bac5-6c9f942714b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single subplot\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Plot training loss\n",
    "ax.plot(range(1, epochs + 1), training_loss_list, label='Training Loss')\n",
    "\n",
    "# Plot validation loss\n",
    "ax.plot(range(1, epochs + 1), validation_loss_list, label='Validation Loss')\n",
    "\n",
    "# Plot F1-score\n",
    "ax.plot(range(1, epochs + 1), f1_score_list, label='F1 Score')\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Metric Value')\n",
    "ax.set_title('Training Loss, Validation Loss, and F1 Score')\n",
    "\n",
    "# Set legend\n",
    "ax.legend()\n",
    "\n",
    "# Show the combined plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f694992a-1a5c-400b-8e4b-1fddfcfce83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the metrics table\n",
    "metrics_table = [\n",
    "    ['Epoch', 'Training Loss', 'Validation Loss', 'F1 Score', 'Accuracy', 'Precision'],\n",
    "]\n",
    "previous_results = None\n",
    "for epoch in range(1, epochs + 1):\n",
    "    row = [\n",
    "        epoch,\n",
    "        training_loss_list[epoch - 1],\n",
    "        validation_loss_list[epoch - 1],\n",
    "        f1_score_list[epoch - 1],\n",
    "        accuracy_list[epoch - 1],\n",
    "        precision_list[epoch - 1]\n",
    "    ]\n",
    "\n",
    "    # Compare with previous epoch results\n",
    "    if previous_results is not None:\n",
    "        if training_loss_list[epoch - 1] < previous_results['loss_train_avg']:\n",
    "            row[1] = '\\033[92m' + str(row[1]) + '\\033[0m'  # Highlight in green\n",
    "        if training_loss_list[epoch - 1] > previous_results['loss_train_avg']:\n",
    "            row[1] = '\\033[91m' + str(row[1]) + '\\033[0m'  # Highlight in red\n",
    "        if validation_loss_list[epoch - 1] < previous_results['val_loss']:\n",
    "            row[2] = '\\033[92m' + str(row[2]) + '\\033[0m'  # Highlight in green\n",
    "        if validation_loss_list[epoch - 1] > previous_results['val_loss']:\n",
    "            row[2] = '\\033[91m' + str(row[2]) + '\\033[0m'  # Highlight in red\n",
    "        if f1_score_list[epoch - 1] > previous_results['val_f1']:\n",
    "            row[3] = '\\033[92m' + str(row[3]) + '\\033[0m'  # Highlight in green\n",
    "        if f1_score_list[epoch - 1] < previous_results['val_f1']:\n",
    "            row[3] = '\\033[91m' + str(row[3]) + '\\033[0m'  # Highlight in red\n",
    "\n",
    "    metrics_table.append(row)\n",
    "    previous_results = {\n",
    "        'loss_train_avg': training_loss_list[epoch - 1],\n",
    "        'val_loss': validation_loss_list[epoch - 1],\n",
    "        'val_f1': f1_score_list[epoch - 1]\n",
    "    }\n",
    "\n",
    "# Calculate total training time in minutes\n",
    "total_time_minutes = total_training_time / 60\n",
    "\n",
    "# Calculate total precision\n",
    "total_precision = precision_list[-1]\n",
    "\n",
    "# Add total training time and total precision rows to the table\n",
    "metrics_table.append(['Total Training Time', '', '', '', '', total_training_time])\n",
    "metrics_table.append(['Final Precision', '', '', '', '', total_precision])\n",
    "metrics_table.append(['Total Time (minutes)', '', '', '', '', total_time_minutes])\n",
    "\n",
    "# Print the table\n",
    "print(tabulate(metrics_table, headers='firstrow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4f78e2-11cb-4638-bf3f-4d37d23443b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
