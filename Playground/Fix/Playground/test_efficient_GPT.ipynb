{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85921a44-1b43-47a9-bdff-63436d91b697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1410c81-8ee4-4978-b7de-addc6d93ba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len, dataset_size = 512, 512\n",
    "\n",
    "dummy_data = {\n",
    "    \"input_ids\": np.random.randint(100, 30000, (dataset_size, seq_len)),\n",
    "    \"labels\": np.random.randint(0, 1, (dataset_size)),\n",
    "}\n",
    "\n",
    "training_data = Dataset.from_dict(dummy_data)\n",
    "eval_data = Dataset.from_dict(dummy_data)  # Create a dummy evaluation dataset\n",
    "\n",
    "training_data.set_format(\"pt\")\n",
    "eval_data.set_format(\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4d669f0-3c57-4a27-a997-36c4676b54d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynvml import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da50dfcd-8bb6-4e79-8417-23cfc800a5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n",
    "\n",
    "\n",
    "def print_summary(result):\n",
    "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
    "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
    "    print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b82b0d23-d7fc-4cd9-9837-311fbc2c7f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 215 MB.\n"
     ]
    }
   ],
   "source": [
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fed946d3-e49a-493b-b5f5-b00fa9484ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "276ff994-6b51-48a5-9c1b-73a1978e0f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 335 MB.\n"
     ]
    }
   ],
   "source": [
    "torch.ones((1, 1)).to(\"cuda\")\n",
    "\n",
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ece9fee-4747-47df-8c39-469c97c094d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 18:48:03.250860: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-12 18:48:03.280935: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-12 18:48:03.695489: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2ForSequenceClassification, GPT2Tokenizer, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9750ec8d-ef0b-4915-b34c-22ea26ca840f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 335 MB.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = GPT2ForSequenceClassification.from_pretrained(\"gpt2\", num_labels=2)\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0467a9d7-990f-4d50-9499-133c9fe41d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_args = {\n",
    "    \"output_dir\": \"tmp\",\n",
    "    \"evaluation_strategy\": \"steps\",\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"log_level\": \"error\",\n",
    "    \"report_to\": \"none\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48abc0dd-e9c1-4843-97f9-d1b6d7cefe77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z123010/.local/lib/python3.10/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0019, 'learning_rate': 1.1718750000000001e-06, 'epoch': 0.98}\n",
      "{'eval_loss': 2.3283062977608182e-10, 'eval_runtime': 9.286, 'eval_samples_per_second': 55.137, 'eval_steps_per_second': 6.892, 'epoch': 0.98}\n",
      "{'train_runtime': 57.3275, 'train_samples_per_second': 8.931, 'train_steps_per_second': 8.931, 'train_loss': 0.001902676303870976, 'epoch': 1.0}\n",
      "Time: 57.33\n",
      "Samples/second: 8.93\n",
      "GPU memory occupied: 3479 MB.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, logging\n",
    "\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(per_device_train_batch_size=1, **default_args)\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=training_data, eval_dataset=eval_data)\n",
    "result = trainer.train()\n",
    "print_summary(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c645b04b-7648-45c7-bbd3-026c4ab2e844",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z123010/.local/lib/python3.10/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 35.617, 'train_samples_per_second': 14.375, 'train_steps_per_second': 3.594, 'train_loss': 2.3283062144940914e-09, 'epoch': 1.0}\n",
      "Time: 35.62\n",
      "Samples/second: 14.38\n",
      "GPU memory occupied: 3479 MB.\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(per_device_train_batch_size=1, gradient_accumulation_steps=4, **default_args)\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=training_data, eval_dataset=eval_data)\n",
    "result = trainer.train()\n",
    "print_summary(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a698f5a-85dd-4912-b10d-031c4b50b7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 46.2662, 'train_samples_per_second': 11.066, 'train_steps_per_second': 2.767, 'train_loss': 0.0, 'epoch': 1.0}\n",
      "Time: 46.27\n",
      "Samples/second: 11.07\n",
      "GPU memory occupied: 3479 MB.\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=1, gradient_accumulation_steps=4, gradient_checkpointing=True, **default_args\n",
    ")\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=training_data, eval_dataset=eval_data)\n",
    "result = trainer.train()\n",
    "print_summary(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05d4038d-327a-4a6d-a063-f64e54cc09a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 26.1324, 'train_samples_per_second': 19.593, 'train_steps_per_second': 4.898, 'train_loss': 0.0, 'epoch': 1.0}\n",
      "Time: 26.13\n",
      "Samples/second: 19.59\n",
      "GPU memory occupied: 3483 MB.\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(per_device_train_batch_size=4, fp16=True, **default_args)\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=training_data, eval_dataset=eval_data)\n",
    "result = trainer.train()\n",
    "print_summary(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f4818db-60df-460f-b15f-78091394b0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 32.7121, 'train_samples_per_second': 15.652, 'train_steps_per_second': 3.913, 'train_loss': 0.0, 'epoch': 1.0}\n",
      "Time: 32.71\n",
      "Samples/second: 15.65\n",
      "GPU memory occupied: 3483 MB.\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    **default_args,\n",
    ")\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=training_data, eval_dataset=eval_data)\n",
    "result = trainer.train()\n",
    "print_summary(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "040ac69c-8ffa-4622-bd7b-c58f47a6b008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 43.6654, 'train_samples_per_second': 11.726, 'train_steps_per_second': 2.931, 'train_loss': 0.0, 'epoch': 1.0}\n",
      "Time: 43.67\n",
      "Samples/second: 11.73\n",
      "GPU memory occupied: 3483 MB.\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(per_device_train_batch_size=4, optim=\"adafactor\", **default_args)\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=training_data, eval_dataset=eval_data)\n",
    "result = trainer.train()\n",
    "print_summary(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f8ce22c-86a9-44e3-a6f1-680ced113aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 33.7098, 'train_samples_per_second': 15.188, 'train_steps_per_second': 3.797, 'train_loss': 0.0, 'epoch': 1.0}\n",
      "Time: 33.71\n",
      "Samples/second: 15.19\n",
      "GPU memory occupied: 3483 MB.\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    optim=\"adafactor\",\n",
    "    **default_args,\n",
    ")\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=training_data, eval_dataset=eval_data)\n",
    "result = trainer.train()\n",
    "print_summary(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7086205-3d36-49ba-b288-db1df4a4b615",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
