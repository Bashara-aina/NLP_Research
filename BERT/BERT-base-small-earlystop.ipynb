{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5bf24e9-d40b-45ad-9330-405d0097fe2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-03 21:42:14.584161: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-03 21:42:14.609443: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-03 21:42:15.475147: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm  # For displaying progress bars\n",
    "from datasets import load_dataset  # For loading datasets\n",
    "from sklearn.model_selection import train_test_split  # For splitting the dataset\n",
    "from transformers import BertTokenizer  # For tokenizing text\n",
    "from torch.utils.data import TensorDataset  # For creating Tensor datasets\n",
    "import time  # For measuring time\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score  # For evaluation metrics\n",
    "from sklearn.exceptions import UndefinedMetricWarning  # For handling metric warnings\n",
    "import matplotlib.pyplot as plt  # For plotting\n",
    "from tabulate import tabulate  # For tabular data formatting\n",
    "import random  # For randomization\n",
    "import numpy as np  # For numerical operations\n",
    "from transformers import (\n",
    "    BertTokenizer,  # Tokenizer for BERT models\n",
    "    AdamW,  # Optimizer for BERT models\n",
    "    get_linear_schedule_with_warmup,  # Learning rate scheduler for BERT models\n",
    "    BertConfig,  # Configuration for BERT models\n",
    "    BertForSequenceClassification  # BERT model for sequence classification tasks\n",
    ")\n",
    "from torch.utils.data import (\n",
    "    DataLoader,  # Data loader for creating batches\n",
    "    RandomSampler,  # Sampler for random sampling of data\n",
    "    SequentialSampler  # Sampler for sequential sampling of data\n",
    ")\n",
    "from sklearn.metrics import f1_score  # For computing the F1 score\n",
    "\n",
    "# 1. Torch: PyTorch library for deep learning\n",
    "# 2. Pandas: Library for data manipulation and analysis\n",
    "# 3. tqdm: Library for displaying progress bars\n",
    "# 4. datasets: Library for working with datasets\n",
    "# 5. train_test_split: Function for splitting the dataset into training and validation sets\n",
    "# 6. BertTokenizer: Tokenizer for BERT models\n",
    "# 7. TensorDataset: Dataset class for creating PyTorch Tensor datasets\n",
    "# 8. time: Module for measuring time\n",
    "# 9. accuracy_score, precision_score, f1_score: Evaluation metrics for classification tasks\n",
    "# 10. UndefinedMetricWarning: Warning for undefined metric values\n",
    "# 11. matplotlib.pyplot: Plotting library\n",
    "# 12. tabulate: Library for formatting tabular data\n",
    "# 13. random: Module for randomization\n",
    "# 14. numpy: Library for numerical operations\n",
    "# 15. AdamW: Optimizer for BERT models\n",
    "# 16. get_linear_schedule_with_warmup: Learning rate scheduler for BERT models\n",
    "# 17. BertConfig: Configuration for BERT models\n",
    "# 18. BertForSequenceClassification: BERT model for sequence classification tasks\n",
    "# 19. DataLoader: Data loader for creating batches\n",
    "# 20. RandomSampler: Sampler for random sampling of data\n",
    "# 21. SequentialSampler: Sampler for sequential sampling of data\n",
    "# 22. f1_score: Function for computing the F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "207f2073-3da6-4185-917f-e8b3694617ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datacleaning_amazon():\n",
    "    dataset = load_dataset(\"amazon_us_reviews\", \"Apparel_v1_00\")\n",
    "    train_data = dataset['train']\n",
    "\n",
    "    # Limit the dataset to the first 100,000 rows\n",
    "    train_data = train_data.select(range(100000))\n",
    "\n",
    "    df = train_data.to_pandas()  # Convert the dataset to a Pandas DataFrame\n",
    "    df = df[['customer_id', 'review_headline', 'review_body', 'star_rating']]  # Select specific columns\n",
    "    df.columns = ['customer_id', 'review_headline', 'review_body', 'star_rating']  # Rename the selected columns\n",
    "    df.set_index('customer_id', inplace=True)\n",
    "\n",
    "    df['sentiment'] = df['star_rating'].map({5: 'good', 4: 'good', 3: 'neutral', 2: 'bad', 1: 'bad'})\n",
    "\n",
    "    possible_labels = df.sentiment.unique()  # Get unique category labels from the DataFrame column 'category'\n",
    "\n",
    "    label_dict = {}  # Create a dictionary to map each possible label to a unique index\n",
    "    for index, possible_label in enumerate(possible_labels):\n",
    "        label_dict[possible_label] = index\n",
    "\n",
    "    df['label'] = df.sentiment.replace(label_dict)\n",
    "\n",
    "    # Split the dataset into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        df.index.values,\n",
    "        df.label.values,\n",
    "        test_size=0.15,\n",
    "        random_state=17,\n",
    "        stratify=df.label.values\n",
    "    )\n",
    "\n",
    "    df['data_type'] = ['not_set'] * df.shape[0]  # Set a new column 'data_type' for later data split\n",
    "\n",
    "    # Set the 'data_type' column of the dataframe for training and validation data\n",
    "    df.loc[X_train, 'data_type'] = 'train'\n",
    "    df.loc[X_val, 'data_type'] = 'val'\n",
    "\n",
    "    return df\n",
    "\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten() #This line finds the index with the highest probability in each prediction, effectively giving the predicted class for each input.\n",
    "    labels_flat = labels.flatten()  #This line flattens the labels array into a 1D vector, as required by the f1_score function.\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted') #This line computes the F1 score using the true labels and the predicted labels, with the weighted averaging scheme. The result is returned.\n",
    "\n",
    "def accuracy_per_class(preds, labels):\n",
    "    # Create a dictionary with keys and values reversed for easy lookup.\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    # Get the predicted labels and flatten them.\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    \n",
    "    # Get the actual labels and flatten them.\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    # Iterate over the unique labels in the actual labels.\n",
    "    for label in np.unique(labels_flat):\n",
    "        # Get the predicted labels for this class.\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        \n",
    "        # Get the actual labels for this class.\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        \n",
    "        # Print the class name, accuracy numerator and denominator.\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n",
    "\n",
    "#This code evaluates the performance of a trained model on a validation dataset by computing its loss and predictions for each batch in the dataset.\n",
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval() # setting the model to evaluation mode to disable dropout and other regularization techniques that are useful during training but not during evaluation.\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "    \n",
    "        batch = tuple(b.to(device) for b in batch) # moving the input batch to the GPU for faster computation.\n",
    "   \n",
    "        #  creating a dictionary of inputs that will be passed to the model. The input IDs and attention mask are for the BERT model, and the labels are the true labels for each input.\n",
    "        inputs = {'input_ids':  \tbatch[0],\n",
    "                'attention_mask': batch[1],\n",
    "                'labels':     \tbatch[2],\n",
    "                } \n",
    "\n",
    "        with torch.no_grad():   \n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val)\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "       \t \n",
    "    return loss_val_avg, predictions, true_vals\n",
    "\n",
    "def train_model(model, dataloader_train, dataloader_val, epochs):\n",
    "    total_training_time = 0\n",
    "    \n",
    "    training_loss_list = []\n",
    "    validation_loss_list = []\n",
    "    accuracy_list = []\n",
    "    precision_list = []\n",
    "    f1_score_list = []\n",
    "    \n",
    "    previous_results = None  # Store previous epoch results\n",
    "    \n",
    "    for epoch in tqdm(range(1, epochs + 1)):\n",
    "        start_time = time.time()\n",
    "    \n",
    "        model.train()\n",
    "        loss_train_total = 0\n",
    "    \n",
    "        progress_bar = tqdm(dataloader_train,\n",
    "                            desc='Epoch {:1d}'.format(epoch),\n",
    "                            leave=False,\n",
    "                            disable=False)\n",
    "        for batch in progress_bar:\n",
    "            model.zero_grad()\n",
    "            batch = tuple(b.to(device) for b in batch)\n",
    "            inputs = {\n",
    "                'input_ids': batch[0],\n",
    "                'attention_mask': batch[1],\n",
    "                'labels': batch[2],\n",
    "            }\n",
    "            output = model(**inputs)\n",
    "            loss = output[0]\n",
    "            loss_train_total += loss.item()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item() / len(batch))})\n",
    "    \n",
    "        end_time = time.time()\n",
    "        epoch_training_time = end_time - start_time\n",
    "        total_training_time += epoch_training_time\n",
    "    \n",
    "        torch.save(model.state_dict(), f'Models/finetuned_gpt_ft_epoch{epoch}.model')\n",
    "    \n",
    "        tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "        loss_train_avg = loss_train_total / len(dataloader_train)\n",
    "        tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "        val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
    "    \n",
    "        # Convert predictions to discrete labels\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "        val_f1 = f1_score(true_vals, predictions, average='weighted')\n",
    "        tqdm.write(f'Validation loss: {val_loss}')\n",
    "        tqdm.write(f'F1 Score (weighted): {val_f1}')\n",
    "    \n",
    "        val_accuracy = accuracy_score(true_vals, predictions)\n",
    "        val_precision = precision_score(true_vals, predictions, average='weighted', zero_division=1)\n",
    "    \n",
    "        # Compute and store metrics\n",
    "        training_loss_list.append(loss_train_avg)\n",
    "        validation_loss_list.append(val_loss)\n",
    "        f1_score_list.append(val_f1)\n",
    "        accuracy_list.append(val_accuracy)\n",
    "        precision_list.append(val_precision)\n",
    "    \n",
    "        # Check if there are previous results to compare with\n",
    "        if previous_results is not None:\n",
    "            if loss_train_avg > previous_results['loss_train_avg']:\n",
    "                percentage_increase = ((loss_train_avg - previous_results['loss_train_avg']) / previous_results['loss_train_avg']) * 100\n",
    "                tqdm.write('\\033[91m' + f'{round(percentage_increase, 2)}% Training loss increased compared to the previous epoch' + '\\033[0m')\n",
    "            if loss_train_avg < previous_results['loss_train_avg']:\n",
    "                percentage_decrease = ((previous_results['loss_train_avg'] - loss_train_avg) / previous_results['loss_train_avg']) * 100\n",
    "                tqdm.write('\\033[92m' + f'{round(percentage_decrease, 2)}% Training loss decreased compared to the previous epoch' + '\\033[0m')\n",
    "            if val_loss > previous_results['val_loss']:\n",
    "                percentage_increase = ((val_loss - previous_results['val_loss']) / previous_results['val_loss']) * 100\n",
    "                tqdm.write('\\033[91m' + f'{round(percentage_increase, 2)}% Validation loss increased compared to the previous epoch' + '\\033[0m')\n",
    "            if val_loss < previous_results['val_loss']:\n",
    "                percentage_decrease = ((previous_results['val_loss'] - val_loss) / previous_results['val_loss']) * 100\n",
    "                tqdm.write('\\033[92m' + f'{round(percentage_decrease, 2)}% Validation loss decreased compared to the previous epoch' + '\\033[0m')\n",
    "            if val_f1 < previous_results['val_f1']:\n",
    "                percentage_decrease = ((previous_results['val_f1'] - val_f1) / previous_results['val_f1']) * 100\n",
    "                tqdm.write('\\033[91m' + f'{round(percentage_decrease, 2)}% F1 Score decreased compared to the previous epoch' + '\\033[0m')\n",
    "            if val_f1 > previous_results['val_f1']:\n",
    "                percentage_increase = ((val_f1 - previous_results['val_f1']) / previous_results['val_f1']) * 100\n",
    "                tqdm.write('\\033[92m' + f'{round(percentage_increase, 2)}% F1 Score increased compared to the previous epoch' + '\\033[0m')\n",
    "    \n",
    "        # Store current results as previous results for the next epoch\n",
    "        previous_results = {\n",
    "            'loss_train_avg': loss_train_avg,\n",
    "            'val_loss': val_loss,\n",
    "            'val_f1': val_f1\n",
    "        }\n",
    "    \n",
    "    total_time_minutes = total_training_time / 60\n",
    "    tqdm.write(f'\\nTotal training time: {total_time_minutes} minutes')\n",
    "    \n",
    "    final_accuracy = accuracy_list[-1]\n",
    "    final_precision = precision_list[-1]\n",
    "    tqdm.write(f'Final Accuracy: {final_accuracy}')\n",
    "    tqdm.write(f'Final Precision: {final_precision}')\n",
    "    \n",
    "    # Create a single subplot\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    # Plot training loss\n",
    "    ax.plot(range(1, epochs + 1), training_loss_list, label='Training Loss')\n",
    "    \n",
    "    # Plot validation loss\n",
    "    ax.plot(range(1, epochs + 1), validation_loss_list, label='Validation Loss')\n",
    "    \n",
    "    # Plot F1-score\n",
    "    ax.plot(range(1, epochs + 1), f1_score_list, label='F1 Score')\n",
    "    \n",
    "    # Set labels and title\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Metric Value')\n",
    "    ax.set_title('Training Loss, Validation Loss, and F1 Score')\n",
    "    \n",
    "    # Set legend\n",
    "    ax.legend()\n",
    "    \n",
    "    # Show the combined plot\n",
    "    plt.show()\n",
    "\n",
    "        # Create the metrics table\n",
    "    metrics_table = [\n",
    "        ['Epoch', 'Training Loss', 'Validation Loss', 'F1 Score', 'Accuracy', 'Precision'],\n",
    "    ]\n",
    "    previous_results = None\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        row = [\n",
    "            epoch,\n",
    "            training_loss_list[epoch - 1],\n",
    "            validation_loss_list[epoch - 1],\n",
    "            f1_score_list[epoch - 1],\n",
    "            accuracy_list[epoch - 1],\n",
    "            precision_list[epoch - 1]\n",
    "        ]\n",
    "    \n",
    "        # Compare with previous epoch results\n",
    "        if previous_results is not None:\n",
    "            if training_loss_list[epoch - 1] < previous_results['loss_train_avg']:\n",
    "                row[1] = '\\033[92m' + str(row[1]) + '\\033[0m'  # Highlight in green\n",
    "            if training_loss_list[epoch - 1] > previous_results['loss_train_avg']:\n",
    "                row[1] = '\\033[91m' + str(row[1]) + '\\033[0m'  # Highlight in red\n",
    "            if validation_loss_list[epoch - 1] < previous_results['val_loss']:\n",
    "                row[2] = '\\033[92m' + str(row[2]) + '\\033[0m'  # Highlight in green\n",
    "            if validation_loss_list[epoch - 1] > previous_results['val_loss']:\n",
    "                row[2] = '\\033[91m' + str(row[2]) + '\\033[0m'  # Highlight in red\n",
    "            if f1_score_list[epoch - 1] > previous_results['val_f1']:\n",
    "                row[3] = '\\033[92m' + str(row[3]) + '\\033[0m'  # Highlight in green\n",
    "            if f1_score_list[epoch - 1] < previous_results['val_f1']:\n",
    "                row[3] = '\\033[91m' + str(row[3]) + '\\033[0m'  # Highlight in red\n",
    "    \n",
    "        metrics_table.append(row)\n",
    "        previous_results = {\n",
    "            'loss_train_avg': training_loss_list[epoch - 1],\n",
    "            'val_loss': validation_loss_list[epoch - 1],\n",
    "            'val_f1': f1_score_list[epoch - 1]\n",
    "        }\n",
    "    \n",
    "    # Calculate total training time in minutes\n",
    "    total_time_minutes = total_training_time / 60\n",
    "    \n",
    "    # Calculate total precision\n",
    "    total_precision = precision_list[-1]\n",
    "    \n",
    "    # Add total training time and total precision rows to the table\n",
    "    metrics_table.append(['Total Training Time', '', '', '', '', total_training_time])\n",
    "    metrics_table.append(['Final Precision', '', '', '', '', total_precision])\n",
    "    metrics_table.append(['Total Time (minutes)', '', '', '', '', total_time_minutes])\n",
    "    \n",
    "    # Print the table\n",
    "    print(tabulate(metrics_table, headers='firstrow'))\n",
    "\n",
    "default_args = {\n",
    "    \"output_dir\": \"tmp\",\n",
    "    \"evaluation_strategy\": \"steps\",\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"log_level\": \"error\",\n",
    "    \"report_to\": \"none\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9785608-cd5e-4432-9d68-68d90c4a0a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset amazon_us_reviews (/home/z123010/.cache/huggingface/datasets/amazon_us_reviews/Apparel_v1_00/0.1.0/17b2481be59723469538adeb8fd0a68b0ba363bbbdd71090e72c325ee6c7e563)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34951f4b03ed47fcb80a46d73589ecd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = datacleaning_amazon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8793b8bc-43bd-4d43-a17e-abf0174eb200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label_dict and assign the number of labels\n",
    "label_dict = {label: index for index, label in enumerate(df['label'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2707709e-9e1b-460f-9386-6d9e999f2d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18281846</th>\n",
       "      <td>Reverse Flash Shirt</td>\n",
       "      <td>Awesome shirt. Fits great. Thank you. Fast shi...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3474709</th>\n",
       "      <td>Two Stars</td>\n",
       "      <td>Colors nothing like the picture. Almost more o...</td>\n",
       "      <td>2</td>\n",
       "      <td>bad</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48464524</th>\n",
       "      <td>WOW</td>\n",
       "      <td>&amp;#34;one size fits all&amp;#34; and it is SOO comf...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21206906</th>\n",
       "      <td>Beautiful wallet</td>\n",
       "      <td>Love this wallet! Holds tons of cards and cash...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13196813</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Nice shirt! !!</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20233350</th>\n",
       "      <td>Not really size free</td>\n",
       "      <td>[[VIDEOID:e551e331d9ee6a11aeb1438ef848a6f5]] I...</td>\n",
       "      <td>3</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35547524</th>\n",
       "      <td>Great product for our beach-going young'un</td>\n",
       "      <td>We are so glad we found this product.  We spen...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45960845</th>\n",
       "      <td>Nice, functional backpack</td>\n",
       "      <td>I purchased this for my middle school daughter...</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19701135</th>\n",
       "      <td>NOT FOR A PLUS SIZE</td>\n",
       "      <td>This is good for a thin person not anyone past...</td>\n",
       "      <td>3</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34464879</th>\n",
       "      <td>fun gifts for family friends and my 2 kids</td>\n",
       "      <td>They were great gifts for friends and my 2 kids.</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "      <td>0</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        review_headline   \n",
       "customer_id                                               \n",
       "18281846                            Reverse Flash Shirt  \\\n",
       "3474709                                       Two Stars   \n",
       "48464524                                            WOW   \n",
       "21206906                               Beautiful wallet   \n",
       "13196813                                     Five Stars   \n",
       "20233350                           Not really size free   \n",
       "35547524     Great product for our beach-going young'un   \n",
       "45960845                      Nice, functional backpack   \n",
       "19701135                            NOT FOR A PLUS SIZE   \n",
       "34464879     fun gifts for family friends and my 2 kids   \n",
       "\n",
       "                                                   review_body  star_rating   \n",
       "customer_id                                                                   \n",
       "18281846     Awesome shirt. Fits great. Thank you. Fast shi...            5  \\\n",
       "3474709      Colors nothing like the picture. Almost more o...            2   \n",
       "48464524     &#34;one size fits all&#34; and it is SOO comf...            5   \n",
       "21206906     Love this wallet! Holds tons of cards and cash...            5   \n",
       "13196813                                        Nice shirt! !!            5   \n",
       "20233350     [[VIDEOID:e551e331d9ee6a11aeb1438ef848a6f5]] I...            3   \n",
       "35547524     We are so glad we found this product.  We spen...            5   \n",
       "45960845     I purchased this for my middle school daughter...            5   \n",
       "19701135     This is good for a thin person not anyone past...            3   \n",
       "34464879      They were great gifts for friends and my 2 kids.            5   \n",
       "\n",
       "            sentiment  label data_type  \n",
       "customer_id                             \n",
       "18281846         good      0     train  \n",
       "3474709           bad      2     train  \n",
       "48464524         good      0     train  \n",
       "21206906         good      0     train  \n",
       "13196813         good      0     train  \n",
       "20233350      neutral      1       val  \n",
       "35547524         good      0       val  \n",
       "45960845         good      0     train  \n",
       "19701135      neutral      1     train  \n",
       "34464879         good      0       val  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(n=10, random_state=42)  # Generate 10 random rows from df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc596d9c-5808-4f39-a59e-6ed36d8927dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>star_rating</th>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>train</th>\n",
       "      <td>9581</td>\n",
       "      <td>9581</td>\n",
       "      <td>9581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>2160</td>\n",
       "      <td>2160</td>\n",
       "      <td>2160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>train</th>\n",
       "      <td>5463</td>\n",
       "      <td>5463</td>\n",
       "      <td>5463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>1228</td>\n",
       "      <td>1228</td>\n",
       "      <td>1228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>train</th>\n",
       "      <td>8439</td>\n",
       "      <td>8439</td>\n",
       "      <td>8439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>train</th>\n",
       "      <td>14202</td>\n",
       "      <td>14202</td>\n",
       "      <td>14202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>3561</td>\n",
       "      <td>3561</td>\n",
       "      <td>3561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>train</th>\n",
       "      <td>41279</td>\n",
       "      <td>41279</td>\n",
       "      <td>41279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>12095</td>\n",
       "      <td>12095</td>\n",
       "      <td>12095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             review_headline  review_body  sentiment\n",
       "star_rating label data_type                                         \n",
       "1           2     train                 9581         9581       9581\n",
       "                  val                   2160         2160       2160\n",
       "2           2     train                 5463         5463       5463\n",
       "                  val                   1228         1228       1228\n",
       "3           1     train                 8439         8439       8439\n",
       "                  val                   1992         1992       1992\n",
       "4           0     train                14202        14202      14202\n",
       "                  val                   3561         3561       3561\n",
       "5           0     train                41279        41279      41279\n",
       "                  val                  12095        12095      12095"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['star_rating', 'label', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "731e5a17-8ab7-4d19-a012-05eeabab1d90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load BERT tokenizer\n",
    "pretrained_path = 'bert-base-uncased'  # Replace with the path to the pretrained BERT model\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    do_lower_case=True\n",
    ")\n",
    "\n",
    "encoded_data_train_headline = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='train'].review_headline.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding='longest',\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_train_body = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='train'].review_body.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding='longest',\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "input_ids_train_headline = encoded_data_train_headline['input_ids']\n",
    "attention_masks_train_headline = encoded_data_train_headline['attention_mask']\n",
    "\n",
    "input_ids_train_body = encoded_data_train_body['input_ids']\n",
    "attention_masks_train_body = encoded_data_train_body['attention_mask']\n",
    "\n",
    "input_ids_train = torch.cat((input_ids_train_headline, input_ids_train_body), dim=1)\n",
    "attention_masks_train = torch.cat((attention_masks_train_headline, attention_masks_train_body), dim=1)\n",
    "\n",
    "labels_train = torch.tensor(df[df.data_type=='train'].label.values)\n",
    "\n",
    "\n",
    "encoded_data_val_headline = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='val'].review_headline.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding='longest',\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_val_body = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='val'].review_body.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding='longest',\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "input_ids_val_headline = encoded_data_val_headline['input_ids']\n",
    "attention_masks_val_headline = encoded_data_val_headline['attention_mask']\n",
    "\n",
    "input_ids_val_body = encoded_data_val_body['input_ids']\n",
    "attention_masks_val_body = encoded_data_val_body['attention_mask']\n",
    "\n",
    "input_ids_val = torch.cat((input_ids_val_headline, input_ids_val_body), dim=1)\n",
    "attention_masks_val = torch.cat((attention_masks_val_headline, attention_masks_val_body), dim=1)\n",
    "\n",
    "labels_val = torch.tensor(df[df.data_type=='val'].label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42125069-fd5d-49c0-8032-2be61cb2a6d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78964, 21036)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
    "len(dataset_train), len(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a2f7e02-8423-4787-994e-d599ab86b123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertConfig\n",
    "\n",
    "num_classes = 6\n",
    "\n",
    "class SentimentModel(nn.Module):\n",
    "    def __init__(self, pretrained_path, num_classes):\n",
    "        super(SentimentModel, self).__init__()\n",
    "\n",
    "        bert_config = BertConfig.from_pretrained(\n",
    "            pretrained_path,\n",
    "            hidden_size=512,  # Reduce the hidden size to make the model smaller\n",
    "            num_attention_heads=8,  # Reduce the number of attention heads to make the model smaller\n",
    "            hidden_dropout_prob=0.3,\n",
    "            attention_probs_dropout_prob=0.1\n",
    "        )\n",
    "        self.bert = BertModel(bert_config)  # Initialize BERT without pre-trained weights\n",
    "\n",
    "        self.fc = nn.Linear(512, num_classes)  # Update the linear layer input size\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        bert_outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = bert_outputs.last_hidden_state[:, 0, :]  # Use the CLS token as the representation\n",
    "\n",
    "        logits = self.fc(hidden_state)\n",
    "        outputs = nn.functional.softmax(logits, dim=1)\n",
    "\n",
    "        if labels is not None:\n",
    "            loss = nn.CrossEntropyLoss()(logits.view(-1, num_classes), labels.view(-1))\n",
    "            return loss, outputs, labels\n",
    "        else:\n",
    "            return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d131f86-ee7e-49b3-a104-a61841bb78d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model instance\n",
    "model = SentimentModel(pretrained_path, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "834c8c87-40a1-49c6-8e7b-307b931aec01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentModel(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 512, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 512)\n",
       "      (token_type_embeddings): Embedding(2, 512)\n",
       "      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.3, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c610d351-0be0-4899-bf58-2397193b5ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, logging\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    **default_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7feb2f9d-26d7-41ed-b138-f2a59173c99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_train,\n",
    "    eval_dataset=dataset_val,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfb9e671-0f31-4a58-bf72-8c13ac04e6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "# Set the batch size and create data loaders for training and validation sets\n",
    "\n",
    "batch_size = 8 #32\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train,\n",
    "    sampler=RandomSampler(dataset_train),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "dataloader_val = DataLoader(\n",
    "    dataset_val,\n",
    "    sampler=RandomSampler(dataset_val),\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3bc14be-49bc-4b42-be70-17412957cdaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/z123010/anaconda3/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=1e-5,\n",
    "    eps=1e-8\n",
    ")\n",
    "\n",
    "epochs = 25\n",
    "patience = 3\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=len(dataloader_train) * epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27c174c9-8e92-42fa-9d81-54260c58251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val) #sets the seed value for the Python built-in pseudo-random generator.\n",
    "np.random.seed(seed_val) #sets the seed value for the NumPy pseudo-random number generator.\n",
    "torch.manual_seed(seed_val) #sets the seed value for the random number generator in PyTorch on the CPU.\n",
    "torch.cuda.manual_seed_all(seed_val) #sets the seed value for the random number generator in PyTorch on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3a28ec5-87fe-4bdf-b6a1-05bf8b6f6b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "110a870e-a6d8-46a5-a668-88049126c9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(trainer, dataloader_train, dataloader_val, epochs, patience):\n",
    "    total_training_time = 0\n",
    "    \n",
    "    training_loss_list = []\n",
    "    validation_loss_list = []\n",
    "    accuracy_list = []\n",
    "    precision_list = []\n",
    "    f1_score_list = []\n",
    "    \n",
    "    previous_results = None  # Store previous epoch results\n",
    "    best_val_loss = float('inf')\n",
    "    counter = 0\n",
    "    \n",
    "    for epoch in tqdm(range(1, epochs + 1)):\n",
    "        start_time = time.time()\n",
    "    \n",
    "        model.train()\n",
    "        loss_train_total = 0\n",
    "    \n",
    "        progress_bar = tqdm(dataloader_train,\n",
    "                            desc='Epoch {:1d}'.format(epoch),\n",
    "                            leave=False,\n",
    "                            disable=False)\n",
    "        for batch in progress_bar:\n",
    "            model.zero_grad()\n",
    "            batch = tuple(b.to(device) for b in batch)\n",
    "            inputs = {\n",
    "                'input_ids': batch[0],\n",
    "                'attention_mask': batch[1],\n",
    "                'labels': batch[2],\n",
    "            }\n",
    "            output = model(**inputs)\n",
    "            loss = output[0]\n",
    "            loss_train_total += loss.item()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item() / len(batch))})\n",
    "    \n",
    "        end_time = time.time()\n",
    "        epoch_training_time = end_time - start_time\n",
    "        total_training_time += epoch_training_time\n",
    "    \n",
    "        torch.save(model.state_dict(), f'Models/finetuned_bert_ft_epoch{epoch}.model')\n",
    "    \n",
    "        tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "        loss_train_avg = loss_train_total / len(dataloader_train)\n",
    "        tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "        val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
    "    \n",
    "        # Convert predictions to discrete labels\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "        val_f1 = f1_score(true_vals, predictions, average='weighted')\n",
    "        tqdm.write(f'Validation loss: {val_loss}')\n",
    "        tqdm.write(f'F1 Score (weighted): {val_f1}')\n",
    "    \n",
    "        val_accuracy = accuracy_score(true_vals, predictions)\n",
    "        val_precision = precision_score(true_vals, predictions, average='weighted', zero_division=1)\n",
    "    \n",
    "        # Compute and store metrics\n",
    "        training_loss_list.append(loss_train_avg)\n",
    "        validation_loss_list.append(val_loss)\n",
    "        f1_score_list.append(val_f1)\n",
    "        accuracy_list.append(val_accuracy)\n",
    "        precision_list.append(val_precision)\n",
    "    \n",
    "        # Check if there are previous results to compare with\n",
    "        if previous_results is not None:\n",
    "            if loss_train_avg > previous_results['loss_train_avg']:\n",
    "                percentage_increase = ((loss_train_avg - previous_results['loss_train_avg']) / previous_results['loss_train_avg']) * 100\n",
    "                tqdm.write('\\033[91m' + f'{round(percentage_increase, 2)}% Training loss increased compared to the previous epoch' + '\\033[0m')\n",
    "            if loss_train_avg < previous_results['loss_train_avg']:\n",
    "                percentage_decrease = ((previous_results['loss_train_avg'] - loss_train_avg) / previous_results['loss_train_avg']) * 100\n",
    "                tqdm.write('\\033[92m' + f'{round(percentage_decrease, 2)}% Training loss decreased compared to the previous epoch' + '\\033[0m')\n",
    "            if val_loss > previous_results['val_loss']:\n",
    "                percentage_increase = ((val_loss - previous_results['val_loss']) / previous_results['val_loss']) * 100\n",
    "                tqdm.write('\\033[91m' + f'{round(percentage_increase, 2)}% Validation loss increased compared to the previous epoch' + '\\033[0m')\n",
    "            if val_loss < previous_results['val_loss']:\n",
    "                percentage_decrease = ((previous_results['val_loss'] - val_loss) / previous_results['val_loss']) * 100\n",
    "                tqdm.write('\\033[92m' + f'{round(percentage_decrease, 2)}% Validation loss decreased compared to the previous epoch' + '\\033[0m')\n",
    "            if val_f1 < previous_results['val_f1']:\n",
    "                percentage_decrease = ((previous_results['val_f1'] - val_f1) / previous_results['val_f1']) * 100\n",
    "                tqdm.write('\\033[91m' + f'{round(percentage_decrease, 2)}% F1 Score decreased compared to the previous epoch' + '\\033[0m')\n",
    "            if val_f1 > previous_results['val_f1']:\n",
    "                percentage_increase = ((val_f1 - previous_results['val_f1']) / previous_results['val_f1']) * 100\n",
    "                tqdm.write('\\033[92m' + f'{round(percentage_increase, 2)}% F1 Score increased compared to the previous epoch' + '\\033[0m')\n",
    "    \n",
    "        # Store current results as previous results for the next epoch\n",
    "        previous_results = {\n",
    "            'loss_train_avg': loss_train_avg,\n",
    "            'val_loss': val_loss,\n",
    "            'val_f1': val_f1\n",
    "        }\n",
    "        \n",
    "        # Check for early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                tqdm.write('\\nEarly stopping triggered. Training stopped.')\n",
    "                break\n",
    "    \n",
    "    total_time_minutes = total_training_time / 60\n",
    "    tqdm.write(f'\\nTotal training time: {total_time_minutes} minutes')\n",
    "    \n",
    "    final_accuracy = accuracy_list[-1]\n",
    "    final_precision = precision_list[-1]\n",
    "    tqdm.write(f'Final Accuracy: {final_accuracy}')\n",
    "    tqdm.write(f'Final Precision: {final_precision}')\n",
    "    \n",
    "    # Create the x-axis values based on the actual number of epochs completed\n",
    "    x_values = range(1, len(training_loss_list) + 1)\n",
    "    \n",
    "    # Create the metrics subplot\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    # Plot training loss\n",
    "    ax.plot(x_values, training_loss_list, label='Training Loss')\n",
    "    \n",
    "    # Plot validation loss\n",
    "    ax.plot(x_values, validation_loss_list, label='Validation Loss')\n",
    "    \n",
    "    # Plot F1-score\n",
    "    ax.plot(x_values, f1_score_list, label='F1 Score')\n",
    "    \n",
    "    # Set labels and title\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Metric Value')\n",
    "    ax.set_title('Training Loss, Validation Loss, and F1 Score')\n",
    "    \n",
    "    # Set legend\n",
    "    ax.legend()\n",
    "    \n",
    "    # Show the combined plot\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    # Create the metrics table\n",
    "    metrics_table = [\n",
    "        ['Epoch', 'Training Loss', 'Validation Loss', 'F1 Score', 'Accuracy', 'Precision'],\n",
    "    ]\n",
    "    previous_results = None\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        row = [\n",
    "            epoch,\n",
    "            training_loss_list[epoch - 1],\n",
    "            validation_loss_list[epoch - 1],\n",
    "            f1_score_list[epoch - 1],\n",
    "            accuracy_list[epoch - 1],\n",
    "            precision_list[epoch - 1]\n",
    "        ]\n",
    "    \n",
    "        # Compare with previous epoch results\n",
    "        if previous_results is not None:\n",
    "            if training_loss_list[epoch - 1] < previous_results['loss_train_avg']:\n",
    "                row[1] = '\\033[92m' + str(row[1]) + '\\033[0m'  # Highlight in green\n",
    "            if training_loss_list[epoch - 1] > previous_results['loss_train_avg']:\n",
    "                row[1] = '\\033[91m' + str(row[1]) + '\\033[0m'  # Highlight in red\n",
    "            if validation_loss_list[epoch - 1] < previous_results['val_loss']:\n",
    "                row[2] = '\\033[92m' + str(row[2]) + '\\033[0m'  # Highlight in green\n",
    "            if validation_loss_list[epoch - 1] > previous_results['val_loss']:\n",
    "                row[2] = '\\033[91m' + str(row[2]) + '\\033[0m'  # Highlight in red\n",
    "            if f1_score_list[epoch - 1] > previous_results['val_f1']:\n",
    "                row[3] = '\\033[92m' + str(row[3]) + '\\033[0m'  # Highlight in green\n",
    "            if f1_score_list[epoch - 1] < previous_results['val_f1']:\n",
    "                row[3] = '\\033[91m' + str(row[3]) + '\\033[0m'  # Highlight in red\n",
    "    \n",
    "        metrics_table.append(row)\n",
    "        previous_results = {\n",
    "            'loss_train_avg': training_loss_list[epoch - 1],\n",
    "            'val_loss': validation_loss_list[epoch - 1],\n",
    "            'val_f1': f1_score_list[epoch - 1]\n",
    "        }\n",
    "    \n",
    "    # Calculate total training time in minutes\n",
    "    total_time_minutes = total_training_time / 60\n",
    "    \n",
    "    # Calculate total precision\n",
    "    total_precision = precision_list[-1]\n",
    "    \n",
    "    # Add total training time and total precision rows to the table\n",
    "    metrics_table.append(['Total Training Time', '', '', '', '', total_training_time])\n",
    "    metrics_table.append(['Final Precision', '', '', '', '', total_precision])\n",
    "    metrics_table.append(['Total Time (minutes)', '', '', '', '', total_time_minutes])\n",
    "    \n",
    "    # Print the table\n",
    "    print(tabulate(metrics_table, headers='firstrow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "092f1c4d-d96b-4ab6-8c15-fdc3caf7a7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d89633a1ae4788a8350810dc867402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/9871 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 0.4119780563209506\n",
      "Validation loss: 0.34055484813797826\n",
      "F1 Score (weighted): 0.8887695229443436\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/9871 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2\n",
      "Training loss: 0.3317595146875387\n",
      "Validation loss: 0.34477695233996175\n",
      "F1 Score (weighted): 0.8972432527766551\n",
      "\u001b[92m19.47% Training loss decreased compared to the previous epoch\u001b[0m\n",
      "\u001b[91m1.24% Validation loss increased compared to the previous epoch\u001b[0m\n",
      "\u001b[92m0.95% F1 Score increased compared to the previous epoch\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/9871 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3\n",
      "Training loss: 0.30985842583539003\n",
      "Validation loss: 0.35224935371403443\n",
      "F1 Score (weighted): 0.8996280894015887\n",
      "\u001b[92m6.6% Training loss decreased compared to the previous epoch\u001b[0m\n",
      "\u001b[91m2.17% Validation loss increased compared to the previous epoch\u001b[0m\n",
      "\u001b[92m0.27% F1 Score increased compared to the previous epoch\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/9871 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4\n",
      "Training loss: 0.30013789265714114\n",
      "Validation loss: 0.293020113776055\n",
      "F1 Score (weighted): 0.9032533286160324\n",
      "\u001b[92m3.14% Training loss decreased compared to the previous epoch\u001b[0m\n",
      "\u001b[92m16.81% Validation loss decreased compared to the previous epoch\u001b[0m\n",
      "\u001b[92m0.4% F1 Score increased compared to the previous epoch\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/9871 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5\n",
      "Training loss: 0.2895080107033905\n",
      "Validation loss: 0.310211590134741\n",
      "F1 Score (weighted): 0.9050004019332055\n",
      "\u001b[92m3.54% Training loss decreased compared to the previous epoch\u001b[0m\n",
      "\u001b[91m5.87% Validation loss increased compared to the previous epoch\u001b[0m\n",
      "\u001b[92m0.19% F1 Score increased compared to the previous epoch\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/9871 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6\n",
      "Training loss: 0.2802368600777674\n",
      "Validation loss: 0.33364832417959156\n",
      "F1 Score (weighted): 0.9028462778537956\n",
      "\u001b[92m3.2% Training loss decreased compared to the previous epoch\u001b[0m\n",
      "\u001b[91m7.56% Validation loss increased compared to the previous epoch\u001b[0m\n",
      "\u001b[91m0.24% F1 Score decreased compared to the previous epoch\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7:   0%|          | 0/9871 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7\n",
      "Training loss: 0.27451048201669137\n",
      "Validation loss: 0.36286005130250243\n",
      "F1 Score (weighted): 0.9029490652521094\n",
      "\u001b[92m2.04% Training loss decreased compared to the previous epoch\u001b[0m\n",
      "\u001b[91m8.76% Validation loss increased compared to the previous epoch\u001b[0m\n",
      "\u001b[92m0.01% F1 Score increased compared to the previous epoch\u001b[0m\n",
      "\n",
      "Early stopping triggered. Training stopped.\n",
      "\n",
      "Total training time: 198.82113594611485 minutes\n",
      "Final Accuracy: 0.9071591557330291\n",
      "Final Precision: 0.9009055679603938\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 152\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(trainer, dataloader_train, dataloader_val, epochs, patience)\u001b[0m\n\u001b[1;32m    148\u001b[0m previous_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    150\u001b[0m     row \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    151\u001b[0m         epoch,\n\u001b[0;32m--> 152\u001b[0m         \u001b[43mtraining_loss_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[1;32m    153\u001b[0m         validation_loss_list[epoch \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    154\u001b[0m         f1_score_list[epoch \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    155\u001b[0m         accuracy_list[epoch \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    156\u001b[0m         precision_list[epoch \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    157\u001b[0m     ]\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# Compare with previous epoch results\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m previous_results \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "train_model(trainer, dataloader_train, dataloader_val, epochs, patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edba37d-25d9-47eb-98e8-6776950fec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# n_folds = 5  # Set the number of folds\n",
    "# kfold = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# total_training_time = 0\n",
    "# training_loss_list = []\n",
    "# validation_loss_list = []\n",
    "# accuracy_list = []\n",
    "# precision_list = []\n",
    "# f1_score_list = []\n",
    "\n",
    "# previous_results = None  # Store previous epoch results\n",
    "# best_val_loss = float('inf')\n",
    "# counter = 0\n",
    "\n",
    "# # Move the model to the GPU\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# for fold, (train_index, val_index) in enumerate(kfold.split(input_ids_train, labels_train)):\n",
    "#     # Split the data into training and validation sets for the current fold\n",
    "#     train_dataset = TensorDataset(input_ids_train[train_index],\n",
    "#                                   attention_masks_train[train_index],\n",
    "#                                   labels_train[train_index])\n",
    "#     val_dataset = TensorDataset(input_ids_train[val_index],\n",
    "#                                 attention_masks_train[val_index],\n",
    "#                                 labels_train[val_index])\n",
    "\n",
    "#     # Create dataloaders for the training and validation sets\n",
    "#     train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "#     val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#     # Create a new model instance for each fold\n",
    "#     model = SentimentModel(pretrained_path, num_classes)\n",
    "#     model.to(device)  # Move the model to the GPU\n",
    "\n",
    "#     for epoch in tqdm(range(1, epochs + 1), desc=f'Fold {fold+1}'):\n",
    "#         start_time = time.time()\n",
    "\n",
    "#         model.train()\n",
    "#         loss_train_total = 0\n",
    "\n",
    "#         progress_bar = tqdm(train_dataloader, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "#         for batch in progress_bar:\n",
    "#             inputs = [t.to(device) for t in batch]\n",
    "#             model.zero_grad()\n",
    "#             outputs = model(*inputs)\n",
    "#             loss = outputs[0]\n",
    "#             loss_train_total += loss.item()\n",
    "#             loss.backward()\n",
    "#             torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "#             optimizer.step()\n",
    "#             scheduler.step()\n",
    "#             progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item() / len(batch))})\n",
    "\n",
    "#         end_time = time.time()\n",
    "#         epoch_training_time = end_time - start_time\n",
    "#         total_training_time += epoch_training_time\n",
    "\n",
    "#         torch.save(model.state_dict(), f'Models/finetuned_bert_ft_epoch{epoch}.model')\n",
    "\n",
    "#         tqdm.write(f'\\nEpoch {epoch}')\n",
    "\n",
    "#         loss_train_avg = loss_train_total / len(train_dataloader)\n",
    "#         tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "\n",
    "#         val_loss, predictions, true_vals = evaluate(val_dataloader)\n",
    "\n",
    "#         # Convert predictions to discrete labels\n",
    "#         predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "#         val_f1 = f1_score(true_vals, predictions, average='weighted')\n",
    "#         tqdm.write(f'Validation loss: {val_loss}')\n",
    "#         tqdm.write(f'F1 Score (weighted): {val_f1}')\n",
    "\n",
    "#         val_accuracy = accuracy_score(true_vals, predictions)\n",
    "#         val_precision = precision_score(true_vals, predictions, average='weighted', zero_division=1)\n",
    "\n",
    "#         # Compute and store metrics\n",
    "#         training_loss_list.append(loss_train_avg)\n",
    "#         validation_loss_list.append(val_loss)\n",
    "#         f1_score_list.append(val_f1)\n",
    "#         accuracy_list.append(val_accuracy)\n",
    "#         precision_list.append(val_precision)\n",
    "        \n",
    "#         # Check if there are previous results to compare with\n",
    "#         if previous_results is not None:\n",
    "#             if loss_train_avg > previous_results['loss_train_avg']:\n",
    "#                 percentage_increase = ((loss_train_avg - previous_results['loss_train_avg']) / previous_results['loss_train_avg']) * 100\n",
    "#                 tqdm.write('\\033[91m' + f'{round(percentage_increase, 2)}% Training loss increased compared to the previous epoch' + '\\033[0m')\n",
    "#             if loss_train_avg < previous_results['loss_train_avg']:\n",
    "#                 percentage_decrease = ((previous_results['loss_train_avg'] - loss_train_avg) / previous_results['loss_train_avg']) * 100\n",
    "#                 tqdm.write('\\033[92m' + f'{round(percentage_decrease, 2)}% Training loss decreased compared to the previous epoch' + '\\033[0m')\n",
    "#             if val_loss > previous_results['val_loss']:\n",
    "#                 percentage_increase = ((val_loss - previous_results['val_loss']) / previous_results['val_loss']) * 100\n",
    "#                 tqdm.write('\\033[91m' + f'{round(percentage_increase, 2)}% Validation loss increased compared to the previous epoch' + '\\033[0m')\n",
    "#             if val_loss < previous_results['val_loss']:\n",
    "#                 percentage_decrease = ((previous_results['val_loss'] - val_loss) / previous_results['val_loss']) * 100\n",
    "#                 tqdm.write('\\033[92m' + f'{round(percentage_decrease, 2)}% Validation loss decreased compared to the previous epoch' + '\\033[0m')\n",
    "#             if val_f1 < previous_results['val_f1']:\n",
    "#                 percentage_decrease = ((previous_results['val_f1'] - val_f1) / previous_results['val_f1']) * 100\n",
    "#                 tqdm.write('\\033[91m' + f'{round(percentage_decrease, 2)}% F1 Score decreased compared to the previous epoch' + '\\033[0m')\n",
    "#             if val_f1 > previous_results['val_f1']:\n",
    "#                 percentage_increase = ((val_f1 - previous_results['val_f1']) / previous_results['val_f1']) * 100\n",
    "#                 tqdm.write('\\033[92m' + f'{round(percentage_increase, 2)}% F1 Score increased compared to the previous epoch' + '\\033[0m')\n",
    "    \n",
    "#         # Store current results as previous results for the next epoch\n",
    "#         previous_results = {\n",
    "#             'loss_train_avg': loss_train_avg,\n",
    "#             'val_loss': val_loss,\n",
    "#             'val_f1': val_f1\n",
    "#         }\n",
    "        \n",
    "#         # Check for early stopping\n",
    "#         if val_loss < best_val_loss:\n",
    "#             best_val_loss = val_loss\n",
    "#             counter = 0\n",
    "#         else:\n",
    "#             counter += 1\n",
    "#             if counter >= patience:\n",
    "#                 tqdm.write('\\nEarly stopping triggered. Training stopped.')\n",
    "#                 break\n",
    "    \n",
    "#     total_time_minutes = total_training_time / 60\n",
    "#     tqdm.write(f'\\nTotal training time: {total_time_minutes} minutes')\n",
    "    \n",
    "#     final_accuracy = accuracy_list[-1]\n",
    "#     final_precision = precision_list[-1]\n",
    "#     tqdm.write(f'Final Accuracy: {final_accuracy}')\n",
    "#     tqdm.write(f'Final Precision: {final_precision}')\n",
    "    \n",
    "#     # Create the x-axis values based on the actual number of epochs completed\n",
    "#     x_values = range(1, len(training_loss_list) + 1)\n",
    "    \n",
    "#     # Create the metrics subplot\n",
    "#     fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "#     # Plot training loss\n",
    "#     ax.plot(x_values, training_loss_list, label='Training Loss')\n",
    "    \n",
    "#     # Plot validation loss\n",
    "#     ax.plot(x_values, validation_loss_list, label='Validation Loss')\n",
    "    \n",
    "#     # Plot F1-score\n",
    "#     ax.plot(x_values, f1_score_list, label='F1 Score')\n",
    "    \n",
    "#     # Set labels and title\n",
    "#     ax.set_xlabel('Epoch')\n",
    "#     ax.set_ylabel('Metric Value')\n",
    "#     ax.set_title('Training Loss, Validation Loss, and F1 Score')\n",
    "    \n",
    "#     # Set legend\n",
    "#     ax.legend()\n",
    "    \n",
    "#     # Show the combined plot\n",
    "#     plt.show()\n",
    "    \n",
    "    \n",
    "#     # Create the metrics table\n",
    "#     metrics_table = [\n",
    "#         ['Epoch', 'Training Loss', 'Validation Loss', 'F1 Score', 'Accuracy', 'Precision'],\n",
    "#     ]\n",
    "#     previous_results = None\n",
    "#     for epoch in range(1, epochs + 1):\n",
    "#         row = [\n",
    "#             epoch,\n",
    "#             training_loss_list[epoch - 1],\n",
    "#             validation_loss_list[epoch - 1],\n",
    "#             f1_score_list[epoch - 1],\n",
    "#             accuracy_list[epoch - 1],\n",
    "#             precision_list[epoch - 1]\n",
    "#         ]\n",
    "    \n",
    "#         # Compare with previous epoch results\n",
    "#         if previous_results is not None:\n",
    "#             if training_loss_list[epoch - 1] < previous_results['loss_train_avg']:\n",
    "#                 row[1] = '\\033[92m' + str(row[1]) + '\\033[0m'  # Highlight in green\n",
    "#             if training_loss_list[epoch - 1] > previous_results['loss_train_avg']:\n",
    "#                 row[1] = '\\033[91m' + str(row[1]) + '\\033[0m'  # Highlight in red\n",
    "#             if validation_loss_list[epoch - 1] < previous_results['val_loss']:\n",
    "#                 row[2] = '\\033[92m' + str(row[2]) + '\\033[0m'  # Highlight in green\n",
    "#             if validation_loss_list[epoch - 1] > previous_results['val_loss']:\n",
    "#                 row[2] = '\\033[91m' + str(row[2]) + '\\033[0m'  # Highlight in red\n",
    "#             if f1_score_list[epoch - 1] > previous_results['val_f1']:\n",
    "#                 row[3] = '\\033[92m' + str(row[3]) + '\\033[0m'  # Highlight in green\n",
    "#             if f1_score_list[epoch - 1] < previous_results['val_f1']:\n",
    "#                 row[3] = '\\033[91m' + str(row[3]) + '\\033[0m'  # Highlight in red\n",
    "    \n",
    "#         metrics_table.append(row)\n",
    "#         previous_results = {\n",
    "#             'loss_train_avg': training_loss_list[epoch - 1],\n",
    "#             'val_loss': validation_loss_list[epoch - 1],\n",
    "#             'val_f1': f1_score_list[epoch - 1]\n",
    "#         }\n",
    "    \n",
    "#     # Calculate total training time in minutes\n",
    "#     total_time_minutes = total_training_time / 60\n",
    "    \n",
    "#     # Calculate total precision\n",
    "#     total_precision = precision_list[-1]\n",
    "    \n",
    "#     # Add total training time and total precision rows to the table\n",
    "#     metrics_table.append(['Total Training Time', '', '', '', '', total_training_time])\n",
    "#     metrics_table.append(['Final Precision', '', '', '', '', total_precision])\n",
    "#     metrics_table.append(['Total Time (minutes)', '', '', '', '', total_time_minutes])\n",
    "    \n",
    "#     # Print the table\n",
    "#     print(tabulate(metrics_table, headers='firstrow'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e1c4af-8187-4d7e-a7b1-ce1f14ea3fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
