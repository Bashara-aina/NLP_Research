{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bf24e9-d40b-45ad-9330-405d0097fe2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm  # For displaying progress bars\n",
    "from datasets import load_dataset  # For loading datasets\n",
    "from sklearn.model_selection import train_test_split  # For splitting the dataset\n",
    "from transformers import BertTokenizer  # For tokenizing text\n",
    "from torch.utils.data import TensorDataset  # For creating Tensor datasets\n",
    "import time  # For measuring time\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score  # For evaluation metrics\n",
    "from sklearn.exceptions import UndefinedMetricWarning  # For handling metric warnings\n",
    "import matplotlib.pyplot as plt  # For plotting\n",
    "from tabulate import tabulate  # For tabular data formatting\n",
    "import random  # For randomization\n",
    "import numpy as np  # For numerical operations\n",
    "from transformers import (\n",
    "    BertTokenizer,  # Tokenizer for BERT models\n",
    "    AdamW,  # Optimizer for BERT models\n",
    "    get_linear_schedule_with_warmup,  # Learning rate scheduler for BERT models\n",
    "    BertConfig,  # Configuration for BERT models\n",
    "    BertForSequenceClassification  # BERT model for sequence classification tasks\n",
    ")\n",
    "from torch.utils.data import (\n",
    "    DataLoader,  # Data loader for creating batches\n",
    "    RandomSampler,  # Sampler for random sampling of data\n",
    "    SequentialSampler  # Sampler for sequential sampling of data\n",
    ")\n",
    "from sklearn.metrics import f1_score  # For computing the F1 score\n",
    "\n",
    "# 1. Torch: PyTorch library for deep learning\n",
    "# 2. Pandas: Library for data manipulation and analysis\n",
    "# 3. tqdm: Library for displaying progress bars\n",
    "# 4. datasets: Library for working with datasets\n",
    "# 5. train_test_split: Function for splitting the dataset into training and validation sets\n",
    "# 6. BertTokenizer: Tokenizer for BERT models\n",
    "# 7. TensorDataset: Dataset class for creating PyTorch Tensor datasets\n",
    "# 8. time: Module for measuring time\n",
    "# 9. accuracy_score, precision_score, f1_score: Evaluation metrics for classification tasks\n",
    "# 10. UndefinedMetricWarning: Warning for undefined metric values\n",
    "# 11. matplotlib.pyplot: Plotting library\n",
    "# 12. tabulate: Library for formatting tabular data\n",
    "# 13. random: Module for randomization\n",
    "# 14. numpy: Library for numerical operations\n",
    "# 15. AdamW: Optimizer for BERT models\n",
    "# 16. get_linear_schedule_with_warmup: Learning rate scheduler for BERT models\n",
    "# 17. BertConfig: Configuration for BERT models\n",
    "# 18. BertForSequenceClassification: BERT model for sequence classification tasks\n",
    "# 19. DataLoader: Data loader for creating batches\n",
    "# 20. RandomSampler: Sampler for random sampling of data\n",
    "# 21. SequentialSampler: Sampler for sequential sampling of data\n",
    "# 22. f1_score: Function for computing the F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207f2073-3da6-4185-917f-e8b3694617ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datacleaning_imdb():\n",
    "    dataset = load_dataset(\"imdb\")\n",
    "    train_data = dataset['train']\n",
    "\n",
    "    df = train_data.to_pandas()  # Convert the dataset to a Pandas DataFrame\n",
    "\n",
    "    df['sentiment'] = df['label'].map({0: 'bad', 1: 'good'})\n",
    "\n",
    "    possible_labels = df.sentiment.unique()  # Get unique category labels from the DataFrame column 'category'\n",
    "\n",
    "    label_dict = {}  # Create a dictionary to map each possible label to a unique index\n",
    "    for index, possible_label in enumerate(possible_labels):\n",
    "        label_dict[possible_label] = index\n",
    "\n",
    "    df['label'] = df.sentiment.replace(label_dict)\n",
    "\n",
    "    # Split the dataset into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        df.index.values,\n",
    "        df.label.values,\n",
    "        test_size=0.15,\n",
    "        random_state=17,\n",
    "        stratify=df.label.values\n",
    "    )\n",
    "\n",
    "    df['data_type'] = ['not_set'] * df.shape[0]  # Set a new column 'data_type' for later data split\n",
    "\n",
    "    # Set the 'data_type' column of the dataframe for training and validation data\n",
    "    df.loc[X_train, 'data_type'] = 'train'\n",
    "    df.loc[X_val, 'data_type'] = 'val'\n",
    "\n",
    "    return df\n",
    "\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten() #This line finds the index with the highest probability in each prediction, effectively giving the predicted class for each input.\n",
    "    labels_flat = labels.flatten()  #This line flattens the labels array into a 1D vector, as required by the f1_score function.\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted') #This line computes the F1 score using the true labels and the predicted labels, with the weighted averaging scheme. The result is returned.\n",
    "\n",
    "def accuracy_per_class(preds, labels):\n",
    "    # Create a dictionary with keys and values reversed for easy lookup.\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    # Get the predicted labels and flatten them.\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    \n",
    "    # Get the actual labels and flatten them.\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    # Iterate over the unique labels in the actual labels.\n",
    "    for label in np.unique(labels_flat):\n",
    "        # Get the predicted labels for this class.\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        \n",
    "        # Get the actual labels for this class.\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        \n",
    "        # Print the class name, accuracy numerator and denominator.\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')\n",
    "\n",
    "#This code evaluates the performance of a trained model on a validation dataset by computing its loss and predictions for each batch in the dataset.\n",
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval() # setting the model to evaluation mode to disable dropout and other regularization techniques that are useful during training but not during evaluation.\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "    \n",
    "        batch = tuple(b.to(device) for b in batch) # moving the input batch to the GPU for faster computation.\n",
    "   \n",
    "        #  creating a dictionary of inputs that will be passed to the model. The input IDs and attention mask are for the BERT model, and the labels are the true labels for each input.\n",
    "        inputs = {'input_ids':  \tbatch[0],\n",
    "                'attention_mask': batch[1],\n",
    "                'labels':     \tbatch[2],\n",
    "                } \n",
    "\n",
    "        with torch.no_grad():   \n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val)\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "       \t \n",
    "    return loss_val_avg, predictions, true_vals\n",
    "\n",
    "def train_model(trainer, dataloader_train, dataloader_val, epochs, patience):\n",
    "    total_training_time = 0\n",
    "    \n",
    "    training_loss_list = []\n",
    "    validation_loss_list = []\n",
    "    accuracy_list = []\n",
    "    precision_list = []\n",
    "    f1_score_list = []\n",
    "    \n",
    "    previous_results = None  # Store previous epoch results\n",
    "    best_val_loss = float('inf')\n",
    "    counter = 0\n",
    "    \n",
    "    for epoch in tqdm(range(1, epochs + 1)):\n",
    "        start_time = time.time()\n",
    "    \n",
    "        model.train()\n",
    "        loss_train_total = 0\n",
    "    \n",
    "        progress_bar = tqdm(dataloader_train,\n",
    "                            desc='Epoch {:1d}'.format(epoch),\n",
    "                            leave=False,\n",
    "                            disable=False)\n",
    "        for batch in progress_bar:\n",
    "            model.zero_grad()\n",
    "            batch = tuple(b.to(device) for b in batch)\n",
    "            inputs = {\n",
    "                'input_ids': batch[0],\n",
    "                'attention_mask': batch[1],\n",
    "                'labels': batch[2],\n",
    "            }\n",
    "            output = model(**inputs)\n",
    "            loss = output[0]\n",
    "\n",
    "            # L1 regularization\n",
    "            l1_regularization = torch.tensor(0., device=device)\n",
    "            for param in model.parameters():\n",
    "                l1_regularization += torch.norm(param, 1)\n",
    "            \n",
    "            # L2 regularization\n",
    "            l2_regularization = torch.tensor(0., device=device)\n",
    "            for param in model.parameters():\n",
    "                l2_regularization += torch.norm(param, 2)\n",
    "\n",
    "            \n",
    "            loss_train_total += loss.item()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item() / len(batch))})\n",
    "    \n",
    "        end_time = time.time()\n",
    "        epoch_training_time = end_time - start_time\n",
    "        total_training_time += epoch_training_time\n",
    "    \n",
    "        torch.save(model.state_dict(), f'Models/finetuned_bert_gpt_ft_epoch{epoch}.model')\n",
    "    \n",
    "        tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "        loss_train_avg = loss_train_total / len(dataloader_train)\n",
    "        tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "        val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
    "    \n",
    "        # Convert predictions to discrete labels\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "        val_f1 = f1_score(true_vals, predictions, average='weighted')\n",
    "        tqdm.write(f'Validation loss: {val_loss}')\n",
    "        tqdm.write(f'F1 Score (weighted): {val_f1}')\n",
    "    \n",
    "        val_accuracy = accuracy_score(true_vals, predictions)\n",
    "        val_precision = precision_score(true_vals, predictions, average='weighted', zero_division=1)\n",
    "    \n",
    "        # Compute and store metrics\n",
    "        training_loss_list.append(loss_train_avg)\n",
    "        validation_loss_list.append(val_loss)\n",
    "        f1_score_list.append(val_f1)\n",
    "        accuracy_list.append(val_accuracy)\n",
    "        precision_list.append(val_precision)\n",
    "    \n",
    "        # Check if there are previous results to compare with\n",
    "        if previous_results is not None:\n",
    "            if loss_train_avg > previous_results['loss_train_avg']:\n",
    "                percentage_increase = ((loss_train_avg - previous_results['loss_train_avg']) / previous_results['loss_train_avg']) * 100\n",
    "                tqdm.write('\\033[91m' + f'{round(percentage_increase, 2)}% Training loss increased compared to the previous epoch' + '\\033[0m')\n",
    "            if loss_train_avg < previous_results['loss_train_avg']:\n",
    "                percentage_decrease = ((previous_results['loss_train_avg'] - loss_train_avg) / previous_results['loss_train_avg']) * 100\n",
    "                tqdm.write('\\033[92m' + f'{round(percentage_decrease, 2)}% Training loss decreased compared to the previous epoch' + '\\033[0m')\n",
    "            if val_loss > previous_results['val_loss']:\n",
    "                percentage_increase = ((val_loss - previous_results['val_loss']) / previous_results['val_loss']) * 100\n",
    "                tqdm.write('\\033[91m' + f'{round(percentage_increase, 2)}% Validation loss increased compared to the previous epoch' + '\\033[0m')\n",
    "            if val_loss < previous_results['val_loss']:\n",
    "                percentage_decrease = ((previous_results['val_loss'] - val_loss) / previous_results['val_loss']) * 100\n",
    "                tqdm.write('\\033[92m' + f'{round(percentage_decrease, 2)}% Validation loss decreased compared to the previous epoch' + '\\033[0m')\n",
    "            if val_f1 < previous_results['val_f1']:\n",
    "                percentage_decrease = ((previous_results['val_f1'] - val_f1) / previous_results['val_f1']) * 100\n",
    "                tqdm.write('\\033[91m' + f'{round(percentage_decrease, 2)}% F1 Score decreased compared to the previous epoch' + '\\033[0m')\n",
    "            if val_f1 > previous_results['val_f1']:\n",
    "                percentage_increase = ((val_f1 - previous_results['val_f1']) / previous_results['val_f1']) * 100\n",
    "                tqdm.write('\\033[92m' + f'{round(percentage_increase, 2)}% F1 Score increased compared to the previous epoch' + '\\033[0m')\n",
    "    \n",
    "        # Store current results as previous results for the next epoch\n",
    "        previous_results = {\n",
    "            'loss_train_avg': loss_train_avg,\n",
    "            'val_loss': val_loss,\n",
    "            'val_f1': val_f1\n",
    "        }\n",
    "        \n",
    "        # Check for early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                tqdm.write('\\nEarly stopping triggered. Training stopped.')\n",
    "                break\n",
    "    \n",
    "    total_time_minutes = total_training_time / 60\n",
    "    tqdm.write(f'\\nTotal training time: {total_time_minutes} minutes')\n",
    "    \n",
    "    final_accuracy = accuracy_list[-1]\n",
    "    final_precision = precision_list[-1]\n",
    "    tqdm.write(f'Final Accuracy: {final_accuracy}')\n",
    "    tqdm.write(f'Final Precision: {final_precision}')\n",
    "    \n",
    "    # Create the x-axis values based on the actual number of epochs completed\n",
    "    x_values = range(1, len(training_loss_list) + 1)\n",
    "    \n",
    "    # Create the metrics subplot\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    # Plot training loss\n",
    "    ax.plot(x_values, training_loss_list, label='Training Loss')\n",
    "    \n",
    "    # Plot validation loss\n",
    "    ax.plot(x_values, validation_loss_list, label='Validation Loss')\n",
    "    \n",
    "    # Plot F1-score\n",
    "    ax.plot(x_values, f1_score_list, label='F1 Score')\n",
    "\n",
    "    # Plot Accuracy\n",
    "    ax.plot(x_values, accuracy_list, label='Accuracy')\n",
    "    \n",
    "    # Set labels and title\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Metric Value')\n",
    "    ax.set_title('Training Loss, Validation Loss, and F1 Score')\n",
    "    \n",
    "    # Set legend\n",
    "    ax.legend()\n",
    "    \n",
    "    # Show the combined plot\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    # Create the metrics table\n",
    "    metrics_table = [\n",
    "        ['Epoch', 'Training Loss', 'Validation Loss', 'F1 Score', 'Accuracy', 'Precision'],\n",
    "    ]\n",
    "    previous_results = None\n",
    "    for epoch in range(1, len(training_loss_list) + 1):\n",
    "        row = [\n",
    "            epoch,\n",
    "            training_loss_list[epoch - 1],\n",
    "            validation_loss_list[epoch - 1],\n",
    "            f1_score_list[epoch - 1],\n",
    "            accuracy_list[epoch - 1],\n",
    "            precision_list[epoch - 1]\n",
    "        ]\n",
    "    \n",
    "        # Compare with previous epoch results\n",
    "        if previous_results is not None:\n",
    "            if training_loss_list[epoch - 1] < previous_results['loss_train_avg']:\n",
    "                row[1] = '\\033[92m' + str(row[1]) + '\\033[0m'  # Highlight in green\n",
    "            if training_loss_list[epoch - 1] > previous_results['loss_train_avg']:\n",
    "                row[1] = '\\033[91m' + str(row[1]) + '\\033[0m'  # Highlight in red\n",
    "            if validation_loss_list[epoch - 1] < previous_results['val_loss']:\n",
    "                row[2] = '\\033[92m' + str(row[2]) + '\\033[0m'  # Highlight in green\n",
    "            if validation_loss_list[epoch - 1] > previous_results['val_loss']:\n",
    "                row[2] = '\\033[91m' + str(row[2]) + '\\033[0m'  # Highlight in red\n",
    "            if f1_score_list[epoch - 1] > previous_results['val_f1']:\n",
    "                row[3] = '\\033[92m' + str(row[3]) + '\\033[0m'  # Highlight in green\n",
    "            if f1_score_list[epoch - 1] < previous_results['val_f1']:\n",
    "                row[3] = '\\033[91m' + str(row[3]) + '\\033[0m'  # Highlight in red\n",
    "            if accuracy_list[epoch - 1] > previous_results['val_f1']:\n",
    "                row[4] = '\\033[92m' + str(row[3]) + '\\033[0m'  # Highlight in green\n",
    "            if accuracy_list[epoch - 1] < previous_results['val_f1']:\n",
    "                row[4] = '\\033[91m' + str(row[3]) + '\\033[0m'  # Highlight in red\n",
    "            if precision_list[epoch - 1] > previous_results['val_f1']:\n",
    "                row[5] = '\\033[92m' + str(row[3]) + '\\033[0m'  # Highlight in green\n",
    "            if precision_list[epoch - 1] < previous_results['val_f1']:\n",
    "                row[5] = '\\033[91m' + str(row[3]) + '\\033[0m'  # Highlight in red\n",
    "    \n",
    "        metrics_table.append(row)\n",
    "        previous_results = {\n",
    "            'loss_train_avg': training_loss_list[epoch - 1],\n",
    "            'val_loss': validation_loss_list[epoch - 1],\n",
    "            'val_f1': f1_score_list[epoch - 1]\n",
    "        }\n",
    "    \n",
    "    # Calculate total training time in minutes\n",
    "    total_time_minutes = total_training_time / 60\n",
    "    \n",
    "    # Calculate total precision\n",
    "    total_precision = precision_list[-1]\n",
    "    \n",
    "    # Add total training time and total precision rows to the table\n",
    "    metrics_table.append(['Total Training Time', '', '', '', '', total_training_time])\n",
    "    metrics_table.append(['Final Precision', '', '', '', '', total_precision])\n",
    "    metrics_table.append(['Total Time (minutes)', '', '', '', '', total_time_minutes])\n",
    "    \n",
    "    # Print the table\n",
    "    print(tabulate(metrics_table, headers='firstrow'))\n",
    "\n",
    "default_args = {\n",
    "    \"output_dir\": \"tmp\",\n",
    "    \"evaluation_strategy\": \"steps\",\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"log_level\": \"error\",\n",
    "    \"report_to\": \"none\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9785608-cd5e-4432-9d68-68d90c4a0a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datacleaning_imdb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8793b8bc-43bd-4d43-a17e-abf0174eb200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label_dict and assign the number of labels\n",
    "label_dict = {label: index for index, label in enumerate(df['label'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2707709e-9e1b-460f-9386-6d9e999f2d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(n=10, random_state=42)  # Generate 10 random rows from df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc596d9c-5808-4f39-a59e-6ed36d8927dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['sentiment']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731e5a17-8ab7-4d19-a012-05eeabab1d90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load BERT tokenizer\n",
    "pretrained_path = 'bert-base-uncased'  # Replace with the path to the pretrained BERT model\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    do_lower_case=True\n",
    ")\n",
    "\n",
    "encoded_data_train_text = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='train'].text.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding='longest',\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "input_ids_train = encoded_data_train_text['input_ids']\n",
    "attention_masks_train = encoded_data_train_text['attention_mask']\n",
    "\n",
    "labels_train = torch.tensor(df[df.data_type=='train'].label.values)\n",
    "\n",
    "encoded_data_val_text = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='val'].text.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding='longest',\n",
    "    max_length=256,\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "input_ids_val = encoded_data_val_text['input_ids']\n",
    "attention_masks_val = encoded_data_val_text['attention_mask']\n",
    "\n",
    "labels_val = torch.tensor(df[df.data_type=='val'].label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42125069-fd5d-49c0-8032-2be61cb2a6d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
    "len(dataset_train), len(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2f7e02-8423-4787-994e-d599ab86b123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertConfig, GPT2Model, GPT2Config\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "class SentimentModel(nn.Module):\n",
    "    def __init__(self, pretrained_bert_path, pretrained_gpt_path):\n",
    "        super(SentimentModel, self).__init__()\n",
    "        \n",
    "        bert_config = BertConfig.from_pretrained(\n",
    "            pretrained_bert_path,\n",
    "            hidden_dropout_prob=0.3,\n",
    "            attention_probs_dropout_prob=0.1\n",
    "        )\n",
    "        self.bert = BertModel.from_pretrained(pretrained_bert_path, config=bert_config)\n",
    "        \n",
    "        gpt_config = GPT2Config.from_pretrained(pretrained_gpt_path)\n",
    "        self.gpt = GPT2Model.from_pretrained(pretrained_gpt_path, config=gpt_config)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(bert_config.hidden_size + gpt_config.hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        bert_outputs = self.bert(input_ids, attention_mask=attention_mask)[0]\n",
    "        gpt_outputs = self.gpt(input_ids, attention_mask=attention_mask)[0]\n",
    "        \n",
    "        bert_pooled_output = self.dropout(bert_outputs[:, 0, :])  # Use the [CLS] token representation\n",
    "        gpt_last_hidden_state = self.dropout(gpt_outputs[:, -1, :])  # Use the last hidden state\n",
    "        \n",
    "        combined_outputs = torch.cat((bert_pooled_output, gpt_last_hidden_state), dim=1)\n",
    "        \n",
    "        logits = self.fc(combined_outputs)\n",
    "        outputs = nn.functional.softmax(logits, dim=1)\n",
    "        \n",
    "        if labels is not None:\n",
    "            loss = nn.CrossEntropyLoss()(logits.view(-1, num_classes), labels.view(-1))\n",
    "            return loss, outputs, labels\n",
    "        else:\n",
    "            return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d131f86-ee7e-49b3-a104-a61841bb78d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model instance\n",
    "model = SentimentModel('bert-base-uncased', 'gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60757b1f-b1d9-468b-9ad0-3d59e4a7da03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the regularization strength\n",
    "lambda_l1 = 0.001\n",
    "lambda_l2 = 0.001\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834c8c87-40a1-49c6-8e7b-307b931aec01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c610d351-0be0-4899-bf58-2397193b5ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, logging\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    **default_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feb2f9d-26d7-41ed-b138-f2a59173c99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_train,\n",
    "    eval_dataset=dataset_val,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb9e671-0f31-4a58-bf72-8c13ac04e6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "# Set the batch size and create data loaders for training and validation sets\n",
    "\n",
    "batch_size = 8 #32\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train,\n",
    "    sampler=RandomSampler(dataset_train),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "dataloader_val = DataLoader(\n",
    "    dataset_val,\n",
    "    sampler=RandomSampler(dataset_val),\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bc14be-49bc-4b42-be70-17412957cdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=1e-5,\n",
    "    eps=1e-8\n",
    ")\n",
    "\n",
    "epochs = 25\n",
    "patience = 5\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=len(dataloader_train) * epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c174c9-8e92-42fa-9d81-54260c58251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val) #sets the seed value for the Python built-in pseudo-random generator.\n",
    "np.random.seed(seed_val) #sets the seed value for the NumPy pseudo-random number generator.\n",
    "torch.manual_seed(seed_val) #sets the seed value for the random number generator in PyTorch on the CPU.\n",
    "torch.cuda.manual_seed_all(seed_val) #sets the seed value for the random number generator in PyTorch on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a28ec5-87fe-4bdf-b6a1-05bf8b6f6b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c363e7-c757-4bb6-bb2c-d19a126fd165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "k = 10  # Number of folds\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store the evaluation metrics for each fold\n",
    "training_loss_lists = []\n",
    "validation_loss_lists = []\n",
    "accuracy_lists = []\n",
    "precision_lists = []\n",
    "f1_score_lists = []\n",
    "\n",
    "# Convert the multilabel indicator target to numpy array\n",
    "targets = dataset_train.tensors[1].numpy()\n",
    "\n",
    "# Perform multilabel k-fold cross-validation\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(targets)):\n",
    "    print(f\"\\nFold {fold+1}\")\n",
    "    train_sampler = SubsetRandomSampler(train_index)\n",
    "    val_sampler = SubsetRandomSampler(val_index)\n",
    "\n",
    "    # Create data loaders for training and validation\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size=batch_size, sampler=train_sampler)\n",
    "    dataloader_val = DataLoader(dataset_train, batch_size=batch_size, sampler=val_sampler)\n",
    "\n",
    "    # train_model(trainer, dataloader_train, dataloader_val, epochs, patience)\n",
    "\n",
    "    try:\n",
    "        train_model(trainer, dataloader_train, dataloader_val, epochs, patience)\n",
    "    except Exception as e:\n",
    "        print(f\"Continue to the next fold {fold+1}: {str(e)}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24429e4-743b-4a11-80d6-5e2fadaabc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"Models/finetuned_bert_gpt_ft_epoch1.model\", \n",
    "        map_location = torch.device('cuda')\n",
    "    )\n",
    ")\n",
    "_, predictions, true_vals = evaluate(dataloader_val)\n",
    "accuracy_per_class(predictions, true_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5f8d3d-86ce-486b-84d4-1363d26dab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"Models/finetuned_bert_gpt_ft_epoch1.model\", \n",
    "        map_location = torch.device('cuda')\n",
    "    )\n",
    ")\n",
    "_, predictions, true_vals = evaluate(dataloader_train)\n",
    "accuracy_per_class(predictions, true_vals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
